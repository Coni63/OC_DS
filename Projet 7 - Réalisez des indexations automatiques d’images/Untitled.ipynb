{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://medium.com/towards-data-science/transfer-learning-using-keras-d804b2e04ef8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob \n",
    "import random\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fait\n",
    "\n",
    "# for filename in glob.glob('test/*.jpg'):\n",
    "#     img = Image.open(filename)\n",
    "#     img = img.resize((256, 256), Image.ANTIALIAS)\n",
    "#     img.save(os.path.join(\"test/resized/\", os.path.basename(filename)))\n",
    "\n",
    "# for filename in glob.glob('train/*.jpg'):\n",
    "#     img = Image.open(filename)\n",
    "#     img = img.resize((256, 256), Image.ANTIALIAS)\n",
    "#     img.save(os.path.join(\"train/resized/\", os.path.basename(filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"labels.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      "id       10222 non-null object\n",
      "breed    10222 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for filename in glob.glob('train/resized/*.jpg'):\n",
    "#     name_img = os.path.basename(filename)[:-4]\n",
    "#     classe = df[df[\"id\"] == name_img][\"breed\"].values[0]\n",
    "#     if not os.path.isdir(\"train/resized/\" + classe):\n",
    "#         os.mkdir(\"train/resized/\" + classe)\n",
    "#     os.rename(filename, os.path.join(\"train\", \"resized\", classe,name_img+\".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for folder in os.listdir(\"train/resized/\"):\n",
    "#     #print(folder)\n",
    "#     for i in range(10):\n",
    "#         img = random.choice(os.listdir(os.path.join(\"train/resized/\", folder)))\n",
    "#         img_path = os.path.join(\"train/resized/\", folder, img)\n",
    "#         to_path = os.path.join(\"eval\", folder, img)\n",
    "#         if not os.path.isdir(\"eval/\" + folder):\n",
    "#             os.mkdir(\"eval/\" + folder)\n",
    "#         os.rename(img_path, to_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"train/resized\"\n",
    "validation_data_dir = \"eval/\"\n",
    "nb_train_samples = 9022\n",
    "nb_validation_samples = 1200 \n",
    "batch_size = 32\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for layer in model.layers[:5]:   # a tester\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(120, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda501\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_final = Model(input = model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latest_save = \"vgg19.16.h5\"\n",
    "\n",
    "if os.path.exists(latest_save):\n",
    "    model_final.load_weights(latest_save)\n",
    "    print(\"Weight Loaded...\")\n",
    "else:\n",
    "    print(\"No save found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_1.h5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9022 images belonging to 120 classes.\n",
      "Found 1200 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda501\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "C:\\Anaconda501\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=50, validation_data=<keras.pre..., callbacks=[<keras.ca..., steps_per_epoch=281, validation_steps=1200)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.8387 - acc: 0.0078Epoch 00001: loss improved from inf to 4.83870, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 585s 2s/step - loss: 4.8387 - acc: 0.0078 - val_loss: 4.7970 - val_acc: 0.0089\n",
      "Epoch 2/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7967 - acc: 0.0105Epoch 00002: loss improved from 4.83870 to 4.79674, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 578s 2s/step - loss: 4.7967 - acc: 0.0105 - val_loss: 4.7931 - val_acc: 0.0101\n",
      "Epoch 3/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7897 - acc: 0.0097Epoch 00003: loss improved from 4.79674 to 4.78957, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 570s 2s/step - loss: 4.7896 - acc: 0.0097 - val_loss: 4.7905 - val_acc: 0.0095\n",
      "Epoch 4/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7867 - acc: 0.0100Epoch 00004: loss improved from 4.78957 to 4.78667, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 569s 2s/step - loss: 4.7867 - acc: 0.0101 - val_loss: 4.7899 - val_acc: 0.0089\n",
      "Epoch 5/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7844 - acc: 0.0109Epoch 00005: loss improved from 4.78667 to 4.78430, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 571s 2s/step - loss: 4.7843 - acc: 0.0110 - val_loss: 4.7896 - val_acc: 0.0085\n",
      "Epoch 6/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7833 - acc: 0.0106Epoch 00006: loss improved from 4.78430 to 4.78328, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 566s 2s/step - loss: 4.7833 - acc: 0.0106 - val_loss: 4.7900 - val_acc: 0.0097\n",
      "Epoch 7/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7820 - acc: 0.0104Epoch 00007: loss improved from 4.78328 to 4.78204, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 571s 2s/step - loss: 4.7820 - acc: 0.0103 - val_loss: 4.7890 - val_acc: 0.0085\n",
      "Epoch 8/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7816 - acc: 0.0116Epoch 00008: loss improved from 4.78204 to 4.78149, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 568s 2s/step - loss: 4.7815 - acc: 0.0116 - val_loss: 4.7867 - val_acc: 0.0101\n",
      "Epoch 9/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7774 - acc: 0.0125Epoch 00009: loss improved from 4.78149 to 4.77744, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 568s 2s/step - loss: 4.7775 - acc: 0.0125 - val_loss: 4.7869 - val_acc: 0.0112\n",
      "Epoch 10/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7736 - acc: 0.0146Epoch 00010: loss improved from 4.77744 to 4.77355, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 569s 2s/step - loss: 4.7735 - acc: 0.0147 - val_loss: 4.7825 - val_acc: 0.0154\n",
      "Epoch 11/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7699 - acc: 0.0151Epoch 00011: loss improved from 4.77355 to 4.76977, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 569s 2s/step - loss: 4.7698 - acc: 0.0152 - val_loss: 4.7812 - val_acc: 0.0138\n",
      "Epoch 12/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7689 - acc: 0.0166Epoch 00012: loss improved from 4.76977 to 4.76888, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 569s 2s/step - loss: 4.7689 - acc: 0.0167 - val_loss: 4.7771 - val_acc: 0.0141\n",
      "Epoch 13/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7575 - acc: 0.0188Epoch 00013: loss improved from 4.76888 to 4.75760, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 578s 2s/step - loss: 4.7576 - acc: 0.0187 - val_loss: 4.7755 - val_acc: 0.0131\n",
      "Epoch 14/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7546 - acc: 0.0187Epoch 00014: loss improved from 4.75760 to 4.75450, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 571s 2s/step - loss: 4.7545 - acc: 0.0187 - val_loss: 4.7731 - val_acc: 0.0143\n",
      "Epoch 15/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7518 - acc: 0.0191Epoch 00015: loss improved from 4.75450 to 4.75205, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 568s 2s/step - loss: 4.7521 - acc: 0.0190 - val_loss: 4.7636 - val_acc: 0.0157\n",
      "Epoch 16/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7369 - acc: 0.0219Epoch 00016: loss improved from 4.75205 to 4.73672, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 578s 2s/step - loss: 4.7367 - acc: 0.0219 - val_loss: 4.7565 - val_acc: 0.0144\n",
      "Epoch 17/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7303 - acc: 0.0208Epoch 00017: loss improved from 4.73672 to 4.73019, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 570s 2s/step - loss: 4.7302 - acc: 0.0208 - val_loss: 4.7505 - val_acc: 0.0153\n",
      "Epoch 18/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7154 - acc: 0.0243Epoch 00018: loss improved from 4.73019 to 4.71583, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 568s 2s/step - loss: 4.7158 - acc: 0.0242 - val_loss: 4.7336 - val_acc: 0.0153\n",
      "Epoch 19/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.7017 - acc: 0.0250Epoch 00019: loss improved from 4.71583 to 4.70155, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 570s 2s/step - loss: 4.7015 - acc: 0.0251 - val_loss: 4.7106 - val_acc: 0.0164\n",
      "Epoch 20/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.6758 - acc: 0.0247Epoch 00020: loss improved from 4.70155 to 4.67629, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 571s 2s/step - loss: 4.6763 - acc: 0.0246 - val_loss: 4.7046 - val_acc: 0.0174\n",
      "Epoch 21/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.6494 - acc: 0.0256Epoch 00021: loss improved from 4.67629 to 4.64976, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 568s 2s/step - loss: 4.6498 - acc: 0.0256 - val_loss: 4.6466 - val_acc: 0.0202\n",
      "Epoch 22/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.6125 - acc: 0.0311Epoch 00022: loss improved from 4.64976 to 4.61225, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 568s 2s/step - loss: 4.6122 - acc: 0.0310 - val_loss: 4.6028 - val_acc: 0.0235\n",
      "Epoch 23/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.5684 - acc: 0.0301Epoch 00023: loss improved from 4.61225 to 4.56808, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 569s 2s/step - loss: 4.5681 - acc: 0.0303 - val_loss: 4.5368 - val_acc: 0.0247\n",
      "Epoch 24/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.5091 - acc: 0.0342Epoch 00024: loss improved from 4.56808 to 4.50915, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 568s 2s/step - loss: 4.5091 - acc: 0.0341 - val_loss: 4.4930 - val_acc: 0.0278\n",
      "Epoch 25/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.4756 - acc: 0.0356Epoch 00025: loss improved from 4.50915 to 4.47539, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 568s 2s/step - loss: 4.4754 - acc: 0.0355 - val_loss: 4.4202 - val_acc: 0.0295\n",
      "Epoch 26/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.4193 - acc: 0.0393Epoch 00026: loss improved from 4.47539 to 4.41919, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 570s 2s/step - loss: 4.4192 - acc: 0.0394 - val_loss: 4.3641 - val_acc: 0.0354\n",
      "Epoch 27/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.3643 - acc: 0.0464Epoch 00027: loss improved from 4.41919 to 4.36340, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 569s 2s/step - loss: 4.3634 - acc: 0.0465 - val_loss: 4.3003 - val_acc: 0.0394\n",
      "Epoch 28/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.2915 - acc: 0.0480Epoch 00028: loss improved from 4.36340 to 4.29151, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 570s 2s/step - loss: 4.2915 - acc: 0.0481 - val_loss: 4.2092 - val_acc: 0.0475\n",
      "Epoch 29/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.2250 - acc: 0.0534Epoch 00029: loss improved from 4.29151 to 4.22383, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 569s 2s/step - loss: 4.2239 - acc: 0.0538 - val_loss: 4.1423 - val_acc: 0.0502\n",
      "Epoch 30/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.1492 - acc: 0.0591Epoch 00030: loss improved from 4.22383 to 4.14855, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 567s 2s/step - loss: 4.1486 - acc: 0.0591 - val_loss: 4.0625 - val_acc: 0.0661\n",
      "Epoch 31/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 4.0576 - acc: 0.0708Epoch 00031: loss improved from 4.14855 to 4.05782, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 572s 2s/step - loss: 4.0578 - acc: 0.0707 - val_loss: 3.9635 - val_acc: 0.0755\n",
      "Epoch 32/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 3.9958 - acc: 0.0771Epoch 00032: loss improved from 4.05782 to 3.99547, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 569s 2s/step - loss: 3.9955 - acc: 0.0772 - val_loss: 3.9387 - val_acc: 0.0727\n",
      "Epoch 33/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 3.9148 - acc: 0.0808Epoch 00033: loss improved from 3.99547 to 3.91508, saving model to vgg19_1.h5\n",
      "281/281 [==============================] - 568s 2s/step - loss: 3.9151 - acc: 0.0808 - val_loss: 3.8101 - val_acc: 0.0870\n",
      "Epoch 34/50\n",
      "280/281 [============================>.] - ETA: 0s - loss: 3.8422 - acc: 0.0939"
     ]
    }
   ],
   "source": [
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = nb_train_samples,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "nb_val_samples = nb_validation_samples,\n",
    "callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "# # fits the model on batches with real-time data augmentation:\n",
    "# model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "#                     steps_per_epoch=len(x_train) / 32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for e in range(epochs):\n",
    "#     print('Epoch', e)\n",
    "#     batches = 0\n",
    "#     for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "#         model.fit(x_batch, y_batch)\n",
    "#         batches += 1\n",
    "#         if batches >= len(x_train) / 32:\n",
    "#             # we need to break the loop by hand because\n",
    "#             # the generator loops indefinitely\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse Model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda501\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 256, 256\n",
    "test_data_dir = \"test/resized\"\n",
    "nb_test_samples = 10357\n",
    "batch_size = 1\n",
    "latest_save = \"vgg19.16.h5\"\n",
    "steps = nb_test_samples//batch_size+1\n",
    "\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(120, activation=\"softmax\")(x)\n",
    "\n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "model_final.load_weights(latest_save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir, target_size = (img_height, img_width), class_mode = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_final.predict_generator(test_generator, steps=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
