{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiLabel Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=3mHy4OSyRf0 à 17min19\n",
    "# https://stackoverflow.com/questions/15880133/jensen-shannon-divergence\n",
    "\n",
    "def JS_Divergence(P, Q):\n",
    "    _P = P / np.linalg.norm(P, ord=1)\n",
    "    _Q = Q / np.linalg.norm(Q, ord=1)\n",
    "    _M = 0.5 * (_P + _Q)\n",
    "    return 0.5 * (entropy(_P, _M) + entropy(_Q, _M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_obj(\"datas/X_train\")\n",
    "X_test = load_obj(\"datas/X_test\")\n",
    "\n",
    "taglist = load_obj(\"datas/taglist\")\n",
    "\n",
    "y_train_clean = load_obj(\"datas/y_train\")\n",
    "y_test_clean = load_obj(\"datas/y_test\")\n",
    "\n",
    "mlb = joblib.load(\"models/MultiLabelBinarizer\")\n",
    "y_train = mlb.transform(y_train_clean)\n",
    "y_test = mlb.transform(y_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparation de la tfidf de test\n",
    "\n",
    "# tfidf = joblib.load(\"models/TfidfVectorizer\")  # chargement du tfidf trained sur le train set\n",
    "# tfidfMatrix_test = tfidf.transform(X_test)\n",
    "# save_npz('datas/tfidfMatrix_test.npz', tfidfMatrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfMatrix = load_npz('datas/tfidfMatrix.npz')             # on a deja le test set de calculé precedemment\n",
    "tfidfMatrix_test = load_npz('datas/tfidfMatrix_test.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ere evaluation des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# autre que http://scikit-learn.org/stable/modules/model_evaluation.html#multilabel-ranking-metrics\n",
    "\n",
    "def to_index(matrix):\n",
    "    matrix = matrix.tolist()\n",
    "    result = []\n",
    "    for row in matrix:\n",
    "        r = []\n",
    "        for index, col in enumerate(row):\n",
    "            if col == 1:\n",
    "                r.append(index)\n",
    "        result.append(r)\n",
    "    return result\n",
    "\n",
    "def score_custom(y_true, y_pred, nb_elem=5):\n",
    "    sum_score = 0\n",
    "    y_pred = np.argsort(y_pred, axis=1)[:, -nb_elem:]\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        intersection = len(np.intersect1d(y_pred[i], y_true[i]))\n",
    "        nb_choice = len(y_true[i])\n",
    "        sum_score += intersection/nb_choice\n",
    "    return sum_score/y_pred.shape[0]\n",
    "\n",
    "y_test_index = to_index(y_test)\n",
    "y_train_index = to_index(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass avec OVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score =  0.6268096311461413\n",
      "test_score =  0.6057808982742091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "mdl = SGDClassifier(loss=\"log\", max_iter=5, tol=None)\n",
    "ovr = OneVsRestClassifier(mdl)\n",
    "ovr.fit(tfidfMatrix, y_train)\n",
    "\n",
    "proba_train = ovr.predict_proba(tfidfMatrix)\n",
    "proba_test = ovr.predict_proba(tfidfMatrix_test)\n",
    "\n",
    "print(\"train_score = \", score_custom(y_train_index, proba_train))\n",
    "print(\"test_score = \", score_custom(y_test_index, proba_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# mdl = SGDClassifier(loss=\"log\", max_iter=5, tol=None)\n",
    "# ens = AdaBoostClassifier(n_estimators=5)\n",
    "# ovr = OneVsRestClassifier(ens)\n",
    "# ovr.fit(tfidfMatrix, y_train)\n",
    "\n",
    "# proba_train = ovr.predict_proba(tfidfMatrix)\n",
    "# proba_test = ovr.predict_proba(tfidfMatrix_test)\n",
    "\n",
    "# print(\"train_score = \", score_custom(y_train_index, proba_train))\n",
    "# print(\"test_score = \", score_custom(y_test_index, proba_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Très très lent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# mdl = GradientBoostingClassifier(loss=\"deviance\", n_estimators=10, max_depth=3)\n",
    "# ovr = OneVsRestClassifier(mdl)\n",
    "# ovr.fit(tfidfMatrix, y_train)\n",
    "\n",
    "# proba_train = ovr.predict_proba(tfidfMatrix)\n",
    "# proba_test = ovr.predict_proba(tfidfMatrix_test)\n",
    "\n",
    "# print(\"train_score = \", score_custom(y_train_index, proba_train))\n",
    "# print(\"test_score = \", score_custom(y_test_index, proba_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraine des arbres de decision (tres tres lent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "# mdl = GaussianProcessClassifier(multi_class=\"one_vs_rest\", n_jobs = -1)\n",
    "# ovr = OneVsRestClassifier(mdl)\n",
    "# ovr.fit(tfidfMatrix, y_train)\n",
    "\n",
    "# proba_train = ovr.predict_proba(tfidfMatrix)\n",
    "# proba_test = ovr.predict_proba(tfidfMatrix_test)\n",
    "\n",
    "# print(\"train_score = \", score_custom(y_train_index, proba_train))\n",
    "# print(\"test_score = \", score_custom(y_test_index, proba_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessite des matrices non sparse => Memory Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=13, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "mdl = ExtraTreesClassifier(n_estimators=20, max_depth=13)\n",
    "mdl.fit(tfidfMatrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = mdl.predict_proba(tfidfMatrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99859832,  0.00140168],\n",
       "       [ 0.99805606,  0.00194394],\n",
       "       [ 0.99897252,  0.00102748],\n",
       "       ..., \n",
       "       [ 0.99875011,  0.00124989],\n",
       "       [ 0.99859832,  0.00140168],\n",
       "       [ 0.99890041,  0.00109959]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba[22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prediction est tj proche de 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=13, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mdl = RandomForestClassifier(n_estimators=20, max_depth=13)\n",
    "mdl.fit(tfidfMatrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = mdl.predict_proba(tfidfMatrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99036105e-01,   9.63895235e-04],\n",
       "       [  9.99279174e-01,   7.20825757e-04],\n",
       "       [  9.99612224e-01,   3.87776437e-04],\n",
       "       ..., \n",
       "       [  9.99115480e-01,   8.84520323e-04],\n",
       "       [  9.99075808e-01,   9.24192488e-04],\n",
       "       [  9.98936830e-01,   1.06317025e-03]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prediction est tj proche de 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score =  0.8205158163933511\n",
      "test_score =  0.6889105656197734\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mdl = MLPClassifier(hidden_layer_sizes=(200, 100), early_stopping=True)\n",
    "mdl.fit(tfidfMatrix, y_train)\n",
    "\n",
    "proba_train = mdl.predict_proba(tfidfMatrix)\n",
    "proba_test = mdl.predict_proba(tfidfMatrix_test)\n",
    "\n",
    "print(\"train_score = \", score_custom(y_train_index, proba_train))\n",
    "print(\"test_score = \", score_custom(y_test_index, proba_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Attention</b>, cette precision n'est peut-être pas tres accurate car on a 3000 features (col_tfidf) en entrée et 773 en sorties (nb_classes). De ce fait, le MLP a 3000 layer puis 200 puis 100 puis 773. On perd beacoup d'information a cause des hidden layers. Cependant, au vu du resultat une évalusation sera faite avec Keras (plus rapide car sur GPU) par la suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# mdl = KNeighborsClassifier(n_neighbors=5, metric=JS_Divergence)\n",
    "# mdl.fit(tfidfMatrix.todense(), y_train)\n",
    "\n",
    "# proba_train = ovr.predict_proba(tfidfMatrix.todense())\n",
    "# proba_test = ovr.predict_proba(tfidfMatrix_test.todense())\n",
    "\n",
    "# print(\"train_score = \", score_custom(y_train_index, proba_train))\n",
    "# print(\"test_score = \", score_custom(y_test_index, proba_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB car il faut des marices denses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "# mdl = RidgeClassifierCV()\n",
    "# mdl.fit(tfidfMatrix, y_train)\n",
    "\n",
    "# proba = mdl.predict(tfidfMatrix_test)\n",
    "# print(score_custom(y_index, proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB car modele lienaire avec inversion de X*tX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'log', 'max_iter': 10, 'n_jobs': -1, 'penalty': None, 'tol': 0.001}\n",
      "train_score =  0.7745893390133173\n",
      "test_score =  0.7068510379819415 \n",
      "\n",
      "{'loss': 'log', 'max_iter': 10, 'n_jobs': -1, 'penalty': 'l1', 'tol': 0.001}\n",
      "train_score =  0.6661014261982294\n",
      "test_score =  0.6609254296637892 \n",
      "\n",
      "{'loss': 'log', 'max_iter': 10, 'n_jobs': -1, 'penalty': 'l2', 'tol': 0.001}\n",
      "train_score =  0.6315917723046102\n",
      "test_score =  0.6101582877764785 \n",
      "\n",
      "{'loss': 'log', 'max_iter': 20, 'n_jobs': -1, 'penalty': None, 'tol': 0.001}\n",
      "train_score =  0.7753182924223373\n",
      "test_score =  0.706694894057977 \n",
      "\n",
      "{'loss': 'log', 'max_iter': 20, 'n_jobs': -1, 'penalty': 'l1', 'tol': 0.001}\n",
      "train_score =  0.6642151084641562\n",
      "test_score =  0.6597823989709679 \n",
      "\n",
      "{'loss': 'log', 'max_iter': 20, 'n_jobs': -1, 'penalty': 'l2', 'tol': 0.001}\n",
      "train_score =  0.6308397267544997\n",
      "test_score =  0.6092982456140463 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "parameters = {\n",
    "    \"loss\": [\"log\"],\n",
    "    \"max_iter\": [10, 20],\n",
    "    \"tol\":[1e-3],\n",
    "    \"tol\":[1e-3],\n",
    "    \"n_jobs\":[-1],\n",
    "    \"penalty\": [None, \"l1\", \"l2\"]\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(parameters):\n",
    "    print(params)\n",
    "    mdl = SGDClassifier(**params)\n",
    "    ovr = OneVsRestClassifier(mdl)\n",
    "    ovr.fit(tfidfMatrix, y_train)\n",
    "    \n",
    "    proba_train = ovr.predict_proba(tfidfMatrix)\n",
    "    proba_test = ovr.predict_proba(tfidfMatrix_test)\n",
    "\n",
    "    print(\"train_score = \", score_custom(y_train_index, proba_train))\n",
    "    print(\"test_score = \", score_custom(y_test_index, proba_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les régularisation diminue le score mais rapproche le train et test set au niveau des resultats. Au final la regualrisation permet de mieux généraliser mais avec de moins bons resultats. Le nombre d'iteration n'aide pas particulierement a partir de 10 itérations. On va garder pour l'API le modèle linéaire sans régularisation car le test set reste plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'identity', 'early_stopping': True, 'hidden_layer_sizes': 2000, 'validation_fraction': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "parameters = {\n",
    "    \"early_stopping\": [True],\n",
    "    \"hidden_layer_sizes\": [(2000), (2000, 1000), (200, 100)],\n",
    "    \"validation_fraction\":[0.1],\n",
    "    \"activation\":[\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(parameters):\n",
    "    print(params)\n",
    "    mdl = MLPClassifier(**params)\n",
    "    mdl.fit(tfidfMatrix, y_train)\n",
    "\n",
    "    proba = mdl.predict_proba(tfidfMatrix_test)\n",
    "    print(score_custom(y_index, proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "nb_input = tfidfMatrix_test.shape[1]\n",
    "nb_output = y_test.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1500, input_shape=(nb_input,)))\n",
    "model.add(Dense(nb_output, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='Nadam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[\"top_k_categorical_accuracy\"])\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38685 samples, validate on 9672 samples\n",
      "Epoch 1/20\n",
      "38685/38685 [==============================] - 5s 122us/step - loss: 0.0292 - top_k_categorical_accuracy: 0.3563 - val_loss: 0.0134 - val_top_k_categorical_accuracy: 0.5505\n",
      "Epoch 2/20\n",
      "38685/38685 [==============================] - 4s 116us/step - loss: 0.0110 - top_k_categorical_accuracy: 0.6424 - val_loss: 0.0097 - val_top_k_categorical_accuracy: 0.6947\n",
      "Epoch 3/20\n",
      "38685/38685 [==============================] - 4s 116us/step - loss: 0.0082 - top_k_categorical_accuracy: 0.7591 - val_loss: 0.0086 - val_top_k_categorical_accuracy: 0.7365\n",
      "Epoch 4/20\n",
      "38685/38685 [==============================] - 5s 117us/step - loss: 0.0069 - top_k_categorical_accuracy: 0.8128 - val_loss: 0.0083 - val_top_k_categorical_accuracy: 0.7451\n",
      "Epoch 5/20\n",
      "38685/38685 [==============================] - 4s 116us/step - loss: 0.0060 - top_k_categorical_accuracy: 0.8514 - val_loss: 0.0084 - val_top_k_categorical_accuracy: 0.7447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x239040b4cc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tfidfMatrix.todense(), y=y_train, batch_size=100, epochs=20, validation_split=0.2, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('my_model.h5')\n",
    "proba_train = model.predict(tfidfMatrix.todense(), batch_size=1000)\n",
    "proba_test = model.predict(tfidfMatrix_test.todense(), batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score =  0.8602663523377974\n",
      "test_score =  0.7215771608246868 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"train_score = \", score_custom(y_train_index, proba_train))\n",
    "print(\"test_score = \", score_custom(y_test_index, proba_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting malgré early stop ? Par contre meilleur perf mais impossible à passer en prod :("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
