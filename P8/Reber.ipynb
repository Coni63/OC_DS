{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REBER Grammar with RNN\n",
    "\n",
    "In this workbook, we are going to set-up multiple Recurrent Neural Network to test them using as test <a href=\"https://www.willamette.edu/~gorr/classes/cs449/reber.html\" target=\"_blank\">Reber's grammar</a> words.\n",
    "\n",
    "## What is a Reber Word ?\n",
    "\n",
    "A Reber word is a word following the Reber's grammar. The grammar is based on the following graph:\n",
    "\n",
    "<img src=\"reber.gif\"/>\n",
    "\n",
    "The word must start with B, then it can be either T or P and so on until it reaches E. To prepare datas for this, we are going to use a OneHotEncoder to have 7 inputs, n timesteps (depending on the length of the word) and k batches. To generate it, I use the algorith from <a href=\"http://christianherta.de/lehre/dataScience/machineLearning/neuralNetworks/reberGrammar.php\" target=\"_target\">this site</a> but slightly modified to be able to validate also embedded Word\n",
    "\n",
    "The Embedded version of the Reber Grammar using the following graph :\n",
    "\n",
    "<img src=\"embreber.gif\"/>\n",
    "\n",
    "Due to current technologies, we will focus on Embedded Word (both system tried below with Simple Reber Word reaches 100% success and cannot be compared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "import create_dataset as reber\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of datas\n",
    "\n",
    "For the OneHotEncoder, the chain 'BTSXPVE' will be used. We can now try only 1 example to check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBTXXTTTTTTTTVPXVPXTVPXVVET\n",
      "[ 1.  0.  0.  0.  0.  0.  0.] [ 0.  1.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "x, y = reber.get_one_embedded_example(minLength=10)\n",
    "print(reber.sequenceToWord(x))\n",
    "print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*y* is the possible outcome for a given input. That means B ([ 1.  0.  0.  0.  0.  0.  0.]) can be followed by T or P ([ 0.  1.  0.  0.  1.  0.  0.]).\n",
    "\n",
    "However, we won't use y as output but for every timestep, we are going to provide the next timestep as target. For this, we will use the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(x0):\n",
    "    end = np.array([0.,  0.,  0.,  0.,  0.,  0.,  1.])\n",
    "    y=x0[1:]\n",
    "    y.append(end)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we take as input \"BTSXS\", the output will be \"TSXSE\" (but the input in encoded).\n",
    "\n",
    "We can also generate few words to check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "33\n",
      "31\n",
      "29\n",
      "36\n",
      "29\n",
      "34\n",
      "33\n",
      "36\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "min_length = 25\n",
    "for i in range(10):\n",
    "    inp, out = reber.get_one_embedded_example(min_length)\n",
    "#     print(reber.sequenceToWord(inp))\n",
    "    print(len(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have the first \"problem\" now, the length of the string is variable. So when we are going to generate our test/train datas, we will have to pad them to the same length (let's say 20). This is done by using <b>sequence.pad_sequences</b> for Keras Library. The padding will be done as \"post\" to improve accuracy. Using a \"pre\" padding reduce accuracy because the cell doesn't know how many times it will receive 0 instead of \"E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 53, 7)\n",
      "(2048, 53, 7)\n",
      "(256, 53, 7)\n",
      "(256, 53, 7)\n",
      "(1, 53, 7)\n",
      "(1, 53, 7)\n",
      "(1, 53, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "X_val, y_val = [], []\n",
    "y_possible = []\n",
    "\n",
    "maxlen = 0\n",
    "for i in range(2048):\n",
    "    x, y = reber.get_one_embedded_example(min_length)\n",
    "    X_train.append(x)\n",
    "    y_train.append(generate(x))\n",
    "    maxlen = max(maxlen, len(x))\n",
    "\n",
    "for i in range(256):\n",
    "    x, y = reber.get_one_embedded_example(min_length)\n",
    "    X_test.append(x)\n",
    "    y_test.append(generate(x))\n",
    "    maxlen = max(maxlen, len(x))\n",
    "    \n",
    "for i in range(1):\n",
    "    x, y = reber.get_one_embedded_example(min_length)\n",
    "    X_val.append(x)\n",
    "    y_val.append(generate(x))\n",
    "    y_possible.append(y)\n",
    "    maxlen = max(maxlen, len(x))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "y_possible = np.array(y_possible)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_train = sequence.pad_sequences(y_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_test = sequence.pad_sequences(y_test, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_val = sequence.pad_sequences(y_val, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_possible = sequence.pad_sequences(y_possible, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(y_possible.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1 0 0 1 0 0]\n",
      "  [1 0 0 0 0 0 0]\n",
      "  [0 1 0 0 1 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 1 1 0 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 1 1 0 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(y_possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have 2048 strings for training, 256 for test and 1 just for visualisation later. We can now set-up our model.\n",
    "\n",
    "## Test of RNNs\n",
    "\n",
    "For this model, we are going to use a many-to-many RNN. That means for every input, the model will predict an output. The training will be done based on the input we prepared previously. Once trained. We will be able to \"transfer\" the learning to a one-to-many model in order to have a \"generator\".\n",
    "\n",
    "<img src=\"RNN_types.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we expect is a probability of having this or this letter. The problem is a multi-class classifier. As a reult, the loss function will be the categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_unit = 7\n",
    "inp_shape = (maxlen, 7)\n",
    "loss_ = \"categorical_crossentropy\"\n",
    "metrics_ = \"categorical_crossentropy\"\n",
    "optimizer_ = \"Nadam\"\n",
    "nb_epoch = 250\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "The first model we will setup is an <b>LSTM</b> which means <b>L</b>ong <b>S</b>hort-<b>T</b>erm <b>M</b>emory. The principle is \n",
    "quite complex but very powerfull for long sequences inputs (because there is less issues with Vanishing Gradient Problem) or long term memory (You can refer to <a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\" target=\"_blank\">this link</a> for more informations)\n",
    "\n",
    "LSTM is widely for speech recognition, Natural Language processing, Sentiment Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=nb_unit, \n",
    "               input_shape=inp_shape, \n",
    "               return_sequences=True))  # single LSTM\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"lstm_simple.h5\",\n",
    "    monitor=loss_,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: (None, 53, 7)\n",
      "Outputs: (None, 53, 7)\n",
      "Actual input: (2048, 53, 7)\n",
      "Actual output: (2048, 53, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs: {}\".format(model.input_shape))\n",
    "print(\"Outputs: {}\".format(model.output_shape))\n",
    "print(\"Actual input: {}\".format(X_train.shape))\n",
    "print(\"Actual output: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 256 samples\n",
      "Epoch 1/250\n",
      "Epoch 00001: categorical_crossentropy improved from inf to 1.11962, saving model to lstm_simple.h5\n",
      " - 4s - loss: 1.1196 - categorical_crossentropy: 1.1196 - val_loss: 1.0798 - val_categorical_crossentropy: 1.0798\n",
      "Epoch 2/250\n",
      "Epoch 00002: categorical_crossentropy improved from 1.11962 to 1.03148, saving model to lstm_simple.h5\n",
      " - 2s - loss: 1.0315 - categorical_crossentropy: 1.0315 - val_loss: 0.9863 - val_categorical_crossentropy: 0.9863\n",
      "Epoch 3/250\n",
      "Epoch 00003: categorical_crossentropy improved from 1.03148 to 0.96066, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.9607 - categorical_crossentropy: 0.9607 - val_loss: 0.9199 - val_categorical_crossentropy: 0.9199\n",
      "Epoch 4/250\n",
      "Epoch 00004: categorical_crossentropy improved from 0.96066 to 0.88719, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.8872 - categorical_crossentropy: 0.8872 - val_loss: 0.8533 - val_categorical_crossentropy: 0.8533\n",
      "Epoch 5/250\n",
      "Epoch 00005: categorical_crossentropy improved from 0.88719 to 0.81990, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.8199 - categorical_crossentropy: 0.8199 - val_loss: 0.7823 - val_categorical_crossentropy: 0.7823\n",
      "Epoch 6/250\n",
      "Epoch 00006: categorical_crossentropy improved from 0.81990 to 0.76207, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.7621 - categorical_crossentropy: 0.7621 - val_loss: 0.7282 - val_categorical_crossentropy: 0.7282\n",
      "Epoch 7/250\n",
      "Epoch 00007: categorical_crossentropy improved from 0.76207 to 0.70897, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.7090 - categorical_crossentropy: 0.7090 - val_loss: 0.6795 - val_categorical_crossentropy: 0.6795\n",
      "Epoch 8/250\n",
      "Epoch 00008: categorical_crossentropy improved from 0.70897 to 0.66421, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.6642 - categorical_crossentropy: 0.6642 - val_loss: 0.6475 - val_categorical_crossentropy: 0.6475\n",
      "Epoch 9/250\n",
      "Epoch 00009: categorical_crossentropy improved from 0.66421 to 0.62662, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.6266 - categorical_crossentropy: 0.6266 - val_loss: 0.6062 - val_categorical_crossentropy: 0.6062\n",
      "Epoch 10/250\n",
      "Epoch 00010: categorical_crossentropy improved from 0.62662 to 0.59196, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5920 - categorical_crossentropy: 0.5920 - val_loss: 0.5771 - val_categorical_crossentropy: 0.5771\n",
      "Epoch 11/250\n",
      "Epoch 00011: categorical_crossentropy improved from 0.59196 to 0.56125, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5613 - categorical_crossentropy: 0.5613 - val_loss: 0.5462 - val_categorical_crossentropy: 0.5462\n",
      "Epoch 12/250\n",
      "Epoch 00012: categorical_crossentropy improved from 0.56125 to 0.53488, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5349 - categorical_crossentropy: 0.5349 - val_loss: 0.5215 - val_categorical_crossentropy: 0.5215\n",
      "Epoch 13/250\n",
      "Epoch 00013: categorical_crossentropy improved from 0.53488 to 0.51243, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5124 - categorical_crossentropy: 0.5124 - val_loss: 0.5005 - val_categorical_crossentropy: 0.5005\n",
      "Epoch 14/250\n",
      "Epoch 00014: categorical_crossentropy improved from 0.51243 to 0.49046, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4905 - categorical_crossentropy: 0.4905 - val_loss: 0.4809 - val_categorical_crossentropy: 0.4809\n",
      "Epoch 15/250\n",
      "Epoch 00015: categorical_crossentropy improved from 0.49046 to 0.47170, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4717 - categorical_crossentropy: 0.4717 - val_loss: 0.4650 - val_categorical_crossentropy: 0.4650\n",
      "Epoch 16/250\n",
      "Epoch 00016: categorical_crossentropy improved from 0.47170 to 0.45550, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4555 - categorical_crossentropy: 0.4555 - val_loss: 0.4466 - val_categorical_crossentropy: 0.4466\n",
      "Epoch 17/250\n",
      "Epoch 00017: categorical_crossentropy improved from 0.45550 to 0.43972, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4397 - categorical_crossentropy: 0.4397 - val_loss: 0.4337 - val_categorical_crossentropy: 0.4337\n",
      "Epoch 18/250\n",
      "Epoch 00018: categorical_crossentropy improved from 0.43972 to 0.42605, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4261 - categorical_crossentropy: 0.4261 - val_loss: 0.4198 - val_categorical_crossentropy: 0.4198\n",
      "Epoch 19/250\n",
      "Epoch 00019: categorical_crossentropy improved from 0.42605 to 0.41351, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4135 - categorical_crossentropy: 0.4135 - val_loss: 0.4081 - val_categorical_crossentropy: 0.4081\n",
      "Epoch 20/250\n",
      "Epoch 00020: categorical_crossentropy improved from 0.41351 to 0.40220, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4022 - categorical_crossentropy: 0.4022 - val_loss: 0.3975 - val_categorical_crossentropy: 0.3975\n",
      "Epoch 21/250\n",
      "Epoch 00021: categorical_crossentropy improved from 0.40220 to 0.39230, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3923 - categorical_crossentropy: 0.3923 - val_loss: 0.3884 - val_categorical_crossentropy: 0.3884\n",
      "Epoch 22/250\n",
      "Epoch 00022: categorical_crossentropy improved from 0.39230 to 0.38292, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3829 - categorical_crossentropy: 0.3829 - val_loss: 0.3792 - val_categorical_crossentropy: 0.3792\n",
      "Epoch 23/250\n",
      "Epoch 00023: categorical_crossentropy improved from 0.38292 to 0.37442, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3744 - categorical_crossentropy: 0.3744 - val_loss: 0.3714 - val_categorical_crossentropy: 0.3714\n",
      "Epoch 24/250\n",
      "Epoch 00024: categorical_crossentropy improved from 0.37442 to 0.36732, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3673 - categorical_crossentropy: 0.3673 - val_loss: 0.3644 - val_categorical_crossentropy: 0.3644\n",
      "Epoch 25/250\n",
      "Epoch 00025: categorical_crossentropy improved from 0.36732 to 0.36002, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3600 - categorical_crossentropy: 0.3600 - val_loss: 0.3582 - val_categorical_crossentropy: 0.3582\n",
      "Epoch 26/250\n",
      "Epoch 00026: categorical_crossentropy improved from 0.36002 to 0.35370, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3537 - categorical_crossentropy: 0.3537 - val_loss: 0.3521 - val_categorical_crossentropy: 0.3521\n",
      "Epoch 27/250\n",
      "Epoch 00027: categorical_crossentropy improved from 0.35370 to 0.34845, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3485 - categorical_crossentropy: 0.3485 - val_loss: 0.3465 - val_categorical_crossentropy: 0.3465\n",
      "Epoch 28/250\n",
      "Epoch 00028: categorical_crossentropy improved from 0.34845 to 0.34310, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3431 - categorical_crossentropy: 0.3431 - val_loss: 0.3413 - val_categorical_crossentropy: 0.3413\n",
      "Epoch 29/250\n",
      "Epoch 00029: categorical_crossentropy improved from 0.34310 to 0.33832, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3383 - categorical_crossentropy: 0.3383 - val_loss: 0.3368 - val_categorical_crossentropy: 0.3368\n",
      "Epoch 30/250\n",
      "Epoch 00030: categorical_crossentropy improved from 0.33832 to 0.33394, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3339 - categorical_crossentropy: 0.3339 - val_loss: 0.3340 - val_categorical_crossentropy: 0.3340\n",
      "Epoch 31/250\n",
      "Epoch 00031: categorical_crossentropy improved from 0.33394 to 0.33033, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3303 - categorical_crossentropy: 0.3303 - val_loss: 0.3288 - val_categorical_crossentropy: 0.3288\n",
      "Epoch 32/250\n",
      "Epoch 00032: categorical_crossentropy improved from 0.33033 to 0.32650, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3265 - categorical_crossentropy: 0.3265 - val_loss: 0.3250 - val_categorical_crossentropy: 0.3250\n",
      "Epoch 33/250\n",
      "Epoch 00033: categorical_crossentropy improved from 0.32650 to 0.32285, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3229 - categorical_crossentropy: 0.3229 - val_loss: 0.3217 - val_categorical_crossentropy: 0.3217\n",
      "Epoch 34/250\n",
      "Epoch 00034: categorical_crossentropy improved from 0.32285 to 0.31959, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3196 - categorical_crossentropy: 0.3196 - val_loss: 0.3185 - val_categorical_crossentropy: 0.3185\n",
      "Epoch 35/250\n",
      "Epoch 00035: categorical_crossentropy improved from 0.31959 to 0.31650, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3165 - categorical_crossentropy: 0.3165 - val_loss: 0.3157 - val_categorical_crossentropy: 0.3157\n",
      "Epoch 36/250\n",
      "Epoch 00036: categorical_crossentropy improved from 0.31650 to 0.31395, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3139 - categorical_crossentropy: 0.3139 - val_loss: 0.3154 - val_categorical_crossentropy: 0.3154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "Epoch 00037: categorical_crossentropy improved from 0.31395 to 0.31076, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3108 - categorical_crossentropy: 0.3108 - val_loss: 0.3102 - val_categorical_crossentropy: 0.3102\n",
      "Epoch 38/250\n",
      "Epoch 00038: categorical_crossentropy improved from 0.31076 to 0.30848, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3085 - categorical_crossentropy: 0.3085 - val_loss: 0.3075 - val_categorical_crossentropy: 0.3075\n",
      "Epoch 39/250\n",
      "Epoch 00039: categorical_crossentropy improved from 0.30848 to 0.30615, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3062 - categorical_crossentropy: 0.3062 - val_loss: 0.3085 - val_categorical_crossentropy: 0.3085\n",
      "Epoch 40/250\n",
      "Epoch 00040: categorical_crossentropy improved from 0.30615 to 0.30394, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3039 - categorical_crossentropy: 0.3039 - val_loss: 0.3030 - val_categorical_crossentropy: 0.3030\n",
      "Epoch 41/250\n",
      "Epoch 00041: categorical_crossentropy improved from 0.30394 to 0.30195, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3020 - categorical_crossentropy: 0.3020 - val_loss: 0.3016 - val_categorical_crossentropy: 0.3016\n",
      "Epoch 42/250\n",
      "Epoch 00042: categorical_crossentropy improved from 0.30195 to 0.29986, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2999 - categorical_crossentropy: 0.2999 - val_loss: 0.3004 - val_categorical_crossentropy: 0.3004\n",
      "Epoch 43/250\n",
      "Epoch 00043: categorical_crossentropy improved from 0.29986 to 0.29785, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2979 - categorical_crossentropy: 0.2979 - val_loss: 0.2996 - val_categorical_crossentropy: 0.2996\n",
      "Epoch 44/250\n",
      "Epoch 00044: categorical_crossentropy improved from 0.29785 to 0.29695, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2969 - categorical_crossentropy: 0.2969 - val_loss: 0.2958 - val_categorical_crossentropy: 0.2958\n",
      "Epoch 45/250\n",
      "Epoch 00045: categorical_crossentropy improved from 0.29695 to 0.29522, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2952 - categorical_crossentropy: 0.2952 - val_loss: 0.2949 - val_categorical_crossentropy: 0.2949\n",
      "Epoch 46/250\n",
      "Epoch 00046: categorical_crossentropy improved from 0.29522 to 0.29297, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2930 - categorical_crossentropy: 0.2930 - val_loss: 0.2988 - val_categorical_crossentropy: 0.2988\n",
      "Epoch 47/250\n",
      "Epoch 00047: categorical_crossentropy improved from 0.29297 to 0.29201, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2920 - categorical_crossentropy: 0.2920 - val_loss: 0.2915 - val_categorical_crossentropy: 0.2915\n",
      "Epoch 48/250\n",
      "Epoch 00048: categorical_crossentropy improved from 0.29201 to 0.29067, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2907 - categorical_crossentropy: 0.2907 - val_loss: 0.2898 - val_categorical_crossentropy: 0.2898\n",
      "Epoch 49/250\n",
      "Epoch 00049: categorical_crossentropy improved from 0.29067 to 0.28902, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2890 - categorical_crossentropy: 0.2890 - val_loss: 0.2888 - val_categorical_crossentropy: 0.2888\n",
      "Epoch 50/250\n",
      "Epoch 00050: categorical_crossentropy improved from 0.28902 to 0.28774, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2877 - categorical_crossentropy: 0.2877 - val_loss: 0.2896 - val_categorical_crossentropy: 0.2896\n",
      "Epoch 51/250\n",
      "Epoch 00051: categorical_crossentropy improved from 0.28774 to 0.28676, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2868 - categorical_crossentropy: 0.2868 - val_loss: 0.2866 - val_categorical_crossentropy: 0.2866\n",
      "Epoch 52/250\n",
      "Epoch 00052: categorical_crossentropy improved from 0.28676 to 0.28560, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2856 - categorical_crossentropy: 0.2856 - val_loss: 0.2853 - val_categorical_crossentropy: 0.2853\n",
      "Epoch 53/250\n",
      "Epoch 00053: categorical_crossentropy improved from 0.28560 to 0.28421, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2842 - categorical_crossentropy: 0.2842 - val_loss: 0.2845 - val_categorical_crossentropy: 0.2845\n",
      "Epoch 54/250\n",
      "Epoch 00054: categorical_crossentropy improved from 0.28421 to 0.28342, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2834 - categorical_crossentropy: 0.2834 - val_loss: 0.2831 - val_categorical_crossentropy: 0.2831\n",
      "Epoch 55/250\n",
      "Epoch 00055: categorical_crossentropy improved from 0.28342 to 0.28252, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2825 - categorical_crossentropy: 0.2825 - val_loss: 0.2869 - val_categorical_crossentropy: 0.2869\n",
      "Epoch 56/250\n",
      "Epoch 00056: categorical_crossentropy improved from 0.28252 to 0.28143, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2814 - categorical_crossentropy: 0.2814 - val_loss: 0.2870 - val_categorical_crossentropy: 0.2870\n",
      "Epoch 57/250\n",
      "Epoch 00057: categorical_crossentropy improved from 0.28143 to 0.28078, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2808 - categorical_crossentropy: 0.2808 - val_loss: 0.2815 - val_categorical_crossentropy: 0.2815\n",
      "Epoch 58/250\n",
      "Epoch 00058: categorical_crossentropy improved from 0.28078 to 0.27947, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2795 - categorical_crossentropy: 0.2795 - val_loss: 0.2832 - val_categorical_crossentropy: 0.2832\n",
      "Epoch 59/250\n",
      "Epoch 00059: categorical_crossentropy improved from 0.27947 to 0.27894, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2789 - categorical_crossentropy: 0.2789 - val_loss: 0.2857 - val_categorical_crossentropy: 0.2857\n",
      "Epoch 60/250\n",
      "Epoch 00060: categorical_crossentropy improved from 0.27894 to 0.27855, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2785 - categorical_crossentropy: 0.2785 - val_loss: 0.2779 - val_categorical_crossentropy: 0.2779\n",
      "Epoch 61/250\n",
      "Epoch 00061: categorical_crossentropy improved from 0.27855 to 0.27739, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2774 - categorical_crossentropy: 0.2774 - val_loss: 0.2776 - val_categorical_crossentropy: 0.2776\n",
      "Epoch 62/250\n",
      "Epoch 00062: categorical_crossentropy improved from 0.27739 to 0.27697, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2770 - categorical_crossentropy: 0.2770 - val_loss: 0.2769 - val_categorical_crossentropy: 0.2769\n",
      "Epoch 63/250\n",
      "Epoch 00063: categorical_crossentropy improved from 0.27697 to 0.27611, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2761 - categorical_crossentropy: 0.2761 - val_loss: 0.2759 - val_categorical_crossentropy: 0.2759\n",
      "Epoch 64/250\n",
      "Epoch 00064: categorical_crossentropy improved from 0.27611 to 0.27532, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2753 - categorical_crossentropy: 0.2753 - val_loss: 0.2774 - val_categorical_crossentropy: 0.2774\n",
      "Epoch 65/250\n",
      "Epoch 00065: categorical_crossentropy improved from 0.27532 to 0.27467, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2747 - categorical_crossentropy: 0.2747 - val_loss: 0.2751 - val_categorical_crossentropy: 0.2751\n",
      "Epoch 66/250\n",
      "Epoch 00066: categorical_crossentropy improved from 0.27467 to 0.27440, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2744 - categorical_crossentropy: 0.2744 - val_loss: 0.2744 - val_categorical_crossentropy: 0.2744\n",
      "Epoch 67/250\n",
      "Epoch 00067: categorical_crossentropy improved from 0.27440 to 0.27366, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2737 - categorical_crossentropy: 0.2737 - val_loss: 0.2744 - val_categorical_crossentropy: 0.2744\n",
      "Epoch 68/250\n",
      "Epoch 00068: categorical_crossentropy improved from 0.27366 to 0.27295, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2729 - categorical_crossentropy: 0.2729 - val_loss: 0.2738 - val_categorical_crossentropy: 0.2738\n",
      "Epoch 69/250\n",
      "Epoch 00069: categorical_crossentropy improved from 0.27295 to 0.27205, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2721 - categorical_crossentropy: 0.2721 - val_loss: 0.2732 - val_categorical_crossentropy: 0.2732\n",
      "Epoch 70/250\n",
      "Epoch 00070: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2724 - categorical_crossentropy: 0.2724 - val_loss: 0.2726 - val_categorical_crossentropy: 0.2726\n",
      "Epoch 71/250\n",
      "Epoch 00071: categorical_crossentropy improved from 0.27205 to 0.27141, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2714 - categorical_crossentropy: 0.2714 - val_loss: 0.2725 - val_categorical_crossentropy: 0.2725\n",
      "Epoch 72/250\n",
      "Epoch 00072: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2717 - categorical_crossentropy: 0.2717 - val_loss: 0.2714 - val_categorical_crossentropy: 0.2714\n",
      "Epoch 73/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00073: categorical_crossentropy improved from 0.27141 to 0.27054, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2705 - categorical_crossentropy: 0.2705 - val_loss: 0.2711 - val_categorical_crossentropy: 0.2711\n",
      "Epoch 74/250\n",
      "Epoch 00074: categorical_crossentropy improved from 0.27054 to 0.27052, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2705 - categorical_crossentropy: 0.2705 - val_loss: 0.2715 - val_categorical_crossentropy: 0.2715\n",
      "Epoch 75/250\n",
      "Epoch 00075: categorical_crossentropy improved from 0.27052 to 0.27017, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2702 - categorical_crossentropy: 0.2702 - val_loss: 0.2700 - val_categorical_crossentropy: 0.2700\n",
      "Epoch 76/250\n",
      "Epoch 00076: categorical_crossentropy improved from 0.27017 to 0.26907, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2691 - categorical_crossentropy: 0.2691 - val_loss: 0.2701 - val_categorical_crossentropy: 0.2701\n",
      "Epoch 77/250\n",
      "Epoch 00077: categorical_crossentropy improved from 0.26907 to 0.26883, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2688 - categorical_crossentropy: 0.2688 - val_loss: 0.2698 - val_categorical_crossentropy: 0.2698\n",
      "Epoch 78/250\n",
      "Epoch 00078: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2691 - categorical_crossentropy: 0.2691 - val_loss: 0.2692 - val_categorical_crossentropy: 0.2692\n",
      "Epoch 79/250\n",
      "Epoch 00079: categorical_crossentropy improved from 0.26883 to 0.26815, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2681 - categorical_crossentropy: 0.2681 - val_loss: 0.2715 - val_categorical_crossentropy: 0.2715\n",
      "Epoch 80/250\n",
      "Epoch 00080: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2685 - categorical_crossentropy: 0.2685 - val_loss: 0.2703 - val_categorical_crossentropy: 0.2703\n",
      "Epoch 81/250\n",
      "Epoch 00081: categorical_crossentropy improved from 0.26815 to 0.26736, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2674 - categorical_crossentropy: 0.2674 - val_loss: 0.2684 - val_categorical_crossentropy: 0.2684\n",
      "Epoch 82/250\n",
      "Epoch 00082: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2677 - categorical_crossentropy: 0.2677 - val_loss: 0.2680 - val_categorical_crossentropy: 0.2680\n",
      "Epoch 83/250\n",
      "Epoch 00083: categorical_crossentropy improved from 0.26736 to 0.26735, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2674 - categorical_crossentropy: 0.2674 - val_loss: 0.2681 - val_categorical_crossentropy: 0.2681\n",
      "Epoch 84/250\n",
      "Epoch 00084: categorical_crossentropy improved from 0.26735 to 0.26718, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2672 - categorical_crossentropy: 0.2672 - val_loss: 0.2711 - val_categorical_crossentropy: 0.2711\n",
      "Epoch 85/250\n",
      "Epoch 00085: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2679 - categorical_crossentropy: 0.2679 - val_loss: 0.2680 - val_categorical_crossentropy: 0.2680\n",
      "Epoch 86/250\n",
      "Epoch 00086: categorical_crossentropy improved from 0.26718 to 0.26662, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2666 - categorical_crossentropy: 0.2666 - val_loss: 0.2669 - val_categorical_crossentropy: 0.2669\n",
      "Epoch 87/250\n",
      "Epoch 00087: categorical_crossentropy improved from 0.26662 to 0.26597, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2660 - categorical_crossentropy: 0.2660 - val_loss: 0.2670 - val_categorical_crossentropy: 0.2670\n",
      "Epoch 88/250\n",
      "Epoch 00088: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2663 - categorical_crossentropy: 0.2663 - val_loss: 0.2665 - val_categorical_crossentropy: 0.2665\n",
      "Epoch 89/250\n",
      "Epoch 00089: categorical_crossentropy improved from 0.26597 to 0.26543, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2654 - categorical_crossentropy: 0.2654 - val_loss: 0.2675 - val_categorical_crossentropy: 0.2675\n",
      "Epoch 90/250\n",
      "Epoch 00090: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2657 - categorical_crossentropy: 0.2657 - val_loss: 0.2662 - val_categorical_crossentropy: 0.2662\n",
      "Epoch 91/250\n",
      "Epoch 00091: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2656 - categorical_crossentropy: 0.2656 - val_loss: 0.2660 - val_categorical_crossentropy: 0.2660\n",
      "Epoch 92/250\n",
      "Epoch 00092: categorical_crossentropy improved from 0.26543 to 0.26512, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2651 - categorical_crossentropy: 0.2651 - val_loss: 0.2659 - val_categorical_crossentropy: 0.2659\n",
      "Epoch 93/250\n",
      "Epoch 00093: categorical_crossentropy improved from 0.26512 to 0.26503, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2650 - categorical_crossentropy: 0.2650 - val_loss: 0.2675 - val_categorical_crossentropy: 0.2675\n",
      "Epoch 94/250\n",
      "Epoch 00094: categorical_crossentropy improved from 0.26503 to 0.26468, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2647 - categorical_crossentropy: 0.2647 - val_loss: 0.2711 - val_categorical_crossentropy: 0.2711\n",
      "Epoch 95/250\n",
      "Epoch 00095: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2647 - categorical_crossentropy: 0.2647 - val_loss: 0.2654 - val_categorical_crossentropy: 0.2654\n",
      "Epoch 96/250\n",
      "Epoch 00096: categorical_crossentropy improved from 0.26468 to 0.26437, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2644 - categorical_crossentropy: 0.2644 - val_loss: 0.2664 - val_categorical_crossentropy: 0.2664\n",
      "Epoch 97/250\n",
      "Epoch 00097: categorical_crossentropy improved from 0.26437 to 0.26417, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2642 - categorical_crossentropy: 0.2642 - val_loss: 0.2651 - val_categorical_crossentropy: 0.2651\n",
      "Epoch 98/250\n",
      "Epoch 00098: categorical_crossentropy improved from 0.26417 to 0.26377, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2638 - categorical_crossentropy: 0.2638 - val_loss: 0.2654 - val_categorical_crossentropy: 0.2654\n",
      "Epoch 99/250\n",
      "Epoch 00099: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2644 - categorical_crossentropy: 0.2644 - val_loss: 0.2646 - val_categorical_crossentropy: 0.2646\n",
      "Epoch 100/250\n",
      "Epoch 00100: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2639 - categorical_crossentropy: 0.2639 - val_loss: 0.2655 - val_categorical_crossentropy: 0.2655\n",
      "Epoch 101/250\n",
      "Epoch 00101: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2640 - categorical_crossentropy: 0.2640 - val_loss: 0.2644 - val_categorical_crossentropy: 0.2644\n",
      "Epoch 102/250\n",
      "Epoch 00102: categorical_crossentropy improved from 0.26377 to 0.26367, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2637 - categorical_crossentropy: 0.2637 - val_loss: 0.2641 - val_categorical_crossentropy: 0.2641\n",
      "Epoch 103/250\n",
      "Epoch 00103: categorical_crossentropy improved from 0.26367 to 0.26310, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2631 - categorical_crossentropy: 0.2631 - val_loss: 0.2642 - val_categorical_crossentropy: 0.2642\n",
      "Epoch 104/250\n",
      "Epoch 00104: categorical_crossentropy improved from 0.26310 to 0.26296, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2630 - categorical_crossentropy: 0.2630 - val_loss: 0.2642 - val_categorical_crossentropy: 0.2642\n",
      "Epoch 105/250\n",
      "Epoch 00105: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2630 - categorical_crossentropy: 0.2630 - val_loss: 0.2643 - val_categorical_crossentropy: 0.2643\n",
      "Epoch 106/250\n",
      "Epoch 00106: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2632 - categorical_crossentropy: 0.2632 - val_loss: 0.2643 - val_categorical_crossentropy: 0.2643\n",
      "Epoch 107/250\n",
      "Epoch 00107: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2630 - categorical_crossentropy: 0.2630 - val_loss: 0.2637 - val_categorical_crossentropy: 0.2637\n",
      "Epoch 108/250\n",
      "Epoch 00108: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2630 - categorical_crossentropy: 0.2630 - val_loss: 0.2634 - val_categorical_crossentropy: 0.2634\n",
      "Epoch 109/250\n",
      "Epoch 00109: categorical_crossentropy improved from 0.26296 to 0.26269, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2627 - categorical_crossentropy: 0.2627 - val_loss: 0.2660 - val_categorical_crossentropy: 0.2660\n",
      "Epoch 110/250\n",
      "Epoch 00110: categorical_crossentropy improved from 0.26269 to 0.26243, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2624 - categorical_crossentropy: 0.2624 - val_loss: 0.2634 - val_categorical_crossentropy: 0.2634\n",
      "Epoch 111/250\n",
      "Epoch 00111: categorical_crossentropy improved from 0.26243 to 0.26217, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2622 - categorical_crossentropy: 0.2622 - val_loss: 0.2630 - val_categorical_crossentropy: 0.2630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/250\n",
      "Epoch 00112: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2626 - categorical_crossentropy: 0.2626 - val_loss: 0.2634 - val_categorical_crossentropy: 0.2634\n",
      "Epoch 113/250\n",
      "Epoch 00113: categorical_crossentropy improved from 0.26217 to 0.26197, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2620 - categorical_crossentropy: 0.2620 - val_loss: 0.2633 - val_categorical_crossentropy: 0.2633\n",
      "Epoch 114/250\n",
      "Epoch 00114: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2620 - categorical_crossentropy: 0.2620 - val_loss: 0.2636 - val_categorical_crossentropy: 0.2636\n",
      "Epoch 115/250\n",
      "Epoch 00115: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2621 - categorical_crossentropy: 0.2621 - val_loss: 0.2626 - val_categorical_crossentropy: 0.2626\n",
      "Epoch 116/250\n",
      "Epoch 00116: categorical_crossentropy improved from 0.26197 to 0.26193, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2619 - categorical_crossentropy: 0.2619 - val_loss: 0.2634 - val_categorical_crossentropy: 0.2634\n",
      "Epoch 117/250\n",
      "Epoch 00117: categorical_crossentropy improved from 0.26193 to 0.26176, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2618 - categorical_crossentropy: 0.2618 - val_loss: 0.2627 - val_categorical_crossentropy: 0.2627\n",
      "Epoch 118/250\n",
      "Epoch 00118: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2618 - categorical_crossentropy: 0.2618 - val_loss: 0.2626 - val_categorical_crossentropy: 0.2626\n",
      "Epoch 119/250\n",
      "Epoch 00119: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2619 - categorical_crossentropy: 0.2619 - val_loss: 0.2624 - val_categorical_crossentropy: 0.2624\n",
      "Epoch 120/250\n",
      "Epoch 00120: categorical_crossentropy improved from 0.26176 to 0.26132, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2613 - categorical_crossentropy: 0.2613 - val_loss: 0.2625 - val_categorical_crossentropy: 0.2625\n",
      "Epoch 121/250\n",
      "Epoch 00121: categorical_crossentropy improved from 0.26132 to 0.26131, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2613 - categorical_crossentropy: 0.2613 - val_loss: 0.2637 - val_categorical_crossentropy: 0.2637\n",
      "Epoch 122/250\n",
      "Epoch 00122: categorical_crossentropy improved from 0.26131 to 0.26128, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2613 - categorical_crossentropy: 0.2613 - val_loss: 0.2651 - val_categorical_crossentropy: 0.2651\n",
      "Epoch 123/250\n",
      "Epoch 00123: categorical_crossentropy improved from 0.26128 to 0.26071, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2607 - categorical_crossentropy: 0.2607 - val_loss: 0.2624 - val_categorical_crossentropy: 0.2624\n",
      "Epoch 124/250\n",
      "Epoch 00124: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2610 - categorical_crossentropy: 0.2610 - val_loss: 0.2632 - val_categorical_crossentropy: 0.2632\n",
      "Epoch 125/250\n",
      "Epoch 00125: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2615 - categorical_crossentropy: 0.2615 - val_loss: 0.2631 - val_categorical_crossentropy: 0.2631\n",
      "Epoch 126/250\n",
      "Epoch 00126: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2609 - categorical_crossentropy: 0.2609 - val_loss: 0.2622 - val_categorical_crossentropy: 0.2622\n",
      "Epoch 127/250\n",
      "Epoch 00127: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2608 - categorical_crossentropy: 0.2608 - val_loss: 0.2622 - val_categorical_crossentropy: 0.2622\n",
      "Epoch 128/250\n",
      "Epoch 00128: categorical_crossentropy improved from 0.26071 to 0.26069, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2607 - categorical_crossentropy: 0.2607 - val_loss: 0.2618 - val_categorical_crossentropy: 0.2618\n",
      "Epoch 129/250\n",
      "Epoch 00129: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2608 - categorical_crossentropy: 0.2608 - val_loss: 0.2617 - val_categorical_crossentropy: 0.2617\n",
      "Epoch 130/250\n",
      "Epoch 00130: categorical_crossentropy improved from 0.26069 to 0.26041, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2604 - categorical_crossentropy: 0.2604 - val_loss: 0.2616 - val_categorical_crossentropy: 0.2616\n",
      "Epoch 131/250\n",
      "Epoch 00131: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2608 - categorical_crossentropy: 0.2608 - val_loss: 0.2615 - val_categorical_crossentropy: 0.2615\n",
      "Epoch 132/250\n",
      "Epoch 00132: categorical_crossentropy improved from 0.26041 to 0.26024, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2602 - categorical_crossentropy: 0.2602 - val_loss: 0.2616 - val_categorical_crossentropy: 0.2616\n",
      "Epoch 133/250\n",
      "Epoch 00133: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2608 - categorical_crossentropy: 0.2608 - val_loss: 0.2616 - val_categorical_crossentropy: 0.2616\n",
      "Epoch 134/250\n",
      "Epoch 00134: categorical_crossentropy improved from 0.26024 to 0.26023, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2602 - categorical_crossentropy: 0.2602 - val_loss: 0.2618 - val_categorical_crossentropy: 0.2618\n",
      "Epoch 135/250\n",
      "Epoch 00135: categorical_crossentropy improved from 0.26023 to 0.26009, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2601 - categorical_crossentropy: 0.2601 - val_loss: 0.2613 - val_categorical_crossentropy: 0.2613\n",
      "Epoch 136/250\n",
      "Epoch 00136: categorical_crossentropy improved from 0.26009 to 0.26008, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2601 - categorical_crossentropy: 0.2601 - val_loss: 0.2613 - val_categorical_crossentropy: 0.2613\n",
      "Epoch 137/250\n",
      "Epoch 00137: categorical_crossentropy improved from 0.26008 to 0.25984, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2598 - categorical_crossentropy: 0.2598 - val_loss: 0.2612 - val_categorical_crossentropy: 0.2612\n",
      "Epoch 138/250\n",
      "Epoch 00138: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2601 - categorical_crossentropy: 0.2601 - val_loss: 0.2613 - val_categorical_crossentropy: 0.2613\n",
      "Epoch 139/250\n",
      "Epoch 00139: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2601 - categorical_crossentropy: 0.2601 - val_loss: 0.2613 - val_categorical_crossentropy: 0.2613\n",
      "Epoch 140/250\n",
      "Epoch 00140: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2601 - categorical_crossentropy: 0.2601 - val_loss: 0.2610 - val_categorical_crossentropy: 0.2610\n",
      "Epoch 141/250\n",
      "Epoch 00141: categorical_crossentropy improved from 0.25984 to 0.25957, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2596 - categorical_crossentropy: 0.2596 - val_loss: 0.2608 - val_categorical_crossentropy: 0.2608\n",
      "Epoch 142/250\n",
      "Epoch 00142: categorical_crossentropy improved from 0.25957 to 0.25948, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2595 - categorical_crossentropy: 0.2595 - val_loss: 0.2622 - val_categorical_crossentropy: 0.2622\n",
      "Epoch 143/250\n",
      "Epoch 00143: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2599 - categorical_crossentropy: 0.2599 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 144/250\n",
      "Epoch 00144: categorical_crossentropy improved from 0.25948 to 0.25945, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2595 - categorical_crossentropy: 0.2595 - val_loss: 0.2608 - val_categorical_crossentropy: 0.2608\n",
      "Epoch 145/250\n",
      "Epoch 00145: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2597 - categorical_crossentropy: 0.2597 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 146/250\n",
      "Epoch 00146: categorical_crossentropy improved from 0.25945 to 0.25942, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2594 - categorical_crossentropy: 0.2594 - val_loss: 0.2645 - val_categorical_crossentropy: 0.2645\n",
      "Epoch 147/250\n",
      "Epoch 00147: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2594 - categorical_crossentropy: 0.2594 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 148/250\n",
      "Epoch 00148: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2598 - categorical_crossentropy: 0.2598 - val_loss: 0.2632 - val_categorical_crossentropy: 0.2632\n",
      "Epoch 149/250\n",
      "Epoch 00149: categorical_crossentropy improved from 0.25942 to 0.25936, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2594 - categorical_crossentropy: 0.2594 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 150/250\n",
      "Epoch 00150: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2597 - categorical_crossentropy: 0.2597 - val_loss: 0.2604 - val_categorical_crossentropy: 0.2604\n",
      "Epoch 151/250\n",
      "Epoch 00151: categorical_crossentropy improved from 0.25936 to 0.25930, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2593 - categorical_crossentropy: 0.2593 - val_loss: 0.2625 - val_categorical_crossentropy: 0.2625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/250\n",
      "Epoch 00152: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2594 - categorical_crossentropy: 0.2594 - val_loss: 0.2604 - val_categorical_crossentropy: 0.2604\n",
      "Epoch 153/250\n",
      "Epoch 00153: categorical_crossentropy improved from 0.25930 to 0.25922, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2592 - categorical_crossentropy: 0.2592 - val_loss: 0.2610 - val_categorical_crossentropy: 0.2610\n",
      "Epoch 154/250\n",
      "Epoch 00154: categorical_crossentropy improved from 0.25922 to 0.25896, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2590 - categorical_crossentropy: 0.2590 - val_loss: 0.2608 - val_categorical_crossentropy: 0.2608\n",
      "Epoch 155/250\n",
      "Epoch 00155: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2592 - categorical_crossentropy: 0.2592 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 156/250\n",
      "Epoch 00156: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2594 - categorical_crossentropy: 0.2594 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 157/250\n",
      "Epoch 00157: categorical_crossentropy improved from 0.25896 to 0.25893, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2589 - categorical_crossentropy: 0.2589 - val_loss: 0.2607 - val_categorical_crossentropy: 0.2607\n",
      "Epoch 158/250\n",
      "Epoch 00158: categorical_crossentropy improved from 0.25893 to 0.25887, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2589 - categorical_crossentropy: 0.2589 - val_loss: 0.2602 - val_categorical_crossentropy: 0.2602\n",
      "Epoch 159/250\n",
      "Epoch 00159: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2590 - categorical_crossentropy: 0.2590 - val_loss: 0.2605 - val_categorical_crossentropy: 0.2605\n",
      "Epoch 160/250\n",
      "Epoch 00160: categorical_crossentropy improved from 0.25887 to 0.25885, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2589 - categorical_crossentropy: 0.2589 - val_loss: 0.2603 - val_categorical_crossentropy: 0.2603\n",
      "Epoch 161/250\n",
      "Epoch 00161: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2592 - categorical_crossentropy: 0.2592 - val_loss: 0.2605 - val_categorical_crossentropy: 0.2605\n",
      "Epoch 162/250\n",
      "Epoch 00162: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2592 - categorical_crossentropy: 0.2592 - val_loss: 0.2600 - val_categorical_crossentropy: 0.2600\n",
      "Epoch 163/250\n",
      "Epoch 00163: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2589 - categorical_crossentropy: 0.2589 - val_loss: 0.2601 - val_categorical_crossentropy: 0.2601\n",
      "Epoch 164/250\n",
      "Epoch 00164: categorical_crossentropy improved from 0.25885 to 0.25862, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2586 - categorical_crossentropy: 0.2586 - val_loss: 0.2601 - val_categorical_crossentropy: 0.2601\n",
      "Epoch 165/250\n",
      "Epoch 00165: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2586 - categorical_crossentropy: 0.2586 - val_loss: 0.2601 - val_categorical_crossentropy: 0.2601\n",
      "Epoch 166/250\n",
      "Epoch 00166: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2588 - categorical_crossentropy: 0.2588 - val_loss: 0.2603 - val_categorical_crossentropy: 0.2603\n",
      "Epoch 167/250\n",
      "Epoch 00167: categorical_crossentropy improved from 0.25862 to 0.25856, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2586 - categorical_crossentropy: 0.2586 - val_loss: 0.2602 - val_categorical_crossentropy: 0.2602\n",
      "Epoch 168/250\n",
      "Epoch 00168: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2589 - categorical_crossentropy: 0.2589 - val_loss: 0.2602 - val_categorical_crossentropy: 0.2602\n",
      "Epoch 169/250\n",
      "Epoch 00169: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2589 - categorical_crossentropy: 0.2589 - val_loss: 0.2603 - val_categorical_crossentropy: 0.2603\n",
      "Epoch 170/250\n",
      "Epoch 00170: categorical_crossentropy improved from 0.25856 to 0.25840, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2584 - categorical_crossentropy: 0.2584 - val_loss: 0.2600 - val_categorical_crossentropy: 0.2600\n",
      "Epoch 171/250\n",
      "Epoch 00171: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2586 - categorical_crossentropy: 0.2586 - val_loss: 0.2599 - val_categorical_crossentropy: 0.2599\n",
      "Epoch 172/250\n",
      "Epoch 00172: categorical_crossentropy improved from 0.25840 to 0.25836, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2584 - categorical_crossentropy: 0.2584 - val_loss: 0.2604 - val_categorical_crossentropy: 0.2604\n",
      "Epoch 173/250\n",
      "Epoch 00173: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2584 - categorical_crossentropy: 0.2584 - val_loss: 0.2600 - val_categorical_crossentropy: 0.2600\n",
      "Epoch 174/250\n",
      "Epoch 00174: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2585 - categorical_crossentropy: 0.2585 - val_loss: 0.2597 - val_categorical_crossentropy: 0.2597\n",
      "Epoch 175/250\n",
      "Epoch 00175: categorical_crossentropy improved from 0.25836 to 0.25825, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2583 - categorical_crossentropy: 0.2583 - val_loss: 0.2616 - val_categorical_crossentropy: 0.2616\n",
      "Epoch 176/250\n",
      "Epoch 00176: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2584 - categorical_crossentropy: 0.2584 - val_loss: 0.2595 - val_categorical_crossentropy: 0.2595\n",
      "Epoch 177/250\n",
      "Epoch 00177: categorical_crossentropy improved from 0.25825 to 0.25820, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2582 - categorical_crossentropy: 0.2582 - val_loss: 0.2605 - val_categorical_crossentropy: 0.2605\n",
      "Epoch 178/250\n",
      "Epoch 00178: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2586 - categorical_crossentropy: 0.2586 - val_loss: 0.2599 - val_categorical_crossentropy: 0.2599\n",
      "Epoch 179/250\n",
      "Epoch 00179: categorical_crossentropy improved from 0.25820 to 0.25797, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2580 - categorical_crossentropy: 0.2580 - val_loss: 0.2596 - val_categorical_crossentropy: 0.2596\n",
      "Epoch 180/250\n",
      "Epoch 00180: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2581 - categorical_crossentropy: 0.2581 - val_loss: 0.2597 - val_categorical_crossentropy: 0.2597\n",
      "Epoch 181/250\n",
      "Epoch 00181: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2587 - categorical_crossentropy: 0.2587 - val_loss: 0.2600 - val_categorical_crossentropy: 0.2600\n",
      "Epoch 182/250\n",
      "Epoch 00182: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2581 - categorical_crossentropy: 0.2581 - val_loss: 0.2605 - val_categorical_crossentropy: 0.2605\n",
      "Epoch 183/250\n",
      "Epoch 00183: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2581 - categorical_crossentropy: 0.2581 - val_loss: 0.2593 - val_categorical_crossentropy: 0.2593\n",
      "Epoch 184/250\n",
      "Epoch 00184: categorical_crossentropy improved from 0.25797 to 0.25793, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2579 - categorical_crossentropy: 0.2579 - val_loss: 0.2594 - val_categorical_crossentropy: 0.2594\n",
      "Epoch 185/250\n",
      "Epoch 00185: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2579 - categorical_crossentropy: 0.2579 - val_loss: 0.2595 - val_categorical_crossentropy: 0.2595\n",
      "Epoch 186/250\n",
      "Epoch 00186: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2583 - categorical_crossentropy: 0.2583 - val_loss: 0.2595 - val_categorical_crossentropy: 0.2595\n",
      "Epoch 187/250\n",
      "Epoch 00187: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2584 - categorical_crossentropy: 0.2584 - val_loss: 0.2600 - val_categorical_crossentropy: 0.2600\n",
      "Epoch 188/250\n",
      "Epoch 00188: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2583 - categorical_crossentropy: 0.2583 - val_loss: 0.2594 - val_categorical_crossentropy: 0.2594\n",
      "Epoch 189/250\n",
      "Epoch 00189: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2582 - categorical_crossentropy: 0.2582 - val_loss: 0.2594 - val_categorical_crossentropy: 0.2594\n",
      "Epoch 190/250\n",
      "Epoch 00190: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2582 - categorical_crossentropy: 0.2582 - val_loss: 0.2593 - val_categorical_crossentropy: 0.2593\n",
      "Epoch 191/250\n",
      "Epoch 00191: categorical_crossentropy improved from 0.25793 to 0.25789, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2579 - categorical_crossentropy: 0.2579 - val_loss: 0.2592 - val_categorical_crossentropy: 0.2592\n",
      "Epoch 192/250\n",
      "Epoch 00192: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2580 - categorical_crossentropy: 0.2580 - val_loss: 0.2593 - val_categorical_crossentropy: 0.2593\n",
      "Epoch 193/250\n",
      "Epoch 00193: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2583 - categorical_crossentropy: 0.2583 - val_loss: 0.2600 - val_categorical_crossentropy: 0.2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/250\n",
      "Epoch 00194: categorical_crossentropy improved from 0.25789 to 0.25775, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2577 - categorical_crossentropy: 0.2577 - val_loss: 0.2599 - val_categorical_crossentropy: 0.2599\n",
      "Epoch 195/250\n",
      "Epoch 00195: categorical_crossentropy improved from 0.25775 to 0.25770, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2577 - categorical_crossentropy: 0.2577 - val_loss: 0.2591 - val_categorical_crossentropy: 0.2591\n",
      "Epoch 196/250\n",
      "Epoch 00196: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2578 - categorical_crossentropy: 0.2578 - val_loss: 0.2599 - val_categorical_crossentropy: 0.2599\n",
      "Epoch 197/250\n",
      "Epoch 00197: categorical_crossentropy improved from 0.25770 to 0.25762, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2576 - categorical_crossentropy: 0.2576 - val_loss: 0.2595 - val_categorical_crossentropy: 0.2595\n",
      "Epoch 198/250\n",
      "Epoch 00198: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2581 - categorical_crossentropy: 0.2581 - val_loss: 0.2595 - val_categorical_crossentropy: 0.2595\n",
      "Epoch 199/250\n",
      "Epoch 00199: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2576 - categorical_crossentropy: 0.2576 - val_loss: 0.2601 - val_categorical_crossentropy: 0.2601\n",
      "Epoch 200/250\n",
      "Epoch 00200: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2576 - categorical_crossentropy: 0.2576 - val_loss: 0.2594 - val_categorical_crossentropy: 0.2594\n",
      "Epoch 201/250\n",
      "Epoch 00201: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2577 - categorical_crossentropy: 0.2577 - val_loss: 0.2598 - val_categorical_crossentropy: 0.2598\n",
      "Epoch 202/250\n",
      "Epoch 00202: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2580 - categorical_crossentropy: 0.2580 - val_loss: 0.2589 - val_categorical_crossentropy: 0.2589\n",
      "Epoch 203/250\n",
      "Epoch 00203: categorical_crossentropy improved from 0.25762 to 0.25751, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2575 - categorical_crossentropy: 0.2575 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 204/250\n",
      "Epoch 00204: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2577 - categorical_crossentropy: 0.2577 - val_loss: 0.2591 - val_categorical_crossentropy: 0.2591\n",
      "Epoch 205/250\n",
      "Epoch 00205: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2577 - categorical_crossentropy: 0.2577 - val_loss: 0.2593 - val_categorical_crossentropy: 0.2593\n",
      "Epoch 206/250\n",
      "Epoch 00206: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2579 - categorical_crossentropy: 0.2579 - val_loss: 0.2593 - val_categorical_crossentropy: 0.2593\n",
      "Epoch 207/250\n",
      "Epoch 00207: categorical_crossentropy improved from 0.25751 to 0.25725, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.2572 - categorical_crossentropy: 0.2572 - val_loss: 0.2590 - val_categorical_crossentropy: 0.2590\n",
      "Epoch 208/250\n",
      "Epoch 00208: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2574 - categorical_crossentropy: 0.2574 - val_loss: 0.2607 - val_categorical_crossentropy: 0.2607\n",
      "Epoch 209/250\n",
      "Epoch 00209: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2575 - categorical_crossentropy: 0.2575 - val_loss: 0.2588 - val_categorical_crossentropy: 0.2588\n",
      "Epoch 210/250\n",
      "Epoch 00210: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2576 - categorical_crossentropy: 0.2576 - val_loss: 0.2589 - val_categorical_crossentropy: 0.2589\n",
      "Epoch 211/250\n",
      "Epoch 00211: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2573 - categorical_crossentropy: 0.2573 - val_loss: 0.2592 - val_categorical_crossentropy: 0.2592\n",
      "Epoch 212/250\n",
      "Epoch 00212: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2574 - categorical_crossentropy: 0.2574 - val_loss: 0.2594 - val_categorical_crossentropy: 0.2594\n",
      "Epoch 213/250\n",
      "Epoch 00213: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2576 - categorical_crossentropy: 0.2576 - val_loss: 0.2588 - val_categorical_crossentropy: 0.2588\n",
      "Epoch 214/250\n",
      "Epoch 00214: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2574 - categorical_crossentropy: 0.2574 - val_loss: 0.2590 - val_categorical_crossentropy: 0.2590\n",
      "Epoch 215/250\n",
      "Epoch 00215: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2573 - categorical_crossentropy: 0.2573 - val_loss: 0.2590 - val_categorical_crossentropy: 0.2590\n",
      "Epoch 216/250\n",
      "Epoch 00216: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2574 - categorical_crossentropy: 0.2574 - val_loss: 0.2587 - val_categorical_crossentropy: 0.2587\n",
      "Epoch 217/250\n",
      "Epoch 00217: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2574 - categorical_crossentropy: 0.2574 - val_loss: 0.2598 - val_categorical_crossentropy: 0.2598\n",
      "Epoch 00217: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 53, 7)             420       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 53, 7)             56        \n",
      "=================================================================\n",
      "Total params: 476\n",
      "Trainable params: 476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training time : 403.7264623641968s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    callbacks = [checkpoint, early])\n",
    "stop = time.time()\n",
    "t1 = stop-start\n",
    "print(model.summary())\n",
    "print(\"Training time : {}s\".format(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_steps = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN\n",
    "\n",
    "Using the same code, we can train the standard RNN. The principle is that every output of every hidden layers, are also feed as entry for the next step\n",
    "\n",
    "<img src=\"SimpleRNN.png\"/>\n",
    "\n",
    "This allows a \"short term memory\". It creates a kind of hysteresis used as memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(SimpleRNN(units=nb_unit, input_shape=inp_shape, return_sequences=True))\n",
    "model2.add(Dense(7, activation='softmax'))\n",
    "model2.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"srnn_simple.h5\",\n",
    "    monitor=loss_,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 256 samples\n",
      "Epoch 1/250\n",
      "Epoch 00001: categorical_crossentropy improved from inf to 1.26835, saving model to srnn_simple.h5\n",
      " - 1s - loss: 1.2684 - categorical_crossentropy: 1.2684 - val_loss: 1.1905 - val_categorical_crossentropy: 1.1905\n",
      "Epoch 2/250\n",
      "Epoch 00002: categorical_crossentropy improved from 1.26835 to 1.12087, saving model to srnn_simple.h5\n",
      " - 1s - loss: 1.1209 - categorical_crossentropy: 1.1209 - val_loss: 1.0586 - val_categorical_crossentropy: 1.0586\n",
      "Epoch 3/250\n",
      "Epoch 00003: categorical_crossentropy improved from 1.12087 to 0.99992, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.9999 - categorical_crossentropy: 0.9999 - val_loss: 0.9427 - val_categorical_crossentropy: 0.9427\n",
      "Epoch 4/250\n",
      "Epoch 00004: categorical_crossentropy improved from 0.99992 to 0.89331, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.8933 - categorical_crossentropy: 0.8933 - val_loss: 0.8471 - val_categorical_crossentropy: 0.8471\n",
      "Epoch 5/250\n",
      "Epoch 00005: categorical_crossentropy improved from 0.89331 to 0.81019, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.8102 - categorical_crossentropy: 0.8102 - val_loss: 0.7736 - val_categorical_crossentropy: 0.7736\n",
      "Epoch 6/250\n",
      "Epoch 00006: categorical_crossentropy improved from 0.81019 to 0.74084, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.7408 - categorical_crossentropy: 0.7408 - val_loss: 0.7062 - val_categorical_crossentropy: 0.7062\n",
      "Epoch 7/250\n",
      "Epoch 00007: categorical_crossentropy improved from 0.74084 to 0.67391, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.6739 - categorical_crossentropy: 0.6739 - val_loss: 0.6415 - val_categorical_crossentropy: 0.6415\n",
      "Epoch 8/250\n",
      "Epoch 00008: categorical_crossentropy improved from 0.67391 to 0.61634, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.6163 - categorical_crossentropy: 0.6163 - val_loss: 0.5912 - val_categorical_crossentropy: 0.5912\n",
      "Epoch 9/250\n",
      "Epoch 00009: categorical_crossentropy improved from 0.61634 to 0.57234, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.5723 - categorical_crossentropy: 0.5723 - val_loss: 0.5530 - val_categorical_crossentropy: 0.5530\n",
      "Epoch 10/250\n",
      "Epoch 00010: categorical_crossentropy improved from 0.57234 to 0.53848, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5385 - categorical_crossentropy: 0.5385 - val_loss: 0.5233 - val_categorical_crossentropy: 0.5233\n",
      "Epoch 11/250\n",
      "Epoch 00011: categorical_crossentropy improved from 0.53848 to 0.51164, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5116 - categorical_crossentropy: 0.5116 - val_loss: 0.4993 - val_categorical_crossentropy: 0.4993\n",
      "Epoch 12/250\n",
      "Epoch 00012: categorical_crossentropy improved from 0.51164 to 0.48961, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4896 - categorical_crossentropy: 0.4896 - val_loss: 0.4795 - val_categorical_crossentropy: 0.4795\n",
      "Epoch 13/250\n",
      "Epoch 00013: categorical_crossentropy improved from 0.48961 to 0.47107, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4711 - categorical_crossentropy: 0.4711 - val_loss: 0.4625 - val_categorical_crossentropy: 0.4625\n",
      "Epoch 14/250\n",
      "Epoch 00014: categorical_crossentropy improved from 0.47107 to 0.45516, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.4552 - categorical_crossentropy: 0.4552 - val_loss: 0.4478 - val_categorical_crossentropy: 0.4478\n",
      "Epoch 15/250\n",
      "Epoch 00015: categorical_crossentropy improved from 0.45516 to 0.44131, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4413 - categorical_crossentropy: 0.4413 - val_loss: 0.4351 - val_categorical_crossentropy: 0.4351\n",
      "Epoch 16/250\n",
      "Epoch 00016: categorical_crossentropy improved from 0.44131 to 0.42913, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.4291 - categorical_crossentropy: 0.4291 - val_loss: 0.4240 - val_categorical_crossentropy: 0.4240\n",
      "Epoch 17/250\n",
      "Epoch 00017: categorical_crossentropy improved from 0.42913 to 0.41836, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.4184 - categorical_crossentropy: 0.4184 - val_loss: 0.4140 - val_categorical_crossentropy: 0.4140\n",
      "Epoch 18/250\n",
      "Epoch 00018: categorical_crossentropy improved from 0.41836 to 0.40872, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4087 - categorical_crossentropy: 0.4087 - val_loss: 0.4052 - val_categorical_crossentropy: 0.4052\n",
      "Epoch 19/250\n",
      "Epoch 00019: categorical_crossentropy improved from 0.40872 to 0.40008, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4001 - categorical_crossentropy: 0.4001 - val_loss: 0.3971 - val_categorical_crossentropy: 0.3971\n",
      "Epoch 20/250\n",
      "Epoch 00020: categorical_crossentropy improved from 0.40008 to 0.39230, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3923 - categorical_crossentropy: 0.3923 - val_loss: 0.3898 - val_categorical_crossentropy: 0.3898\n",
      "Epoch 21/250\n",
      "Epoch 00021: categorical_crossentropy improved from 0.39230 to 0.38524, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3852 - categorical_crossentropy: 0.3852 - val_loss: 0.3833 - val_categorical_crossentropy: 0.3833\n",
      "Epoch 22/250\n",
      "Epoch 00022: categorical_crossentropy improved from 0.38524 to 0.37888, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3789 - categorical_crossentropy: 0.3789 - val_loss: 0.3772 - val_categorical_crossentropy: 0.3772\n",
      "Epoch 23/250\n",
      "Epoch 00023: categorical_crossentropy improved from 0.37888 to 0.37304, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3730 - categorical_crossentropy: 0.3730 - val_loss: 0.3717 - val_categorical_crossentropy: 0.3717\n",
      "Epoch 24/250\n",
      "Epoch 00024: categorical_crossentropy improved from 0.37304 to 0.36769, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3677 - categorical_crossentropy: 0.3677 - val_loss: 0.3664 - val_categorical_crossentropy: 0.3664\n",
      "Epoch 25/250\n",
      "Epoch 00025: categorical_crossentropy improved from 0.36769 to 0.36279, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3628 - categorical_crossentropy: 0.3628 - val_loss: 0.3619 - val_categorical_crossentropy: 0.3619\n",
      "Epoch 26/250\n",
      "Epoch 00026: categorical_crossentropy improved from 0.36279 to 0.35822, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3582 - categorical_crossentropy: 0.3582 - val_loss: 0.3574 - val_categorical_crossentropy: 0.3574\n",
      "Epoch 27/250\n",
      "Epoch 00027: categorical_crossentropy improved from 0.35822 to 0.35390, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3539 - categorical_crossentropy: 0.3539 - val_loss: 0.3532 - val_categorical_crossentropy: 0.3532\n",
      "Epoch 28/250\n",
      "Epoch 00028: categorical_crossentropy improved from 0.35390 to 0.34977, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3498 - categorical_crossentropy: 0.3498 - val_loss: 0.3491 - val_categorical_crossentropy: 0.3491\n",
      "Epoch 29/250\n",
      "Epoch 00029: categorical_crossentropy improved from 0.34977 to 0.34572, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3457 - categorical_crossentropy: 0.3457 - val_loss: 0.3451 - val_categorical_crossentropy: 0.3451\n",
      "Epoch 30/250\n",
      "Epoch 00030: categorical_crossentropy improved from 0.34572 to 0.34182, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3418 - categorical_crossentropy: 0.3418 - val_loss: 0.3411 - val_categorical_crossentropy: 0.3411\n",
      "Epoch 31/250\n",
      "Epoch 00031: categorical_crossentropy improved from 0.34182 to 0.33797, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3380 - categorical_crossentropy: 0.3380 - val_loss: 0.3373 - val_categorical_crossentropy: 0.3373\n",
      "Epoch 32/250\n",
      "Epoch 00032: categorical_crossentropy improved from 0.33797 to 0.33425, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3342 - categorical_crossentropy: 0.3342 - val_loss: 0.3336 - val_categorical_crossentropy: 0.3336\n",
      "Epoch 33/250\n",
      "Epoch 00033: categorical_crossentropy improved from 0.33425 to 0.33072, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3307 - categorical_crossentropy: 0.3307 - val_loss: 0.3303 - val_categorical_crossentropy: 0.3303\n",
      "Epoch 34/250\n",
      "Epoch 00034: categorical_crossentropy improved from 0.33072 to 0.32745, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3274 - categorical_crossentropy: 0.3274 - val_loss: 0.3271 - val_categorical_crossentropy: 0.3271\n",
      "Epoch 35/250\n",
      "Epoch 00035: categorical_crossentropy improved from 0.32745 to 0.32442, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3244 - categorical_crossentropy: 0.3244 - val_loss: 0.3242 - val_categorical_crossentropy: 0.3242\n",
      "Epoch 36/250\n",
      "Epoch 00036: categorical_crossentropy improved from 0.32442 to 0.32167, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3217 - categorical_crossentropy: 0.3217 - val_loss: 0.3214 - val_categorical_crossentropy: 0.3214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "Epoch 00037: categorical_crossentropy improved from 0.32167 to 0.31918, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3192 - categorical_crossentropy: 0.3192 - val_loss: 0.3191 - val_categorical_crossentropy: 0.3191\n",
      "Epoch 38/250\n",
      "Epoch 00038: categorical_crossentropy improved from 0.31918 to 0.31694, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3169 - categorical_crossentropy: 0.3169 - val_loss: 0.3172 - val_categorical_crossentropy: 0.3172\n",
      "Epoch 39/250\n",
      "Epoch 00039: categorical_crossentropy improved from 0.31694 to 0.31497, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3150 - categorical_crossentropy: 0.3150 - val_loss: 0.3151 - val_categorical_crossentropy: 0.3151\n",
      "Epoch 40/250\n",
      "Epoch 00040: categorical_crossentropy improved from 0.31497 to 0.31319, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3132 - categorical_crossentropy: 0.3132 - val_loss: 0.3134 - val_categorical_crossentropy: 0.3134\n",
      "Epoch 41/250\n",
      "Epoch 00041: categorical_crossentropy improved from 0.31319 to 0.31158, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3116 - categorical_crossentropy: 0.3116 - val_loss: 0.3119 - val_categorical_crossentropy: 0.3119\n",
      "Epoch 42/250\n",
      "Epoch 00042: categorical_crossentropy improved from 0.31158 to 0.31014, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3101 - categorical_crossentropy: 0.3101 - val_loss: 0.3108 - val_categorical_crossentropy: 0.3108\n",
      "Epoch 43/250\n",
      "Epoch 00043: categorical_crossentropy improved from 0.31014 to 0.30884, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3088 - categorical_crossentropy: 0.3088 - val_loss: 0.3092 - val_categorical_crossentropy: 0.3092\n",
      "Epoch 44/250\n",
      "Epoch 00044: categorical_crossentropy improved from 0.30884 to 0.30767, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3077 - categorical_crossentropy: 0.3077 - val_loss: 0.3081 - val_categorical_crossentropy: 0.3081\n",
      "Epoch 45/250\n",
      "Epoch 00045: categorical_crossentropy improved from 0.30767 to 0.30658, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3066 - categorical_crossentropy: 0.3066 - val_loss: 0.3071 - val_categorical_crossentropy: 0.3071\n",
      "Epoch 46/250\n",
      "Epoch 00046: categorical_crossentropy improved from 0.30658 to 0.30560, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3056 - categorical_crossentropy: 0.3056 - val_loss: 0.3062 - val_categorical_crossentropy: 0.3062\n",
      "Epoch 47/250\n",
      "Epoch 00047: categorical_crossentropy improved from 0.30560 to 0.30470, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3047 - categorical_crossentropy: 0.3047 - val_loss: 0.3055 - val_categorical_crossentropy: 0.3055\n",
      "Epoch 48/250\n",
      "Epoch 00048: categorical_crossentropy improved from 0.30470 to 0.30389, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3039 - categorical_crossentropy: 0.3039 - val_loss: 0.3049 - val_categorical_crossentropy: 0.3049\n",
      "Epoch 49/250\n",
      "Epoch 00049: categorical_crossentropy improved from 0.30389 to 0.30313, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3031 - categorical_crossentropy: 0.3031 - val_loss: 0.3040 - val_categorical_crossentropy: 0.3040\n",
      "Epoch 50/250\n",
      "Epoch 00050: categorical_crossentropy improved from 0.30313 to 0.30241, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3024 - categorical_crossentropy: 0.3024 - val_loss: 0.3032 - val_categorical_crossentropy: 0.3032\n",
      "Epoch 51/250\n",
      "Epoch 00051: categorical_crossentropy improved from 0.30241 to 0.30170, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3017 - categorical_crossentropy: 0.3017 - val_loss: 0.3026 - val_categorical_crossentropy: 0.3026\n",
      "Epoch 52/250\n",
      "Epoch 00052: categorical_crossentropy improved from 0.30170 to 0.30111, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3011 - categorical_crossentropy: 0.3011 - val_loss: 0.3020 - val_categorical_crossentropy: 0.3020\n",
      "Epoch 53/250\n",
      "Epoch 00053: categorical_crossentropy improved from 0.30111 to 0.30046, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3005 - categorical_crossentropy: 0.3005 - val_loss: 0.3015 - val_categorical_crossentropy: 0.3015\n",
      "Epoch 54/250\n",
      "Epoch 00054: categorical_crossentropy improved from 0.30046 to 0.29992, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2999 - categorical_crossentropy: 0.2999 - val_loss: 0.3004 - val_categorical_crossentropy: 0.3004\n",
      "Epoch 55/250\n",
      "Epoch 00055: categorical_crossentropy improved from 0.29992 to 0.29931, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2993 - categorical_crossentropy: 0.2993 - val_loss: 0.3000 - val_categorical_crossentropy: 0.3000\n",
      "Epoch 56/250\n",
      "Epoch 00056: categorical_crossentropy improved from 0.29931 to 0.29870, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2987 - categorical_crossentropy: 0.2987 - val_loss: 0.2996 - val_categorical_crossentropy: 0.2996\n",
      "Epoch 57/250\n",
      "Epoch 00057: categorical_crossentropy improved from 0.29870 to 0.29834, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2983 - categorical_crossentropy: 0.2983 - val_loss: 0.2993 - val_categorical_crossentropy: 0.2993\n",
      "Epoch 58/250\n",
      "Epoch 00058: categorical_crossentropy improved from 0.29834 to 0.29742, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2974 - categorical_crossentropy: 0.2974 - val_loss: 0.2985 - val_categorical_crossentropy: 0.2985\n",
      "Epoch 59/250\n",
      "Epoch 00059: categorical_crossentropy improved from 0.29742 to 0.29669, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2967 - categorical_crossentropy: 0.2967 - val_loss: 0.2976 - val_categorical_crossentropy: 0.2976\n",
      "Epoch 60/250\n",
      "Epoch 00060: categorical_crossentropy improved from 0.29669 to 0.29616, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2962 - categorical_crossentropy: 0.2962 - val_loss: 0.2972 - val_categorical_crossentropy: 0.2972\n",
      "Epoch 61/250\n",
      "Epoch 00061: categorical_crossentropy improved from 0.29616 to 0.29529, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2953 - categorical_crossentropy: 0.2953 - val_loss: 0.2958 - val_categorical_crossentropy: 0.2958\n",
      "Epoch 62/250\n",
      "Epoch 00062: categorical_crossentropy improved from 0.29529 to 0.29457, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2946 - categorical_crossentropy: 0.2946 - val_loss: 0.2943 - val_categorical_crossentropy: 0.2943\n",
      "Epoch 63/250\n",
      "Epoch 00063: categorical_crossentropy improved from 0.29457 to 0.29451, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2945 - categorical_crossentropy: 0.2945 - val_loss: 0.2945 - val_categorical_crossentropy: 0.2945\n",
      "Epoch 64/250\n",
      "Epoch 00064: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2965 - categorical_crossentropy: 0.2965 - val_loss: 0.2963 - val_categorical_crossentropy: 0.2963\n",
      "Epoch 65/250\n",
      "Epoch 00065: categorical_crossentropy improved from 0.29451 to 0.29355, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2935 - categorical_crossentropy: 0.2935 - val_loss: 0.2938 - val_categorical_crossentropy: 0.2938\n",
      "Epoch 66/250\n",
      "Epoch 00066: categorical_crossentropy improved from 0.29355 to 0.29211, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2921 - categorical_crossentropy: 0.2921 - val_loss: 0.2924 - val_categorical_crossentropy: 0.2924\n",
      "Epoch 67/250\n",
      "Epoch 00067: categorical_crossentropy improved from 0.29211 to 0.29115, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2911 - categorical_crossentropy: 0.2911 - val_loss: 0.2914 - val_categorical_crossentropy: 0.2914\n",
      "Epoch 68/250\n",
      "Epoch 00068: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2920 - categorical_crossentropy: 0.2920 - val_loss: 0.2916 - val_categorical_crossentropy: 0.2916\n",
      "Epoch 69/250\n",
      "Epoch 00069: categorical_crossentropy improved from 0.29115 to 0.29023, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2902 - categorical_crossentropy: 0.2902 - val_loss: 0.2903 - val_categorical_crossentropy: 0.2903\n",
      "Epoch 70/250\n",
      "Epoch 00070: categorical_crossentropy improved from 0.29023 to 0.28969, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2897 - categorical_crossentropy: 0.2897 - val_loss: 0.2939 - val_categorical_crossentropy: 0.2939\n",
      "Epoch 71/250\n",
      "Epoch 00071: categorical_crossentropy improved from 0.28969 to 0.28916, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2892 - categorical_crossentropy: 0.2892 - val_loss: 0.2887 - val_categorical_crossentropy: 0.2887\n",
      "Epoch 72/250\n",
      "Epoch 00072: categorical_crossentropy improved from 0.28916 to 0.28903, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2890 - categorical_crossentropy: 0.2890 - val_loss: 0.2883 - val_categorical_crossentropy: 0.2883\n",
      "Epoch 73/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00073: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2919 - categorical_crossentropy: 0.2919 - val_loss: 0.2902 - val_categorical_crossentropy: 0.2902\n",
      "Epoch 74/250\n",
      "Epoch 00074: categorical_crossentropy improved from 0.28903 to 0.28843, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2884 - categorical_crossentropy: 0.2884 - val_loss: 0.2891 - val_categorical_crossentropy: 0.2891\n",
      "Epoch 75/250\n",
      "Epoch 00075: categorical_crossentropy improved from 0.28843 to 0.28761, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2876 - categorical_crossentropy: 0.2876 - val_loss: 0.2899 - val_categorical_crossentropy: 0.2899\n",
      "Epoch 76/250\n",
      "Epoch 00076: categorical_crossentropy improved from 0.28761 to 0.28761, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2876 - categorical_crossentropy: 0.2876 - val_loss: 0.2867 - val_categorical_crossentropy: 0.2867\n",
      "Epoch 77/250\n",
      "Epoch 00077: categorical_crossentropy improved from 0.28761 to 0.28616, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2862 - categorical_crossentropy: 0.2862 - val_loss: 0.2865 - val_categorical_crossentropy: 0.2865\n",
      "Epoch 78/250\n",
      "Epoch 00078: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2862 - categorical_crossentropy: 0.2862 - val_loss: 0.2861 - val_categorical_crossentropy: 0.2861\n",
      "Epoch 79/250\n",
      "Epoch 00079: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2870 - categorical_crossentropy: 0.2870 - val_loss: 0.2859 - val_categorical_crossentropy: 0.2859\n",
      "Epoch 80/250\n",
      "Epoch 00080: categorical_crossentropy improved from 0.28616 to 0.28535, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2854 - categorical_crossentropy: 0.2854 - val_loss: 0.2859 - val_categorical_crossentropy: 0.2859\n",
      "Epoch 81/250\n",
      "Epoch 00081: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2953 - categorical_crossentropy: 0.2953 - val_loss: 0.2935 - val_categorical_crossentropy: 0.2935\n",
      "Epoch 82/250\n",
      "Epoch 00082: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2902 - categorical_crossentropy: 0.2902 - val_loss: 0.2900 - val_categorical_crossentropy: 0.2900\n",
      "Epoch 83/250\n",
      "Epoch 00083: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2876 - categorical_crossentropy: 0.2876 - val_loss: 0.2873 - val_categorical_crossentropy: 0.2873\n",
      "Epoch 84/250\n",
      "Epoch 00084: categorical_crossentropy improved from 0.28535 to 0.28480, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2848 - categorical_crossentropy: 0.2848 - val_loss: 0.2864 - val_categorical_crossentropy: 0.2864\n",
      "Epoch 85/250\n",
      "Epoch 00085: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2873 - categorical_crossentropy: 0.2873 - val_loss: 0.2881 - val_categorical_crossentropy: 0.2881\n",
      "Epoch 86/250\n",
      "Epoch 00086: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2860 - categorical_crossentropy: 0.2860 - val_loss: 0.2851 - val_categorical_crossentropy: 0.2851\n",
      "Epoch 87/250\n",
      "Epoch 00087: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2872 - categorical_crossentropy: 0.2872 - val_loss: 0.2940 - val_categorical_crossentropy: 0.2940\n",
      "Epoch 88/250\n",
      "Epoch 00088: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2915 - categorical_crossentropy: 0.2915 - val_loss: 0.2906 - val_categorical_crossentropy: 0.2906\n",
      "Epoch 89/250\n",
      "Epoch 00089: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2883 - categorical_crossentropy: 0.2883 - val_loss: 0.2885 - val_categorical_crossentropy: 0.2885\n",
      "Epoch 90/250\n",
      "Epoch 00090: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2865 - categorical_crossentropy: 0.2865 - val_loss: 0.2867 - val_categorical_crossentropy: 0.2867\n",
      "Epoch 91/250\n",
      "Epoch 00091: categorical_crossentropy improved from 0.28480 to 0.28401, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2840 - categorical_crossentropy: 0.2840 - val_loss: 0.2834 - val_categorical_crossentropy: 0.2834\n",
      "Epoch 92/250\n",
      "Epoch 00092: categorical_crossentropy improved from 0.28401 to 0.28258, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2826 - categorical_crossentropy: 0.2826 - val_loss: 0.2827 - val_categorical_crossentropy: 0.2827\n",
      "Epoch 93/250\n",
      "Epoch 00093: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2826 - categorical_crossentropy: 0.2826 - val_loss: 0.2820 - val_categorical_crossentropy: 0.2820\n",
      "Epoch 94/250\n",
      "Epoch 00094: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2832 - categorical_crossentropy: 0.2832 - val_loss: 0.2825 - val_categorical_crossentropy: 0.2825\n",
      "Epoch 95/250\n",
      "Epoch 00095: categorical_crossentropy improved from 0.28258 to 0.28126, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2813 - categorical_crossentropy: 0.2813 - val_loss: 0.2814 - val_categorical_crossentropy: 0.2814\n",
      "Epoch 96/250\n",
      "Epoch 00096: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2814 - categorical_crossentropy: 0.2814 - val_loss: 0.2808 - val_categorical_crossentropy: 0.2808\n",
      "Epoch 97/250\n",
      "Epoch 00097: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2884 - categorical_crossentropy: 0.2884 - val_loss: 0.2968 - val_categorical_crossentropy: 0.2968\n",
      "Epoch 98/250\n",
      "Epoch 00098: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2927 - categorical_crossentropy: 0.2927 - val_loss: 0.2911 - val_categorical_crossentropy: 0.2911\n",
      "Epoch 99/250\n",
      "Epoch 00099: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2886 - categorical_crossentropy: 0.2886 - val_loss: 0.2889 - val_categorical_crossentropy: 0.2889\n",
      "Epoch 100/250\n",
      "Epoch 00100: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2868 - categorical_crossentropy: 0.2868 - val_loss: 0.2875 - val_categorical_crossentropy: 0.2875\n",
      "Epoch 101/250\n",
      "Epoch 00101: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2853 - categorical_crossentropy: 0.2853 - val_loss: 0.2855 - val_categorical_crossentropy: 0.2855\n",
      "Epoch 102/250\n",
      "Epoch 00102: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2830 - categorical_crossentropy: 0.2830 - val_loss: 0.2824 - val_categorical_crossentropy: 0.2824\n",
      "Epoch 103/250\n",
      "Epoch 00103: categorical_crossentropy improved from 0.28126 to 0.28125, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2813 - categorical_crossentropy: 0.2813 - val_loss: 0.2846 - val_categorical_crossentropy: 0.2846\n",
      "Epoch 104/250\n",
      "Epoch 00104: categorical_crossentropy improved from 0.28125 to 0.28107, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2811 - categorical_crossentropy: 0.2811 - val_loss: 0.2804 - val_categorical_crossentropy: 0.2804\n",
      "Epoch 105/250\n",
      "Epoch 00105: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2811 - categorical_crossentropy: 0.2811 - val_loss: 0.2798 - val_categorical_crossentropy: 0.2798\n",
      "Epoch 106/250\n",
      "Epoch 00106: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2817 - categorical_crossentropy: 0.2817 - val_loss: 0.2821 - val_categorical_crossentropy: 0.2821\n",
      "Epoch 107/250\n",
      "Epoch 00107: categorical_crossentropy improved from 0.28107 to 0.27993, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2799 - categorical_crossentropy: 0.2799 - val_loss: 0.2811 - val_categorical_crossentropy: 0.2811\n",
      "Epoch 108/250\n",
      "Epoch 00108: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2915 - categorical_crossentropy: 0.2915 - val_loss: 0.2891 - val_categorical_crossentropy: 0.2891\n",
      "Epoch 109/250\n",
      "Epoch 00109: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2867 - categorical_crossentropy: 0.2867 - val_loss: 0.2866 - val_categorical_crossentropy: 0.2866\n",
      "Epoch 110/250\n",
      "Epoch 00110: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2845 - categorical_crossentropy: 0.2845 - val_loss: 0.2844 - val_categorical_crossentropy: 0.2844\n",
      "Epoch 111/250\n",
      "Epoch 00111: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2818 - categorical_crossentropy: 0.2818 - val_loss: 0.2811 - val_categorical_crossentropy: 0.2811\n",
      "Epoch 112/250\n",
      "Epoch 00112: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2845 - categorical_crossentropy: 0.2845 - val_loss: 0.2847 - val_categorical_crossentropy: 0.2847\n",
      "Epoch 113/250\n",
      "Epoch 00113: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2827 - categorical_crossentropy: 0.2827 - val_loss: 0.2823 - val_categorical_crossentropy: 0.2823\n",
      "Epoch 114/250\n",
      "Epoch 00114: categorical_crossentropy improved from 0.27993 to 0.27959, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2796 - categorical_crossentropy: 0.2796 - val_loss: 0.2793 - val_categorical_crossentropy: 0.2793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/250\n",
      "Epoch 00115: categorical_crossentropy improved from 0.27959 to 0.27860, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2786 - categorical_crossentropy: 0.2786 - val_loss: 0.2788 - val_categorical_crossentropy: 0.2788\n",
      "Epoch 116/250\n",
      "Epoch 00116: categorical_crossentropy improved from 0.27860 to 0.27860, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2786 - categorical_crossentropy: 0.2786 - val_loss: 0.2786 - val_categorical_crossentropy: 0.2786\n",
      "Epoch 117/250\n",
      "Epoch 00117: categorical_crossentropy improved from 0.27860 to 0.27849, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2785 - categorical_crossentropy: 0.2785 - val_loss: 0.2779 - val_categorical_crossentropy: 0.2779\n",
      "Epoch 118/250\n",
      "Epoch 00118: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2844 - categorical_crossentropy: 0.2844 - val_loss: 0.2886 - val_categorical_crossentropy: 0.2886\n",
      "Epoch 119/250\n",
      "Epoch 00119: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2864 - categorical_crossentropy: 0.2864 - val_loss: 0.2857 - val_categorical_crossentropy: 0.2857\n",
      "Epoch 120/250\n",
      "Epoch 00120: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2834 - categorical_crossentropy: 0.2834 - val_loss: 0.2831 - val_categorical_crossentropy: 0.2831\n",
      "Epoch 121/250\n",
      "Epoch 00121: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2799 - categorical_crossentropy: 0.2799 - val_loss: 0.2790 - val_categorical_crossentropy: 0.2790\n",
      "Epoch 122/250\n",
      "Epoch 00122: categorical_crossentropy improved from 0.27849 to 0.27778, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2778 - categorical_crossentropy: 0.2778 - val_loss: 0.2800 - val_categorical_crossentropy: 0.2800\n",
      "Epoch 123/250\n",
      "Epoch 00123: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2782 - categorical_crossentropy: 0.2782 - val_loss: 0.2787 - val_categorical_crossentropy: 0.2787\n",
      "Epoch 124/250\n",
      "Epoch 00124: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2830 - categorical_crossentropy: 0.2830 - val_loss: 0.2873 - val_categorical_crossentropy: 0.2873\n",
      "Epoch 125/250\n",
      "Epoch 00125: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2854 - categorical_crossentropy: 0.2854 - val_loss: 0.2846 - val_categorical_crossentropy: 0.2846\n",
      "Epoch 126/250\n",
      "Epoch 00126: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2822 - categorical_crossentropy: 0.2822 - val_loss: 0.2814 - val_categorical_crossentropy: 0.2814\n",
      "Epoch 127/250\n",
      "Epoch 00127: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2785 - categorical_crossentropy: 0.2785 - val_loss: 0.2788 - val_categorical_crossentropy: 0.2788\n",
      "Epoch 128/250\n",
      "Epoch 00128: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2807 - categorical_crossentropy: 0.2807 - val_loss: 0.2806 - val_categorical_crossentropy: 0.2806\n",
      "Epoch 129/250\n",
      "Epoch 00129: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2778 - categorical_crossentropy: 0.2778 - val_loss: 0.2779 - val_categorical_crossentropy: 0.2779\n",
      "Epoch 130/250\n",
      "Epoch 00130: categorical_crossentropy improved from 0.27778 to 0.27675, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2768 - categorical_crossentropy: 0.2768 - val_loss: 0.2785 - val_categorical_crossentropy: 0.2785\n",
      "Epoch 131/250\n",
      "Epoch 00131: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2781 - categorical_crossentropy: 0.2781 - val_loss: 0.2770 - val_categorical_crossentropy: 0.2770\n",
      "Epoch 132/250\n",
      "Epoch 00132: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2773 - categorical_crossentropy: 0.2773 - val_loss: 0.2783 - val_categorical_crossentropy: 0.2783\n",
      "Epoch 133/250\n",
      "Epoch 00133: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2879 - categorical_crossentropy: 0.2879 - val_loss: 0.2879 - val_categorical_crossentropy: 0.2879\n",
      "Epoch 134/250\n",
      "Epoch 00134: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2854 - categorical_crossentropy: 0.2854 - val_loss: 0.2853 - val_categorical_crossentropy: 0.2853\n",
      "Epoch 135/250\n",
      "Epoch 00135: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2830 - categorical_crossentropy: 0.2830 - val_loss: 0.2826 - val_categorical_crossentropy: 0.2826\n",
      "Epoch 136/250\n",
      "Epoch 00136: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2798 - categorical_crossentropy: 0.2798 - val_loss: 0.2783 - val_categorical_crossentropy: 0.2783\n",
      "Epoch 137/250\n",
      "Epoch 00137: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2784 - categorical_crossentropy: 0.2784 - val_loss: 0.2773 - val_categorical_crossentropy: 0.2773\n",
      "Epoch 138/250\n",
      "Epoch 00138: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2803 - categorical_crossentropy: 0.2803 - val_loss: 0.2805 - val_categorical_crossentropy: 0.2805\n",
      "Epoch 139/250\n",
      "Epoch 00139: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2774 - categorical_crossentropy: 0.2774 - val_loss: 0.2766 - val_categorical_crossentropy: 0.2766\n",
      "Epoch 140/250\n",
      "Epoch 00140: categorical_crossentropy improved from 0.27675 to 0.27585, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2758 - categorical_crossentropy: 0.2758 - val_loss: 0.2763 - val_categorical_crossentropy: 0.2763\n",
      "Epoch 141/250\n",
      "Epoch 00141: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2763 - categorical_crossentropy: 0.2763 - val_loss: 0.2763 - val_categorical_crossentropy: 0.2763\n",
      "Epoch 142/250\n",
      "Epoch 00142: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2759 - categorical_crossentropy: 0.2759 - val_loss: 0.2754 - val_categorical_crossentropy: 0.2754\n",
      "Epoch 143/250\n",
      "Epoch 00143: categorical_crossentropy improved from 0.27585 to 0.27555, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2756 - categorical_crossentropy: 0.2756 - val_loss: 0.2757 - val_categorical_crossentropy: 0.2757\n",
      "Epoch 144/250\n",
      "Epoch 00144: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2866 - categorical_crossentropy: 0.2866 - val_loss: 0.2895 - val_categorical_crossentropy: 0.2895\n",
      "Epoch 145/250\n",
      "Epoch 00145: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2867 - categorical_crossentropy: 0.2867 - val_loss: 0.2866 - val_categorical_crossentropy: 0.2866\n",
      "Epoch 146/250\n",
      "Epoch 00146: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2842 - categorical_crossentropy: 0.2842 - val_loss: 0.2844 - val_categorical_crossentropy: 0.2844\n",
      "Epoch 147/250\n",
      "Epoch 00147: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2821 - categorical_crossentropy: 0.2821 - val_loss: 0.2820 - val_categorical_crossentropy: 0.2820\n",
      "Epoch 148/250\n",
      "Epoch 00148: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2792 - categorical_crossentropy: 0.2792 - val_loss: 0.2778 - val_categorical_crossentropy: 0.2778\n",
      "Epoch 149/250\n",
      "Epoch 00149: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2760 - categorical_crossentropy: 0.2760 - val_loss: 0.2757 - val_categorical_crossentropy: 0.2757\n",
      "Epoch 150/250\n",
      "Epoch 00150: categorical_crossentropy improved from 0.27555 to 0.27510, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2751 - categorical_crossentropy: 0.2751 - val_loss: 0.2749 - val_categorical_crossentropy: 0.2749\n",
      "Epoch 151/250\n",
      "Epoch 00151: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2803 - categorical_crossentropy: 0.2803 - val_loss: 0.2784 - val_categorical_crossentropy: 0.2784\n",
      "Epoch 152/250\n",
      "Epoch 00152: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2755 - categorical_crossentropy: 0.2755 - val_loss: 0.2755 - val_categorical_crossentropy: 0.2755\n",
      "Epoch 153/250\n",
      "Epoch 00153: categorical_crossentropy improved from 0.27510 to 0.27435, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2744 - categorical_crossentropy: 0.2744 - val_loss: 0.2762 - val_categorical_crossentropy: 0.2762\n",
      "Epoch 154/250\n",
      "Epoch 00154: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2748 - categorical_crossentropy: 0.2748 - val_loss: 0.2743 - val_categorical_crossentropy: 0.2743\n",
      "Epoch 155/250\n",
      "Epoch 00155: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2846 - categorical_crossentropy: 0.2846 - val_loss: 0.2851 - val_categorical_crossentropy: 0.2851\n",
      "Epoch 156/250\n",
      "Epoch 00156: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2825 - categorical_crossentropy: 0.2825 - val_loss: 0.2820 - val_categorical_crossentropy: 0.2820\n",
      "Epoch 157/250\n",
      "Epoch 00157: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2789 - categorical_crossentropy: 0.2789 - val_loss: 0.2772 - val_categorical_crossentropy: 0.2772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/250\n",
      "Epoch 00158: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2750 - categorical_crossentropy: 0.2750 - val_loss: 0.2752 - val_categorical_crossentropy: 0.2752\n",
      "Epoch 159/250\n",
      "Epoch 00159: categorical_crossentropy improved from 0.27435 to 0.27410, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2741 - categorical_crossentropy: 0.2741 - val_loss: 0.2760 - val_categorical_crossentropy: 0.2760\n",
      "Epoch 160/250\n",
      "Epoch 00160: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2746 - categorical_crossentropy: 0.2746 - val_loss: 0.2766 - val_categorical_crossentropy: 0.2766\n",
      "Epoch 161/250\n",
      "Epoch 00161: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2744 - categorical_crossentropy: 0.2744 - val_loss: 0.2740 - val_categorical_crossentropy: 0.2740\n",
      "Epoch 162/250\n",
      "Epoch 00162: categorical_crossentropy improved from 0.27410 to 0.27381, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2738 - categorical_crossentropy: 0.2738 - val_loss: 0.2738 - val_categorical_crossentropy: 0.2738\n",
      "Epoch 163/250\n",
      "Epoch 00163: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2809 - categorical_crossentropy: 0.2809 - val_loss: 0.2798 - val_categorical_crossentropy: 0.2798\n",
      "Epoch 164/250\n",
      "Epoch 00164: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2757 - categorical_crossentropy: 0.2757 - val_loss: 0.2746 - val_categorical_crossentropy: 0.2746\n",
      "Epoch 165/250\n",
      "Epoch 00165: categorical_crossentropy improved from 0.27381 to 0.27354, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2735 - categorical_crossentropy: 0.2735 - val_loss: 0.2735 - val_categorical_crossentropy: 0.2735\n",
      "Epoch 166/250\n",
      "Epoch 00166: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2869 - categorical_crossentropy: 0.2869 - val_loss: 0.2838 - val_categorical_crossentropy: 0.2838\n",
      "Epoch 167/250\n",
      "Epoch 00167: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2808 - categorical_crossentropy: 0.2808 - val_loss: 0.2799 - val_categorical_crossentropy: 0.2799\n",
      "Epoch 168/250\n",
      "Epoch 00168: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2762 - categorical_crossentropy: 0.2762 - val_loss: 0.2748 - val_categorical_crossentropy: 0.2748\n",
      "Epoch 169/250\n",
      "Epoch 00169: categorical_crossentropy improved from 0.27354 to 0.27341, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2734 - categorical_crossentropy: 0.2734 - val_loss: 0.2735 - val_categorical_crossentropy: 0.2735\n",
      "Epoch 170/250\n",
      "Epoch 00170: categorical_crossentropy improved from 0.27341 to 0.27332, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2733 - categorical_crossentropy: 0.2733 - val_loss: 0.2738 - val_categorical_crossentropy: 0.2738\n",
      "Epoch 171/250\n",
      "Epoch 00171: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2749 - categorical_crossentropy: 0.2749 - val_loss: 0.2764 - val_categorical_crossentropy: 0.2764\n",
      "Epoch 172/250\n",
      "Epoch 00172: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2772 - categorical_crossentropy: 0.2772 - val_loss: 0.2749 - val_categorical_crossentropy: 0.2749\n",
      "Epoch 173/250\n",
      "Epoch 00173: categorical_crossentropy improved from 0.27332 to 0.27321, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2732 - categorical_crossentropy: 0.2732 - val_loss: 0.2734 - val_categorical_crossentropy: 0.2734\n",
      "Epoch 174/250\n",
      "Epoch 00174: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2804 - categorical_crossentropy: 0.2804 - val_loss: 0.2778 - val_categorical_crossentropy: 0.2778\n",
      "Epoch 175/250\n",
      "Epoch 00175: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2741 - categorical_crossentropy: 0.2741 - val_loss: 0.2755 - val_categorical_crossentropy: 0.2755\n",
      "Epoch 176/250\n",
      "Epoch 00176: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2741 - categorical_crossentropy: 0.2741 - val_loss: 0.2768 - val_categorical_crossentropy: 0.2768\n",
      "Epoch 177/250\n",
      "Epoch 00177: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2750 - categorical_crossentropy: 0.2750 - val_loss: 0.2798 - val_categorical_crossentropy: 0.2798\n",
      "Epoch 178/250\n",
      "Epoch 00178: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2761 - categorical_crossentropy: 0.2761 - val_loss: 0.2750 - val_categorical_crossentropy: 0.2750\n",
      "Epoch 179/250\n",
      "Epoch 00179: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2735 - categorical_crossentropy: 0.2735 - val_loss: 0.2756 - val_categorical_crossentropy: 0.2756\n",
      "Epoch 180/250\n",
      "Epoch 00180: categorical_crossentropy improved from 0.27321 to 0.27300, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2730 - categorical_crossentropy: 0.2730 - val_loss: 0.2740 - val_categorical_crossentropy: 0.2740\n",
      "Epoch 181/250\n",
      "Epoch 00181: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2739 - categorical_crossentropy: 0.2739 - val_loss: 0.2730 - val_categorical_crossentropy: 0.2730\n",
      "Epoch 182/250\n",
      "Epoch 00182: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2737 - categorical_crossentropy: 0.2737 - val_loss: 0.2753 - val_categorical_crossentropy: 0.2753\n",
      "Epoch 183/250\n",
      "Epoch 00183: categorical_crossentropy improved from 0.27300 to 0.27256, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2726 - categorical_crossentropy: 0.2726 - val_loss: 0.2730 - val_categorical_crossentropy: 0.2730\n",
      "Epoch 184/250\n",
      "Epoch 00184: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2733 - categorical_crossentropy: 0.2733 - val_loss: 0.2760 - val_categorical_crossentropy: 0.2760\n",
      "Epoch 185/250\n",
      "Epoch 00185: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2728 - categorical_crossentropy: 0.2728 - val_loss: 0.2730 - val_categorical_crossentropy: 0.2730\n",
      "Epoch 186/250\n",
      "Epoch 00186: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2737 - categorical_crossentropy: 0.2737 - val_loss: 0.2770 - val_categorical_crossentropy: 0.2770\n",
      "Epoch 187/250\n",
      "Epoch 00187: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2730 - categorical_crossentropy: 0.2730 - val_loss: 0.2739 - val_categorical_crossentropy: 0.2739\n",
      "Epoch 188/250\n",
      "Epoch 00188: categorical_crossentropy improved from 0.27256 to 0.27206, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.2721 - categorical_crossentropy: 0.2721 - val_loss: 0.2748 - val_categorical_crossentropy: 0.2748\n",
      "Epoch 189/250\n",
      "Epoch 00189: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2733 - categorical_crossentropy: 0.2733 - val_loss: 0.2864 - val_categorical_crossentropy: 0.2864\n",
      "Epoch 190/250\n",
      "Epoch 00190: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2785 - categorical_crossentropy: 0.2785 - val_loss: 0.2750 - val_categorical_crossentropy: 0.2750\n",
      "Epoch 191/250\n",
      "Epoch 00191: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2803 - categorical_crossentropy: 0.2803 - val_loss: 0.2815 - val_categorical_crossentropy: 0.2815\n",
      "Epoch 192/250\n",
      "Epoch 00192: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2775 - categorical_crossentropy: 0.2775 - val_loss: 0.2754 - val_categorical_crossentropy: 0.2754\n",
      "Epoch 193/250\n",
      "Epoch 00193: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2762 - categorical_crossentropy: 0.2762 - val_loss: 0.2818 - val_categorical_crossentropy: 0.2818\n",
      "Epoch 194/250\n",
      "Epoch 00194: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2789 - categorical_crossentropy: 0.2789 - val_loss: 0.2778 - val_categorical_crossentropy: 0.2778\n",
      "Epoch 195/250\n",
      "Epoch 00195: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2735 - categorical_crossentropy: 0.2735 - val_loss: 0.2727 - val_categorical_crossentropy: 0.2727\n",
      "Epoch 196/250\n",
      "Epoch 00196: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2726 - categorical_crossentropy: 0.2726 - val_loss: 0.2733 - val_categorical_crossentropy: 0.2733\n",
      "Epoch 197/250\n",
      "Epoch 00197: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2735 - categorical_crossentropy: 0.2735 - val_loss: 0.3010 - val_categorical_crossentropy: 0.3010\n",
      "Epoch 198/250\n",
      "Epoch 00198: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2873 - categorical_crossentropy: 0.2873 - val_loss: 0.2851 - val_categorical_crossentropy: 0.2851\n",
      "Epoch 00198: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 53, 7)             105       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 53, 7)             56        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None Training time : 101.453458070755s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history2 = model2.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    callbacks = [checkpoint, early])\n",
    "stop = time.time()\n",
    "t2 = stop-start\n",
    "print(model2.summary(), end=\" \")\n",
    "print(\"Training time : {}s\".format(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SRNN_steps = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "Finally, we can train a <b>GRU</b> (<b>G</b>ated <b>R</b>ecurrent <b>U</b>nits). It's a simplification of LSTMs. They also have a memory mechanism but with less parameters. As a result they are faster to train. You can find differences on <a href=\"https://datascience.stackexchange.com/questions/14581/what-is-difference-between-gru-and-lstm\" target=\"_blank\">this topic</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(GRU(units=nb_unit, input_shape=inp_shape, return_sequences=True))\n",
    "model3.add(Dense(7, activation='softmax'))\n",
    "model3.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"gru_simple.h5\",\n",
    "    monitor=loss_,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 256 samples\n",
      "Epoch 1/250\n",
      "Epoch 00001: categorical_crossentropy improved from inf to 1.15125, saving model to gru_simple.h5\n",
      " - 2s - loss: 1.1513 - categorical_crossentropy: 1.1513 - val_loss: 1.1144 - val_categorical_crossentropy: 1.1144\n",
      "Epoch 2/250\n",
      "Epoch 00002: categorical_crossentropy improved from 1.15125 to 1.06026, saving model to gru_simple.h5\n",
      " - 2s - loss: 1.0603 - categorical_crossentropy: 1.0603 - val_loss: 1.0054 - val_categorical_crossentropy: 1.0054\n",
      "Epoch 3/250\n",
      "Epoch 00003: categorical_crossentropy improved from 1.06026 to 0.98101, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.9810 - categorical_crossentropy: 0.9810 - val_loss: 0.9498 - val_categorical_crossentropy: 0.9498\n",
      "Epoch 4/250\n",
      "Epoch 00004: categorical_crossentropy improved from 0.98101 to 0.92562, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.9256 - categorical_crossentropy: 0.9256 - val_loss: 0.8860 - val_categorical_crossentropy: 0.8860\n",
      "Epoch 5/250\n",
      "Epoch 00005: categorical_crossentropy improved from 0.92562 to 0.85249, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.8525 - categorical_crossentropy: 0.8525 - val_loss: 0.8039 - val_categorical_crossentropy: 0.8039\n",
      "Epoch 6/250\n",
      "Epoch 00006: categorical_crossentropy improved from 0.85249 to 0.76780, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.7678 - categorical_crossentropy: 0.7678 - val_loss: 0.7205 - val_categorical_crossentropy: 0.7205\n",
      "Epoch 7/250\n",
      "Epoch 00007: categorical_crossentropy improved from 0.76780 to 0.68924, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.6892 - categorical_crossentropy: 0.6892 - val_loss: 0.6506 - val_categorical_crossentropy: 0.6506\n",
      "Epoch 8/250\n",
      "Epoch 00008: categorical_crossentropy improved from 0.68924 to 0.62483, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.6248 - categorical_crossentropy: 0.6248 - val_loss: 0.5944 - val_categorical_crossentropy: 0.5944\n",
      "Epoch 9/250\n",
      "Epoch 00009: categorical_crossentropy improved from 0.62483 to 0.57217, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.5722 - categorical_crossentropy: 0.5722 - val_loss: 0.5471 - val_categorical_crossentropy: 0.5471\n",
      "Epoch 10/250\n",
      "Epoch 00010: categorical_crossentropy improved from 0.57217 to 0.52774, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.5277 - categorical_crossentropy: 0.5277 - val_loss: 0.5077 - val_categorical_crossentropy: 0.5077\n",
      "Epoch 11/250\n",
      "Epoch 00011: categorical_crossentropy improved from 0.52774 to 0.49151, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4915 - categorical_crossentropy: 0.4915 - val_loss: 0.4755 - val_categorical_crossentropy: 0.4755\n",
      "Epoch 12/250\n",
      "Epoch 00012: categorical_crossentropy improved from 0.49151 to 0.46145, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.4614 - categorical_crossentropy: 0.4614 - val_loss: 0.4474 - val_categorical_crossentropy: 0.4474\n",
      "Epoch 13/250\n",
      "Epoch 00013: categorical_crossentropy improved from 0.46145 to 0.43427, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.4343 - categorical_crossentropy: 0.4343 - val_loss: 0.4216 - val_categorical_crossentropy: 0.4216\n",
      "Epoch 14/250\n",
      "Epoch 00014: categorical_crossentropy improved from 0.43427 to 0.41004, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.4100 - categorical_crossentropy: 0.4100 - val_loss: 0.3991 - val_categorical_crossentropy: 0.3991\n",
      "Epoch 15/250\n",
      "Epoch 00015: categorical_crossentropy improved from 0.41004 to 0.38917, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3892 - categorical_crossentropy: 0.3892 - val_loss: 0.3801 - val_categorical_crossentropy: 0.3801\n",
      "Epoch 16/250\n",
      "Epoch 00016: categorical_crossentropy improved from 0.38917 to 0.37193, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3719 - categorical_crossentropy: 0.3719 - val_loss: 0.3652 - val_categorical_crossentropy: 0.3652\n",
      "Epoch 17/250\n",
      "Epoch 00017: categorical_crossentropy improved from 0.37193 to 0.35820, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3582 - categorical_crossentropy: 0.3582 - val_loss: 0.3532 - val_categorical_crossentropy: 0.3532\n",
      "Epoch 18/250\n",
      "Epoch 00018: categorical_crossentropy improved from 0.35820 to 0.34741, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3474 - categorical_crossentropy: 0.3474 - val_loss: 0.3438 - val_categorical_crossentropy: 0.3438\n",
      "Epoch 19/250\n",
      "Epoch 00019: categorical_crossentropy improved from 0.34741 to 0.33898, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3390 - categorical_crossentropy: 0.3390 - val_loss: 0.3363 - val_categorical_crossentropy: 0.3363\n",
      "Epoch 20/250\n",
      "Epoch 00020: categorical_crossentropy improved from 0.33898 to 0.33229, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3323 - categorical_crossentropy: 0.3323 - val_loss: 0.3304 - val_categorical_crossentropy: 0.3304\n",
      "Epoch 21/250\n",
      "Epoch 00021: categorical_crossentropy improved from 0.33229 to 0.32692, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3269 - categorical_crossentropy: 0.3269 - val_loss: 0.3256 - val_categorical_crossentropy: 0.3256\n",
      "Epoch 22/250\n",
      "Epoch 00022: categorical_crossentropy improved from 0.32692 to 0.32258, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3226 - categorical_crossentropy: 0.3226 - val_loss: 0.3217 - val_categorical_crossentropy: 0.3217\n",
      "Epoch 23/250\n",
      "Epoch 00023: categorical_crossentropy improved from 0.32258 to 0.31913, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3191 - categorical_crossentropy: 0.3191 - val_loss: 0.3186 - val_categorical_crossentropy: 0.3186\n",
      "Epoch 24/250\n",
      "Epoch 00024: categorical_crossentropy improved from 0.31913 to 0.31638, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3164 - categorical_crossentropy: 0.3164 - val_loss: 0.3163 - val_categorical_crossentropy: 0.3163\n",
      "Epoch 25/250\n",
      "Epoch 00025: categorical_crossentropy improved from 0.31638 to 0.31417, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3142 - categorical_crossentropy: 0.3142 - val_loss: 0.3144 - val_categorical_crossentropy: 0.3144\n",
      "Epoch 26/250\n",
      "Epoch 00026: categorical_crossentropy improved from 0.31417 to 0.31234, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3123 - categorical_crossentropy: 0.3123 - val_loss: 0.3126 - val_categorical_crossentropy: 0.3126\n",
      "Epoch 27/250\n",
      "Epoch 00027: categorical_crossentropy improved from 0.31234 to 0.31075, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3107 - categorical_crossentropy: 0.3107 - val_loss: 0.3113 - val_categorical_crossentropy: 0.3113\n",
      "Epoch 28/250\n",
      "Epoch 00028: categorical_crossentropy improved from 0.31075 to 0.30932, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3093 - categorical_crossentropy: 0.3093 - val_loss: 0.3096 - val_categorical_crossentropy: 0.3096\n",
      "Epoch 29/250\n",
      "Epoch 00029: categorical_crossentropy improved from 0.30932 to 0.30811, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3081 - categorical_crossentropy: 0.3081 - val_loss: 0.3085 - val_categorical_crossentropy: 0.3085\n",
      "Epoch 30/250\n",
      "Epoch 00030: categorical_crossentropy improved from 0.30811 to 0.30698, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3070 - categorical_crossentropy: 0.3070 - val_loss: 0.3076 - val_categorical_crossentropy: 0.3076\n",
      "Epoch 31/250\n",
      "Epoch 00031: categorical_crossentropy improved from 0.30698 to 0.30595, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3059 - categorical_crossentropy: 0.3059 - val_loss: 0.3066 - val_categorical_crossentropy: 0.3066\n",
      "Epoch 32/250\n",
      "Epoch 00032: categorical_crossentropy improved from 0.30595 to 0.30503, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3050 - categorical_crossentropy: 0.3050 - val_loss: 0.3058 - val_categorical_crossentropy: 0.3058\n",
      "Epoch 33/250\n",
      "Epoch 00033: categorical_crossentropy improved from 0.30503 to 0.30421, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3042 - categorical_crossentropy: 0.3042 - val_loss: 0.3049 - val_categorical_crossentropy: 0.3049\n",
      "Epoch 34/250\n",
      "Epoch 00034: categorical_crossentropy improved from 0.30421 to 0.30346, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3035 - categorical_crossentropy: 0.3035 - val_loss: 0.3043 - val_categorical_crossentropy: 0.3043\n",
      "Epoch 35/250\n",
      "Epoch 00035: categorical_crossentropy improved from 0.30346 to 0.30274, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3027 - categorical_crossentropy: 0.3027 - val_loss: 0.3033 - val_categorical_crossentropy: 0.3033\n",
      "Epoch 36/250\n",
      "Epoch 00036: categorical_crossentropy improved from 0.30274 to 0.30212, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3021 - categorical_crossentropy: 0.3021 - val_loss: 0.3029 - val_categorical_crossentropy: 0.3029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "Epoch 00037: categorical_crossentropy improved from 0.30212 to 0.30150, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3015 - categorical_crossentropy: 0.3015 - val_loss: 0.3022 - val_categorical_crossentropy: 0.3022\n",
      "Epoch 38/250\n",
      "Epoch 00038: categorical_crossentropy improved from 0.30150 to 0.30096, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3010 - categorical_crossentropy: 0.3010 - val_loss: 0.3021 - val_categorical_crossentropy: 0.3021\n",
      "Epoch 39/250\n",
      "Epoch 00039: categorical_crossentropy improved from 0.30096 to 0.30049, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3005 - categorical_crossentropy: 0.3005 - val_loss: 0.3013 - val_categorical_crossentropy: 0.3013\n",
      "Epoch 40/250\n",
      "Epoch 00040: categorical_crossentropy improved from 0.30049 to 0.29999, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.3000 - categorical_crossentropy: 0.3000 - val_loss: 0.3007 - val_categorical_crossentropy: 0.3007\n",
      "Epoch 41/250\n",
      "Epoch 00041: categorical_crossentropy improved from 0.29999 to 0.29951, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2995 - categorical_crossentropy: 0.2995 - val_loss: 0.3004 - val_categorical_crossentropy: 0.3004\n",
      "Epoch 42/250\n",
      "Epoch 00042: categorical_crossentropy improved from 0.29951 to 0.29907, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2991 - categorical_crossentropy: 0.2991 - val_loss: 0.2997 - val_categorical_crossentropy: 0.2997\n",
      "Epoch 43/250\n",
      "Epoch 00043: categorical_crossentropy improved from 0.29907 to 0.29845, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2985 - categorical_crossentropy: 0.2985 - val_loss: 0.2990 - val_categorical_crossentropy: 0.2990\n",
      "Epoch 44/250\n",
      "Epoch 00044: categorical_crossentropy improved from 0.29845 to 0.29779, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2978 - categorical_crossentropy: 0.2978 - val_loss: 0.2987 - val_categorical_crossentropy: 0.2987\n",
      "Epoch 45/250\n",
      "Epoch 00045: categorical_crossentropy improved from 0.29779 to 0.29692, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2969 - categorical_crossentropy: 0.2969 - val_loss: 0.2977 - val_categorical_crossentropy: 0.2977\n",
      "Epoch 46/250\n",
      "Epoch 00046: categorical_crossentropy improved from 0.29692 to 0.29543, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2954 - categorical_crossentropy: 0.2954 - val_loss: 0.2991 - val_categorical_crossentropy: 0.2991\n",
      "Epoch 47/250\n",
      "Epoch 00047: categorical_crossentropy improved from 0.29543 to 0.29161, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2916 - categorical_crossentropy: 0.2916 - val_loss: 0.2867 - val_categorical_crossentropy: 0.2867\n",
      "Epoch 48/250\n",
      "Epoch 00048: categorical_crossentropy improved from 0.29161 to 0.28713, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2871 - categorical_crossentropy: 0.2871 - val_loss: 0.2879 - val_categorical_crossentropy: 0.2879\n",
      "Epoch 49/250\n",
      "Epoch 00049: categorical_crossentropy improved from 0.28713 to 0.28422, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2842 - categorical_crossentropy: 0.2842 - val_loss: 0.2822 - val_categorical_crossentropy: 0.2822\n",
      "Epoch 50/250\n",
      "Epoch 00050: categorical_crossentropy improved from 0.28422 to 0.28202, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2820 - categorical_crossentropy: 0.2820 - val_loss: 0.2798 - val_categorical_crossentropy: 0.2798\n",
      "Epoch 51/250\n",
      "Epoch 00051: categorical_crossentropy improved from 0.28202 to 0.27974, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2797 - categorical_crossentropy: 0.2797 - val_loss: 0.2825 - val_categorical_crossentropy: 0.2825\n",
      "Epoch 52/250\n",
      "Epoch 00052: categorical_crossentropy improved from 0.27974 to 0.27728, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2773 - categorical_crossentropy: 0.2773 - val_loss: 0.2750 - val_categorical_crossentropy: 0.2750\n",
      "Epoch 53/250\n",
      "Epoch 00053: categorical_crossentropy improved from 0.27728 to 0.27718, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2772 - categorical_crossentropy: 0.2772 - val_loss: 0.2747 - val_categorical_crossentropy: 0.2747\n",
      "Epoch 54/250\n",
      "Epoch 00054: categorical_crossentropy improved from 0.27718 to 0.27495, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2750 - categorical_crossentropy: 0.2750 - val_loss: 0.2732 - val_categorical_crossentropy: 0.2732\n",
      "Epoch 55/250\n",
      "Epoch 00055: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2750 - categorical_crossentropy: 0.2750 - val_loss: 0.2728 - val_categorical_crossentropy: 0.2728\n",
      "Epoch 56/250\n",
      "Epoch 00056: categorical_crossentropy improved from 0.27495 to 0.27327, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2733 - categorical_crossentropy: 0.2733 - val_loss: 0.2741 - val_categorical_crossentropy: 0.2741\n",
      "Epoch 57/250\n",
      "Epoch 00057: categorical_crossentropy improved from 0.27327 to 0.27269, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2727 - categorical_crossentropy: 0.2727 - val_loss: 0.2751 - val_categorical_crossentropy: 0.2751\n",
      "Epoch 58/250\n",
      "Epoch 00058: categorical_crossentropy improved from 0.27269 to 0.27166, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2717 - categorical_crossentropy: 0.2717 - val_loss: 0.2706 - val_categorical_crossentropy: 0.2706\n",
      "Epoch 59/250\n",
      "Epoch 00059: categorical_crossentropy improved from 0.27166 to 0.27065, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2707 - categorical_crossentropy: 0.2707 - val_loss: 0.2703 - val_categorical_crossentropy: 0.2703\n",
      "Epoch 60/250\n",
      "Epoch 00060: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2709 - categorical_crossentropy: 0.2709 - val_loss: 0.2702 - val_categorical_crossentropy: 0.2702\n",
      "Epoch 61/250\n",
      "Epoch 00061: categorical_crossentropy improved from 0.27065 to 0.27005, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2701 - categorical_crossentropy: 0.2701 - val_loss: 0.2693 - val_categorical_crossentropy: 0.2693\n",
      "Epoch 62/250\n",
      "Epoch 00062: categorical_crossentropy improved from 0.27005 to 0.26848, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2685 - categorical_crossentropy: 0.2685 - val_loss: 0.2683 - val_categorical_crossentropy: 0.2683\n",
      "Epoch 63/250\n",
      "Epoch 00063: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2699 - categorical_crossentropy: 0.2699 - val_loss: 0.2726 - val_categorical_crossentropy: 0.2726\n",
      "Epoch 64/250\n",
      "Epoch 00064: categorical_crossentropy improved from 0.26848 to 0.26821, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2682 - categorical_crossentropy: 0.2682 - val_loss: 0.2694 - val_categorical_crossentropy: 0.2694\n",
      "Epoch 65/250\n",
      "Epoch 00065: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2689 - categorical_crossentropy: 0.2689 - val_loss: 0.2677 - val_categorical_crossentropy: 0.2677\n",
      "Epoch 66/250\n",
      "Epoch 00066: categorical_crossentropy improved from 0.26821 to 0.26776, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2678 - categorical_crossentropy: 0.2678 - val_loss: 0.2674 - val_categorical_crossentropy: 0.2674\n",
      "Epoch 67/250\n",
      "Epoch 00067: categorical_crossentropy improved from 0.26776 to 0.26722, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2672 - categorical_crossentropy: 0.2672 - val_loss: 0.2679 - val_categorical_crossentropy: 0.2679\n",
      "Epoch 68/250\n",
      "Epoch 00068: categorical_crossentropy improved from 0.26722 to 0.26677, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2668 - categorical_crossentropy: 0.2668 - val_loss: 0.2738 - val_categorical_crossentropy: 0.2738\n",
      "Epoch 69/250\n",
      "Epoch 00069: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2668 - categorical_crossentropy: 0.2668 - val_loss: 0.2667 - val_categorical_crossentropy: 0.2667\n",
      "Epoch 70/250\n",
      "Epoch 00070: categorical_crossentropy improved from 0.26677 to 0.26658, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2666 - categorical_crossentropy: 0.2666 - val_loss: 0.2662 - val_categorical_crossentropy: 0.2662\n",
      "Epoch 71/250\n",
      "Epoch 00071: categorical_crossentropy improved from 0.26658 to 0.26618, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2662 - categorical_crossentropy: 0.2662 - val_loss: 0.2662 - val_categorical_crossentropy: 0.2662\n",
      "Epoch 72/250\n",
      "Epoch 00072: categorical_crossentropy improved from 0.26618 to 0.26542, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2654 - categorical_crossentropy: 0.2654 - val_loss: 0.2654 - val_categorical_crossentropy: 0.2654\n",
      "Epoch 73/250\n",
      "Epoch 00073: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2660 - categorical_crossentropy: 0.2660 - val_loss: 0.2687 - val_categorical_crossentropy: 0.2687\n",
      "Epoch 74/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00074: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2657 - categorical_crossentropy: 0.2657 - val_loss: 0.2650 - val_categorical_crossentropy: 0.2650\n",
      "Epoch 75/250\n",
      "Epoch 00075: categorical_crossentropy improved from 0.26542 to 0.26509, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2651 - categorical_crossentropy: 0.2651 - val_loss: 0.2650 - val_categorical_crossentropy: 0.2650\n",
      "Epoch 76/250\n",
      "Epoch 00076: categorical_crossentropy improved from 0.26509 to 0.26490, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2649 - categorical_crossentropy: 0.2649 - val_loss: 0.2656 - val_categorical_crossentropy: 0.2656\n",
      "Epoch 77/250\n",
      "Epoch 00077: categorical_crossentropy improved from 0.26490 to 0.26454, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2645 - categorical_crossentropy: 0.2645 - val_loss: 0.2649 - val_categorical_crossentropy: 0.2649\n",
      "Epoch 78/250\n",
      "Epoch 00078: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2652 - categorical_crossentropy: 0.2652 - val_loss: 0.2663 - val_categorical_crossentropy: 0.2663\n",
      "Epoch 79/250\n",
      "Epoch 00079: categorical_crossentropy improved from 0.26454 to 0.26421, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2642 - categorical_crossentropy: 0.2642 - val_loss: 0.2658 - val_categorical_crossentropy: 0.2658\n",
      "Epoch 80/250\n",
      "Epoch 00080: categorical_crossentropy improved from 0.26421 to 0.26415, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2642 - categorical_crossentropy: 0.2642 - val_loss: 0.2640 - val_categorical_crossentropy: 0.2640\n",
      "Epoch 81/250\n",
      "Epoch 00081: categorical_crossentropy improved from 0.26415 to 0.26409, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2641 - categorical_crossentropy: 0.2641 - val_loss: 0.2639 - val_categorical_crossentropy: 0.2639\n",
      "Epoch 82/250\n",
      "Epoch 00082: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2643 - categorical_crossentropy: 0.2643 - val_loss: 0.2643 - val_categorical_crossentropy: 0.2643\n",
      "Epoch 83/250\n",
      "Epoch 00083: categorical_crossentropy improved from 0.26409 to 0.26370, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2637 - categorical_crossentropy: 0.2637 - val_loss: 0.2636 - val_categorical_crossentropy: 0.2636\n",
      "Epoch 84/250\n",
      "Epoch 00084: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2641 - categorical_crossentropy: 0.2641 - val_loss: 0.2641 - val_categorical_crossentropy: 0.2641\n",
      "Epoch 85/250\n",
      "Epoch 00085: categorical_crossentropy improved from 0.26370 to 0.26295, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2629 - categorical_crossentropy: 0.2629 - val_loss: 0.2648 - val_categorical_crossentropy: 0.2648\n",
      "Epoch 86/250\n",
      "Epoch 00086: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2632 - categorical_crossentropy: 0.2632 - val_loss: 0.2660 - val_categorical_crossentropy: 0.2660\n",
      "Epoch 87/250\n",
      "Epoch 00087: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2635 - categorical_crossentropy: 0.2635 - val_loss: 0.2664 - val_categorical_crossentropy: 0.2664\n",
      "Epoch 88/250\n",
      "Epoch 00088: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2632 - categorical_crossentropy: 0.2632 - val_loss: 0.2634 - val_categorical_crossentropy: 0.2634\n",
      "Epoch 89/250\n",
      "Epoch 00089: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2636 - categorical_crossentropy: 0.2636 - val_loss: 0.2634 - val_categorical_crossentropy: 0.2634\n",
      "Epoch 90/250\n",
      "Epoch 00090: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2630 - categorical_crossentropy: 0.2630 - val_loss: 0.2662 - val_categorical_crossentropy: 0.2662\n",
      "Epoch 91/250\n",
      "Epoch 00091: categorical_crossentropy improved from 0.26295 to 0.26251, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2625 - categorical_crossentropy: 0.2625 - val_loss: 0.2628 - val_categorical_crossentropy: 0.2628\n",
      "Epoch 92/250\n",
      "Epoch 00092: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2629 - categorical_crossentropy: 0.2629 - val_loss: 0.2642 - val_categorical_crossentropy: 0.2642\n",
      "Epoch 93/250\n",
      "Epoch 00093: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2626 - categorical_crossentropy: 0.2626 - val_loss: 0.2632 - val_categorical_crossentropy: 0.2632\n",
      "Epoch 94/250\n",
      "Epoch 00094: categorical_crossentropy improved from 0.26251 to 0.26191, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2619 - categorical_crossentropy: 0.2619 - val_loss: 0.2624 - val_categorical_crossentropy: 0.2624\n",
      "Epoch 95/250\n",
      "Epoch 00095: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2626 - categorical_crossentropy: 0.2626 - val_loss: 0.2625 - val_categorical_crossentropy: 0.2625\n",
      "Epoch 96/250\n",
      "Epoch 00096: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2622 - categorical_crossentropy: 0.2622 - val_loss: 0.2673 - val_categorical_crossentropy: 0.2673\n",
      "Epoch 97/250\n",
      "Epoch 00097: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2623 - categorical_crossentropy: 0.2623 - val_loss: 0.2622 - val_categorical_crossentropy: 0.2622\n",
      "Epoch 98/250\n",
      "Epoch 00098: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2624 - categorical_crossentropy: 0.2624 - val_loss: 0.2646 - val_categorical_crossentropy: 0.2646\n",
      "Epoch 99/250\n",
      "Epoch 00099: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2620 - categorical_crossentropy: 0.2620 - val_loss: 0.2638 - val_categorical_crossentropy: 0.2638\n",
      "Epoch 100/250\n",
      "Epoch 00100: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2623 - categorical_crossentropy: 0.2623 - val_loss: 0.2654 - val_categorical_crossentropy: 0.2654\n",
      "Epoch 101/250\n",
      "Epoch 00101: categorical_crossentropy improved from 0.26191 to 0.26156, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2616 - categorical_crossentropy: 0.2616 - val_loss: 0.2623 - val_categorical_crossentropy: 0.2623\n",
      "Epoch 102/250\n",
      "Epoch 00102: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2617 - categorical_crossentropy: 0.2617 - val_loss: 0.2623 - val_categorical_crossentropy: 0.2623\n",
      "Epoch 103/250\n",
      "Epoch 00103: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2621 - categorical_crossentropy: 0.2621 - val_loss: 0.2634 - val_categorical_crossentropy: 0.2634\n",
      "Epoch 104/250\n",
      "Epoch 00104: categorical_crossentropy improved from 0.26156 to 0.26146, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2615 - categorical_crossentropy: 0.2615 - val_loss: 0.2627 - val_categorical_crossentropy: 0.2627\n",
      "Epoch 105/250\n",
      "Epoch 00105: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2619 - categorical_crossentropy: 0.2619 - val_loss: 0.2619 - val_categorical_crossentropy: 0.2619\n",
      "Epoch 106/250\n",
      "Epoch 00106: categorical_crossentropy improved from 0.26146 to 0.26139, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2614 - categorical_crossentropy: 0.2614 - val_loss: 0.2615 - val_categorical_crossentropy: 0.2615\n",
      "Epoch 107/250\n",
      "Epoch 00107: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2615 - categorical_crossentropy: 0.2615 - val_loss: 0.2617 - val_categorical_crossentropy: 0.2617\n",
      "Epoch 108/250\n",
      "Epoch 00108: categorical_crossentropy improved from 0.26139 to 0.26067, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2607 - categorical_crossentropy: 0.2607 - val_loss: 0.2636 - val_categorical_crossentropy: 0.2636\n",
      "Epoch 109/250\n",
      "Epoch 00109: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2615 - categorical_crossentropy: 0.2615 - val_loss: 0.2616 - val_categorical_crossentropy: 0.2616\n",
      "Epoch 110/250\n",
      "Epoch 00110: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2615 - categorical_crossentropy: 0.2615 - val_loss: 0.2673 - val_categorical_crossentropy: 0.2673\n",
      "Epoch 111/250\n",
      "Epoch 00111: categorical_crossentropy improved from 0.26067 to 0.26067, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2607 - categorical_crossentropy: 0.2607 - val_loss: 0.2625 - val_categorical_crossentropy: 0.2625\n",
      "Epoch 112/250\n",
      "Epoch 00112: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2621 - categorical_crossentropy: 0.2621 - val_loss: 0.2614 - val_categorical_crossentropy: 0.2614\n",
      "Epoch 113/250\n",
      "Epoch 00113: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2609 - categorical_crossentropy: 0.2609 - val_loss: 0.2610 - val_categorical_crossentropy: 0.2610\n",
      "Epoch 114/250\n",
      "Epoch 00114: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2612 - categorical_crossentropy: 0.2612 - val_loss: 0.2643 - val_categorical_crossentropy: 0.2643\n",
      "Epoch 115/250\n",
      "Epoch 00115: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2607 - categorical_crossentropy: 0.2607 - val_loss: 0.2612 - val_categorical_crossentropy: 0.2612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/250\n",
      "Epoch 00116: categorical_crossentropy improved from 0.26067 to 0.26065, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2607 - categorical_crossentropy: 0.2607 - val_loss: 0.2684 - val_categorical_crossentropy: 0.2684\n",
      "Epoch 117/250\n",
      "Epoch 00117: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2610 - categorical_crossentropy: 0.2610 - val_loss: 0.2609 - val_categorical_crossentropy: 0.2609\n",
      "Epoch 118/250\n",
      "Epoch 00118: categorical_crossentropy improved from 0.26065 to 0.26033, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2603 - categorical_crossentropy: 0.2603 - val_loss: 0.2632 - val_categorical_crossentropy: 0.2632\n",
      "Epoch 119/250\n",
      "Epoch 00119: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2606 - categorical_crossentropy: 0.2606 - val_loss: 0.2616 - val_categorical_crossentropy: 0.2616\n",
      "Epoch 120/250\n",
      "Epoch 00120: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2611 - categorical_crossentropy: 0.2611 - val_loss: 0.2653 - val_categorical_crossentropy: 0.2653\n",
      "Epoch 121/250\n",
      "Epoch 00121: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2606 - categorical_crossentropy: 0.2606 - val_loss: 0.2609 - val_categorical_crossentropy: 0.2609\n",
      "Epoch 122/250\n",
      "Epoch 00122: categorical_crossentropy improved from 0.26033 to 0.26028, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2603 - categorical_crossentropy: 0.2603 - val_loss: 0.2650 - val_categorical_crossentropy: 0.2650\n",
      "Epoch 123/250\n",
      "Epoch 00123: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2608 - categorical_crossentropy: 0.2608 - val_loss: 0.2607 - val_categorical_crossentropy: 0.2607\n",
      "Epoch 124/250\n",
      "Epoch 00124: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2609 - categorical_crossentropy: 0.2609 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 125/250\n",
      "Epoch 00125: categorical_crossentropy improved from 0.26028 to 0.26027, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2603 - categorical_crossentropy: 0.2603 - val_loss: 0.2604 - val_categorical_crossentropy: 0.2604\n",
      "Epoch 126/250\n",
      "Epoch 00126: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2605 - categorical_crossentropy: 0.2605 - val_loss: 0.2609 - val_categorical_crossentropy: 0.2609\n",
      "Epoch 127/250\n",
      "Epoch 00127: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2606 - categorical_crossentropy: 0.2606 - val_loss: 0.2609 - val_categorical_crossentropy: 0.2609\n",
      "Epoch 128/250\n",
      "Epoch 00128: categorical_crossentropy improved from 0.26027 to 0.26027, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2603 - categorical_crossentropy: 0.2603 - val_loss: 0.2695 - val_categorical_crossentropy: 0.2695\n",
      "Epoch 129/250\n",
      "Epoch 00129: categorical_crossentropy improved from 0.26027 to 0.26015, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2602 - categorical_crossentropy: 0.2602 - val_loss: 0.2605 - val_categorical_crossentropy: 0.2605\n",
      "Epoch 130/250\n",
      "Epoch 00130: categorical_crossentropy improved from 0.26015 to 0.26000, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2600 - categorical_crossentropy: 0.2600 - val_loss: 0.2610 - val_categorical_crossentropy: 0.2610\n",
      "Epoch 131/250\n",
      "Epoch 00131: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2603 - categorical_crossentropy: 0.2603 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 132/250\n",
      "Epoch 00132: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2606 - categorical_crossentropy: 0.2606 - val_loss: 0.2675 - val_categorical_crossentropy: 0.2675\n",
      "Epoch 133/250\n",
      "Epoch 00133: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2608 - categorical_crossentropy: 0.2608 - val_loss: 0.2603 - val_categorical_crossentropy: 0.2603\n",
      "Epoch 134/250\n",
      "Epoch 00134: categorical_crossentropy improved from 0.26000 to 0.25966, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2597 - categorical_crossentropy: 0.2597 - val_loss: 0.2637 - val_categorical_crossentropy: 0.2637\n",
      "Epoch 135/250\n",
      "Epoch 00135: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2598 - categorical_crossentropy: 0.2598 - val_loss: 0.2602 - val_categorical_crossentropy: 0.2602\n",
      "Epoch 136/250\n",
      "Epoch 00136: categorical_crossentropy improved from 0.25966 to 0.25965, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2596 - categorical_crossentropy: 0.2596 - val_loss: 0.2609 - val_categorical_crossentropy: 0.2609\n",
      "Epoch 137/250\n",
      "Epoch 00137: categorical_crossentropy improved from 0.25965 to 0.25950, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2595 - categorical_crossentropy: 0.2595 - val_loss: 0.2602 - val_categorical_crossentropy: 0.2602\n",
      "Epoch 138/250\n",
      "Epoch 00138: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2598 - categorical_crossentropy: 0.2598 - val_loss: 0.2604 - val_categorical_crossentropy: 0.2604\n",
      "Epoch 139/250\n",
      "Epoch 00139: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2598 - categorical_crossentropy: 0.2598 - val_loss: 0.2631 - val_categorical_crossentropy: 0.2631\n",
      "Epoch 140/250\n",
      "Epoch 00140: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2597 - categorical_crossentropy: 0.2597 - val_loss: 0.2618 - val_categorical_crossentropy: 0.2618\n",
      "Epoch 141/250\n",
      "Epoch 00141: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2601 - categorical_crossentropy: 0.2601 - val_loss: 0.2602 - val_categorical_crossentropy: 0.2602\n",
      "Epoch 142/250\n",
      "Epoch 00142: categorical_crossentropy improved from 0.25950 to 0.25905, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.2590 - categorical_crossentropy: 0.2590 - val_loss: 0.2626 - val_categorical_crossentropy: 0.2626\n",
      "Epoch 143/250\n",
      "Epoch 00143: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2595 - categorical_crossentropy: 0.2595 - val_loss: 0.2600 - val_categorical_crossentropy: 0.2600\n",
      "Epoch 144/250\n",
      "Epoch 00144: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2607 - categorical_crossentropy: 0.2607 - val_loss: 0.2610 - val_categorical_crossentropy: 0.2610\n",
      "Epoch 145/250\n",
      "Epoch 00145: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2596 - categorical_crossentropy: 0.2596 - val_loss: 0.2608 - val_categorical_crossentropy: 0.2608\n",
      "Epoch 146/250\n",
      "Epoch 00146: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2598 - categorical_crossentropy: 0.2598 - val_loss: 0.2613 - val_categorical_crossentropy: 0.2613\n",
      "Epoch 147/250\n",
      "Epoch 00147: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2594 - categorical_crossentropy: 0.2594 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 148/250\n",
      "Epoch 00148: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2596 - categorical_crossentropy: 0.2596 - val_loss: 0.2599 - val_categorical_crossentropy: 0.2599\n",
      "Epoch 149/250\n",
      "Epoch 00149: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2596 - categorical_crossentropy: 0.2596 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 150/250\n",
      "Epoch 00150: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2594 - categorical_crossentropy: 0.2594 - val_loss: 0.2606 - val_categorical_crossentropy: 0.2606\n",
      "Epoch 151/250\n",
      "Epoch 00151: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2600 - categorical_crossentropy: 0.2600 - val_loss: 0.2599 - val_categorical_crossentropy: 0.2599\n",
      "Epoch 152/250\n",
      "Epoch 00152: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.2591 - categorical_crossentropy: 0.2591 - val_loss: 0.2599 - val_categorical_crossentropy: 0.2599\n",
      "Epoch 00152: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 53, 7)             315       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 53, 7)             56        \n",
      "=================================================================\n",
      "Total params: 371\n",
      "Trainable params: 371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None Training time : 230.32060170173645s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history3 = model3.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    callbacks = [checkpoint, early])\n",
    "stop = time.time()\n",
    "t3 = stop-start\n",
    "print(model3.summary(), end=\" \")\n",
    "print(\"Training time : {}s\".format(t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GRU_steps = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We can first check the time used to train them on the same dataset with the same number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-331fb464ae6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LSTM :       {:.2f}s\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Simple RNN : {:.2f}s\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GRU :        {:.2f}s\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't1' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"LSTM :       {:.2f}s\".format(t1))\n",
    "print(\"Simple RNN : {:.2f}s\".format(t2))\n",
    "print(\"GRU :        {:.2f}s\".format(t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the simple RNN is the fastest to train because there is nearly no impact of provide the output as input. It's only and addtion to do on Matrices. However, LSTM and GRU are slower to train and as expected, GRU trained faster than LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [207, 250, 250]\n",
      "time [164.06, 181.82, 330.12]\n"
     ]
    }
   ],
   "source": [
    "print(\"epoch\", [LSTM_steps, SRNN_steps, GRU_steps])\n",
    "print(\"time\", [164.06, 181.82, 330.12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a860639e91a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pastel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LSTM\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"SimpleRNN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"GRU\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training time\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"muted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAHUCAYAAADWXIWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njgEAIIljAABI4hgAAJI4BgCA9D9daMSaik5nvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bae9d19c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=[t1, t2, t3] , y=[\"LSTM\", \"SimpleRNN\", \"GRU\"], label=\"Training time\", color=\"b\")\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=[LSTM_steps, SRNN_steps, GRU_steps], y=[\"LSTM\", \"SimpleRNN\", \"GRU\"], label=\"Training Epoch\", color=\"b\")\n",
    "\n",
    "\n",
    "\n",
    "# Add a legend and informative axis label\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(xlim=(0, 350), ylabel=\"\",\n",
    "       xlabel=\"Epochs/Time(s)\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig(\"barplot_softmax.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In term of loss TO BE DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_crossentropy', 'loss', 'categorical_crossentropy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAK9CAYAAAAE1vtiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24c6b871780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "key_ = list(history.history.keys())[3]\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(history.history[key_], label=\"LSTM\")\n",
    "plt.plot(history2.history[key_], label=\"SimpleRNN\")\n",
    "plt.plot(history3.history[key_], label=\"GRU\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.savefig(\"loss_softmax.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that GRU and LSTM perform better than a Simple RNN. LSTM is also performing slightly better that GRU but require more computation time. We can also check the output and compare it to the real output provided by the graph (see the y description in preparation of data section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :\n",
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]]]\n",
      "\n",
      "\n",
      "LSTM predicts :\n",
      "[[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "\n",
      "\n",
      "GRU predicts :\n",
      "[[ 0.974]\n",
      " [ 0.807]\n",
      " [ 0.719]\n",
      " [ 1.184]\n",
      " [ 0.944]\n",
      " [ 0.999]\n",
      " [ 1.426]\n",
      " [ 0.957]\n",
      " [ 0.999]\n",
      " [ 1.212]\n",
      " [ 1.52 ]\n",
      " [ 0.954]\n",
      " [ 0.42 ]\n",
      " [ 0.83 ]\n",
      " [ 0.903]\n",
      " [ 0.944]\n",
      " [ 0.976]\n",
      " [ 1.005]\n",
      " [ 1.022]\n",
      " [ 1.029]]\n",
      "\n",
      "\n",
      "SRNN predicts :\n",
      "[[[ 0.     0.539  0.001  0.001  0.456  0.001  0.001]\n",
      "  [ 0.     0.662  0.039  0.051  0.002  0.246  0.   ]\n",
      "  [ 0.     0.63   0.007  0.005  0.001  0.356  0.   ]\n",
      "  [ 0.     0.002  0.     0.     0.764  0.232  0.002]\n",
      "  [ 0.     0.012  0.218  0.761  0.     0.007  0.002]\n",
      "  [ 0.     0.568  0.002  0.014  0.001  0.414  0.002]\n",
      "  [ 0.     0.002  0.     0.     0.745  0.251  0.002]\n",
      "  [ 0.     0.016  0.207  0.766  0.     0.009  0.002]\n",
      "  [ 0.     0.571  0.001  0.012  0.001  0.413  0.002]\n",
      "  [ 0.     0.578  0.005  0.006  0.001  0.41   0.   ]\n",
      "  [ 0.     0.002  0.     0.     0.752  0.244  0.002]\n",
      "  [ 0.     0.014  0.211  0.765  0.     0.008  0.002]\n",
      "  [ 0.     0.008  0.019  0.002  0.001  0.002  0.968]\n",
      "  [ 0.003  0.03   0.418  0.527  0.005  0.005  0.012]\n",
      "  [ 0.007  0.387  0.232  0.137  0.03   0.153  0.055]\n",
      "  [ 0.004  0.454  0.055  0.034  0.156  0.295  0.002]\n",
      "  [ 0.003  0.38   0.025  0.014  0.218  0.358  0.003]\n",
      "  [ 0.004  0.334  0.046  0.031  0.226  0.353  0.006]\n",
      "  [ 0.005  0.32   0.072  0.051  0.211  0.331  0.009]\n",
      "  [ 0.006  0.328  0.081  0.058  0.197  0.321  0.01 ]]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input :\")\n",
    "print(X_val)\n",
    "print(\"\\n\\nLSTM predicts :\")\n",
    "y_pred = model.predict(X_val)\n",
    "print(np.sum(y_pred, axis=2).reshape(-1,1))\n",
    "print(\"\\n\\nGRU predicts :\")\n",
    "y_pred = model3.predict(X_val)\n",
    "print(np.sum(y_pred, axis=2).reshape(-1,1))\n",
    "print(\"\\n\\nSRNN predicts :\")\n",
    "y_pred = model2.predict(X_val)\n",
    "print(y_pred)\n",
    "print(np.sum(y_pred, axis=2).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply the output by removing small output and compare it to the possible output (we will only keep prediction from GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred = np.where(y_pred < 0.1, 0, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.     0.54   0.     0.     0.407  0.     0.   ] \t [0 1 0 0 1 0 0]\n",
      "[ 0.     0.     0.66   0.314  0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.     0.     0.957  0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.628  0.     0.     0.     0.372  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.555  0.     0.     0.     0.372  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.996  0.319  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.     0.     0.167  0.55   0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.486  0.     0.     0.     0.51   0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.992  0.499  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.     0.     0.301  0.55   0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.396  0.     0.     0.     0.592  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.689  0.     0.     0.     0.592  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.997  0.592  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.    0.    0.37  0.55  0.    0.    0.  ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.327  0.     0.     0.     0.599  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.967  0.599  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.     0.     0.     0.     0.     0.     0.874] \t [0 0 0 0 0 0 1]\n",
      "[ 0.     0.     0.128  0.337  0.     0.     0.378] \t [0 0 0 0 0 0 0]\n",
      "[ 0.     0.379  0.     0.113  0.     0.284  0.193] \t [0 0 0 0 0 0 0]\n",
      "[ 0.     0.469  0.     0.     0.13   0.295  0.193] \t [0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for pred, real in zip(y_pred[0], y_possible[0]):\n",
    "    print(pred, \"\\t\", real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah !! Output is balanced between both offset but with different \"probabilities\". We can also check how well they are to generate sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it as generator\n",
    "\n",
    "As explained previously, we trained our model as a many-to-many RNN. Now we want a generator so we are going to use a one-to-many model but reusing knowledge from the training. \n",
    "\n",
    "Before that, we will need an evaluation function which take the output, pick the next input based on the probability to have this output, create the next input and run it until the graph is over. After that, we will check is the created word is really a Reber word. This will be done with following functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pick_From_Output(x):\n",
    "    y = np.zeros_like(x)\n",
    "#     x = np.where(x < 0.1, 0, x)\n",
    "    x = x[0]/x[0].sum(axis=1)\n",
    "    i = np.random.choice(list(range(7)), size=1, p=x[0])\n",
    "    y[0,0,i] = 1\n",
    "    return y\n",
    "\n",
    "def evaluate(model, nb_word = 1, max_iter = 100, errors = None):\n",
    "    good_pred = 0\n",
    "    if errors is None:\n",
    "        errors = {1:0, 2:0, 3:0, 4:0}\n",
    "    for _ in range(nb_word):\n",
    "        model.reset_states()\n",
    "        first_input = np.array([[[1,0,0,0,0,0,0]]])\n",
    "        word = \"B\"\n",
    "        loop = 0\n",
    "        nextLetter = \"B\"\n",
    "        next_seq = first_input\n",
    "        count_E = 0\n",
    "        while count_E < 2 and loop < max_iter:\n",
    "            y_pred = model.predict(next_seq)\n",
    "            next_seq = Pick_From_Output(y_pred)\n",
    "            nextLetter = reber.sequenceToWord(next_seq[0])\n",
    "            loop += 1\n",
    "            word += nextLetter\n",
    "            if nextLetter == \"E\":\n",
    "                count_E += 1\n",
    "#         print(word)\n",
    "        code = reber.in_embedded_grammar(word)\n",
    "        if code == 0:\n",
    "            good_pred += 1\n",
    "        else:\n",
    "#             print(word, code)\n",
    "            errors[code] += 1\n",
    "    print(errors)\n",
    "    acc = 100*good_pred/nb_word\n",
    "    print(\"Good prediction : {:.2f}%\".format(acc))\n",
    "    return acc, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create both model as one-to-many and evaluate them 20 times on 100 words generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = load_model(\"lstm_simple.h5\")  # lstm_simple /  srnn_simple / gru_simple\n",
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(LSTM(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.add(Dense(7, activation='softmax'))\n",
    "newModel.set_weights(Model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 55, 4: 2}\n",
      "Good prediction : 43.00%\n",
      "{1: 0, 2: 0, 3: 105, 4: 2}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 0, 3: 163, 4: 3}\n",
      "Good prediction : 41.00%\n",
      "{1: 0, 2: 0, 3: 221, 4: 4}\n",
      "Good prediction : 41.00%\n",
      "{1: 0, 2: 1, 3: 270, 4: 5}\n",
      "Good prediction : 49.00%\n",
      "{1: 0, 2: 2, 3: 321, 4: 6}\n",
      "Good prediction : 47.00%\n",
      "{1: 0, 2: 3, 3: 371, 4: 6}\n",
      "Good prediction : 49.00%\n",
      "{1: 0, 2: 3, 3: 419, 4: 11}\n",
      "Good prediction : 47.00%\n",
      "{1: 0, 2: 3, 3: 468, 4: 11}\n",
      "Good prediction : 51.00%\n",
      "{1: 0, 2: 3, 3: 519, 4: 13}\n",
      "Good prediction : 47.00%\n",
      "{1: 0, 2: 4, 3: 572, 4: 16}\n",
      "Good prediction : 43.00%\n",
      "{1: 0, 2: 4, 3: 619, 4: 18}\n",
      "Good prediction : 51.00%\n",
      "{1: 0, 2: 4, 3: 666, 4: 22}\n",
      "Good prediction : 49.00%\n",
      "{1: 0, 2: 4, 3: 717, 4: 26}\n",
      "Good prediction : 45.00%\n",
      "{1: 0, 2: 5, 3: 771, 4: 29}\n",
      "Good prediction : 42.00%\n",
      "{1: 0, 2: 5, 3: 825, 4: 30}\n",
      "Good prediction : 45.00%\n",
      "{1: 0, 2: 7, 3: 874, 4: 32}\n",
      "Good prediction : 47.00%\n",
      "{1: 0, 2: 7, 3: 922, 4: 34}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 8, 3: 973, 4: 36}\n",
      "Good prediction : 46.00%\n",
      "{1: 0, 2: 8, 3: 1020, 4: 40}\n",
      "Good prediction : 49.00%\n",
      "{1: 0, 2: 8, 3: 1020, 4: 40}\n"
     ]
    }
   ],
   "source": [
    "error_LSTM = None\n",
    "result_LSTM = []\n",
    "for _ in range(nb_samples):\n",
    "    acc, error_LSTM = evaluate(newModel, 100, 50, error_LSTM)\n",
    "    result_LSTM.append(acc)\n",
    "print(error_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = load_model(\"srnn_simple.h5\")\n",
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(SimpleRNN(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.add(Dense(7, activation='softmax'))\n",
    "newModel.set_weights(Model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 49, 4: 1}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 0, 3: 89, 4: 3}\n",
      "Good prediction : 58.00%\n",
      "{1: 0, 2: 0, 3: 137, 4: 7}\n",
      "Good prediction : 48.00%\n",
      "{1: 0, 2: 0, 3: 181, 4: 9}\n",
      "Good prediction : 54.00%\n",
      "{1: 0, 2: 0, 3: 230, 4: 9}\n",
      "Good prediction : 51.00%\n",
      "{1: 0, 2: 0, 3: 275, 4: 11}\n",
      "Good prediction : 53.00%\n",
      "{1: 0, 2: 0, 3: 320, 4: 13}\n",
      "Good prediction : 53.00%\n",
      "{1: 0, 2: 0, 3: 384, 4: 14}\n",
      "Good prediction : 35.00%\n",
      "{1: 0, 2: 1, 3: 434, 4: 14}\n",
      "Good prediction : 49.00%\n",
      "{1: 0, 2: 1, 3: 489, 4: 15}\n",
      "Good prediction : 44.00%\n",
      "{1: 0, 2: 1, 3: 533, 4: 16}\n",
      "Good prediction : 55.00%\n",
      "{1: 0, 2: 1, 3: 582, 4: 19}\n",
      "Good prediction : 48.00%\n",
      "{1: 0, 2: 1, 3: 636, 4: 21}\n",
      "Good prediction : 44.00%\n",
      "{1: 0, 2: 1, 3: 688, 4: 24}\n",
      "Good prediction : 45.00%\n",
      "{1: 0, 2: 1, 3: 748, 4: 25}\n",
      "Good prediction : 39.00%\n",
      "{1: 0, 2: 3, 3: 797, 4: 29}\n",
      "Good prediction : 45.00%\n",
      "{1: 0, 2: 3, 3: 847, 4: 34}\n",
      "Good prediction : 45.00%\n",
      "{1: 0, 2: 3, 3: 906, 4: 36}\n",
      "Good prediction : 39.00%\n",
      "{1: 0, 2: 3, 3: 956, 4: 38}\n",
      "Good prediction : 48.00%\n",
      "{1: 0, 2: 3, 3: 1008, 4: 40}\n",
      "Good prediction : 46.00%\n",
      "{1: 0, 2: 3, 3: 1008, 4: 40}\n"
     ]
    }
   ],
   "source": [
    "error_SRNN = None\n",
    "result_SRNN = []\n",
    "for _ in range(nb_samples):\n",
    "    acc, error_SRNN = evaluate(newModel, 100, 50, error_SRNN)\n",
    "    result_SRNN.append(acc)\n",
    "print(error_SRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = load_model(\"gru_simple.h5\")\n",
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(GRU(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.add(Dense(7, activation='softmax'))\n",
    "newModel.set_weights(Model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 58, 4: 3}\n",
      "Good prediction : 39.00%\n",
      "{1: 0, 2: 1, 3: 106, 4: 6}\n",
      "Good prediction : 48.00%\n",
      "{1: 0, 2: 1, 3: 168, 4: 7}\n",
      "Good prediction : 37.00%\n",
      "{1: 0, 2: 1, 3: 218, 4: 10}\n",
      "Good prediction : 47.00%\n",
      "{1: 0, 2: 1, 3: 264, 4: 13}\n",
      "Good prediction : 51.00%\n",
      "{1: 0, 2: 2, 3: 318, 4: 13}\n",
      "Good prediction : 45.00%\n",
      "{1: 0, 2: 2, 3: 358, 4: 14}\n",
      "Good prediction : 59.00%\n",
      "{1: 0, 2: 4, 3: 401, 4: 19}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 4, 3: 448, 4: 23}\n",
      "Good prediction : 49.00%\n",
      "{1: 0, 2: 4, 3: 499, 4: 27}\n",
      "Good prediction : 45.00%\n"
     ]
    }
   ],
   "source": [
    "error_GRU = None\n",
    "result_GRU = []\n",
    "for _ in range(nb_samples):\n",
    "    acc, error_GRU = evaluate(newModel, 100, 50, error_GRU)\n",
    "    result_GRU.append(acc)\n",
    "error_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'LSTM': result_LSTM, 'Simple RNN': result_SRNN, 'GRU' : result_GRU}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bae6630860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bad5942d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.barplot(x=[\"LSTM\", \"Simple RNN\", \"GRU\"], data=df, capsize=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that bost LSTM and GRU outperform the standard RNN. In average LSTM is slightly better than GRU but takes also more time to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAFyCAYAAABFkzRRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDS/u/OA2wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e00bd7bb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax = sns.boxplot(x=[result_LSTM, result_SRNN, result_GRU], y=[\"LSTM\", \"SimpleRNN\", \"GRU\"])\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(xlim=(0, 100), ylabel=\"\",\n",
    "       xlabel=\"Accuracy (%)\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig(\"boxplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0sAAAK8CAYAAAA+pCRjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e1eaba8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(nb_samples))\n",
    "y = [result_LSTM, result_SRNN, result_GRU]\n",
    "labels = [\"LSTM\", \"SimpleRNN\", \"GRU\"]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for y_arr, label in zip(y, labels):\n",
    "    plt.plot(x, y_arr, label=label)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.ylim((0,100))\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.savefig(\"test_result.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(data=error_LSTM, index=[\"LSTM\"])\n",
    "df3 = df3.append(pd.DataFrame(data=error_GRU, index=[\"GRU\"]))\n",
    "df3 = df3.append(pd.DataFrame(data=error_SRNN, index=[\"SRNN\"]))\n",
    "df3.columns = [\"1st Letter\", \"2nd Letter\", \"LTM\", \"Reber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Letter</th>\n",
       "      <th>2nd Letter</th>\n",
       "      <th>LTM</th>\n",
       "      <th>Reber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>985</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>865</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRNN</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1001</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1st Letter  2nd Letter   LTM  Reber\n",
       "LSTM           0           2   985     26\n",
       "GRU            0           1   865     11\n",
       "SRNN           0           3  1001     18"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this workbook, we started to go through RNN. We check a simple model of both LSTM, GRU and SimpleRNN to check how fast and well they learn. On this example GRU and LSTM outperform the standard RNN due to the memory function. There is also a difference between LSTM and GRU but with slightly more epochs, they both perform similar. We can probably have better result by using a more advanced model but for such a simple model, we can see that it works really well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further\n",
    "\n",
    "On a future notebook, we will explore Embedded Reber but using deeper RNNs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
