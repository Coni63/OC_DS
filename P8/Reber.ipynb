{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REBER Grammar with RNN\n",
    "\n",
    "In this workbook, we are going to set-up multiple Recurrent Neural Network to test them using as test <a href=\"https://www.willamette.edu/~gorr/classes/cs449/reber.html\" target=\"_blank\">Reber's grammar</a> words.\n",
    "\n",
    "## What is a Reber Word ?\n",
    "\n",
    "A Reber word is a word following the Reber's grammar. The grammar is based on the following graph:\n",
    "\n",
    "<img src=\"reber.gif\"/>\n",
    "\n",
    "The word must start with B, then it can be either T or P and so on until it reaches E. To prepare datas for this, we are going to use a OneHotEncoder to have 7 inputs, n timesteps (depending on the length of the word) and k batches. To generate it, I use the algorith from <a href=\"http://christianherta.de/lehre/dataScience/machineLearning/neuralNetworks/reberGrammar.php\" target=\"_target\">this site</a> but slightly modified to be able to validate also embedded Word\n",
    "\n",
    "The Embedded version of the Reber Grammar using the following graph :\n",
    "\n",
    "<img src=\"embreber.gif\"/>\n",
    "\n",
    "Due to current technologies, we will focus on Embedded Word (both system tried below with Simple Reber Word reaches 100% success and cannot be compared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "import create_dataset as reber\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of datas\n",
    "\n",
    "For the OneHotEncoder, the chain 'BTSXPVE' will be used. We can now try only 1 example to check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBPVPXTTTVPSET\n",
      "[ 1.  0.  0.  0.  0.  0.  0.] [ 0.  1.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "x, y = reber.get_one_embedded_example(minLength=10)\n",
    "print(reber.sequenceToWord(x))\n",
    "print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*y* is the possible outcome for a given input. That means B ([ 1.  0.  0.  0.  0.  0.  0.]) can be followed by T or P ([ 0.  1.  0.  0.  1.  0.  0.]).\n",
    "\n",
    "However, we won't use y as output but for every timestep, we are going to provide the next timestep as target. For this, we will use the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(x0):\n",
    "    end = np.array([0.,  0.,  0.,  0.,  0.,  0.,  1.])\n",
    "    y=x0[1:]\n",
    "    y.append(end)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we take as input \"BTSXS\", the output will be \"TSXSE\" (but the input in encoded).\n",
    "\n",
    "We can also generate few words to check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "14\n",
      "18\n",
      "14\n",
      "19\n",
      "14\n",
      "14\n",
      "23\n",
      "14\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "min_length = 10\n",
    "for i in range(10):\n",
    "    inp, out = reber.get_one_embedded_example(min_length)\n",
    "#     print(reber.sequenceToWord(inp))\n",
    "    print(len(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have the first \"problem\" now, the length of the string is variable. So when we are going to generate our test/train datas, we will have to pad them to the same length (let's say 20). This is done by using <b>sequence.pad_sequences</b> for Keras Library. The padding will be done as \"post\" to improve accuracy. Using a \"pre\" padding reduce accuracy because the cell doesn't know how many times it will receive 0 instead of \"E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 36, 7)\n",
      "(2048, 36, 7)\n",
      "(256, 36, 7)\n",
      "(256, 36, 7)\n",
      "(1, 36, 7)\n",
      "(1, 36, 7)\n",
      "(1, 36, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "X_val, y_val = [], []\n",
    "y_possible = []\n",
    "\n",
    "maxlen = 0\n",
    "for i in range(2048):\n",
    "    x, y = reber.get_one_embedded_example(min_length)\n",
    "    X_train.append(x)\n",
    "    y_train.append(generate(x))\n",
    "    maxlen = max(maxlen, len(x))\n",
    "\n",
    "for i in range(256):\n",
    "    x, y = reber.get_one_embedded_example(min_length)\n",
    "    X_test.append(x)\n",
    "    y_test.append(generate(x))\n",
    "    maxlen = max(maxlen, len(x))\n",
    "    \n",
    "for i in range(1):\n",
    "    x, y = reber.get_one_embedded_example(min_length)\n",
    "    X_val.append(x)\n",
    "    y_val.append(generate(x))\n",
    "    y_possible.append(y)\n",
    "    maxlen = max(maxlen, len(x))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "y_possible = np.array(y_possible)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_train = sequence.pad_sequences(y_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_test = sequence.pad_sequences(y_test, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_val = sequence.pad_sequences(y_val, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_possible = sequence.pad_sequences(y_possible, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(y_possible.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1 0 0 1 0 0]\n",
      "  [1 0 0 0 0 0 0]\n",
      "  [0 1 0 0 1 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 1 1 0 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 1 1 0 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(y_possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have 2048 strings for training, 256 for test and 1 just for visualisation later. We can now set-up our model.\n",
    "\n",
    "## Test of RNNs\n",
    "\n",
    "For this model, we are going to use a many-to-many RNN. That means for every input, the model will predict an output. The training will be done based on the input we prepared previously. Once trained. We will be able to \"transfer\" the learning to a one-to-many model in order to have a \"generator\".\n",
    "\n",
    "<img src=\"RNN_types.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we expect is a probability of having this or this letter. The problem is a multi-class classifier. As a reult, the loss function will be the categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_unit = 7\n",
    "inp_shape = (maxlen, 7)\n",
    "loss_ = \"categorical_crossentropy\"\n",
    "metrics_ = \"categorical_crossentropy\"\n",
    "optimizer_ = \"Nadam\"\n",
    "nb_epoch = 250\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "The first model we will setup is an <b>LSTM</b> which means <b>L</b>ong <b>S</b>hort-<b>T</b>erm <b>M</b>emory. The principle is \n",
    "quite complex but very powerfull for long sequences inputs (because there is less issues with Vanishing Gradient Problem) or long term memory (You can refer to <a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\" target=\"_blank\">this link</a> for more informations)\n",
    "\n",
    "LSTM is widely for speech recognition, Natural Language processing, Sentiment Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=nb_unit, \n",
    "               input_shape=inp_shape, \n",
    "               return_sequences=True))  # single LSTM\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"lstm_simple.h5\",\n",
    "    monitor=loss_,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: (None, 36, 7)\n",
      "Outputs: (None, 36, 7)\n",
      "Actual input: (2048, 36, 7)\n",
      "Actual output: (2048, 36, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs: {}\".format(model.input_shape))\n",
    "print(\"Outputs: {}\".format(model.output_shape))\n",
    "print(\"Actual input: {}\".format(X_train.shape))\n",
    "print(\"Actual output: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 256 samples\n",
      "Epoch 1/250\n",
      "Epoch 00001: categorical_crossentropy improved from inf to 0.87656, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.8766 - categorical_crossentropy: 0.8766 - val_loss: 0.8389 - val_categorical_crossentropy: 0.8389\n",
      "Epoch 2/250\n",
      "Epoch 00002: categorical_crossentropy improved from 0.87656 to 0.82919, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.8292 - categorical_crossentropy: 0.8292 - val_loss: 0.7940 - val_categorical_crossentropy: 0.7940\n",
      "Epoch 3/250\n",
      "Epoch 00003: categorical_crossentropy improved from 0.82919 to 0.78130, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.7813 - categorical_crossentropy: 0.7813 - val_loss: 0.7428 - val_categorical_crossentropy: 0.7428\n",
      "Epoch 4/250\n",
      "Epoch 00004: categorical_crossentropy improved from 0.78130 to 0.72755, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.7276 - categorical_crossentropy: 0.7276 - val_loss: 0.6885 - val_categorical_crossentropy: 0.6885\n",
      "Epoch 5/250\n",
      "Epoch 00005: categorical_crossentropy improved from 0.72755 to 0.67646, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.6765 - categorical_crossentropy: 0.6765 - val_loss: 0.6388 - val_categorical_crossentropy: 0.6388\n",
      "Epoch 6/250\n",
      "Epoch 00006: categorical_crossentropy improved from 0.67646 to 0.62766, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.6277 - categorical_crossentropy: 0.6277 - val_loss: 0.5920 - val_categorical_crossentropy: 0.5920\n",
      "Epoch 7/250\n",
      "Epoch 00007: categorical_crossentropy improved from 0.62766 to 0.58133, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.5813 - categorical_crossentropy: 0.5813 - val_loss: 0.5483 - val_categorical_crossentropy: 0.5483\n",
      "Epoch 8/250\n",
      "Epoch 00008: categorical_crossentropy improved from 0.58133 to 0.53747, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.5375 - categorical_crossentropy: 0.5375 - val_loss: 0.5059 - val_categorical_crossentropy: 0.5059\n",
      "Epoch 9/250\n",
      "Epoch 00009: categorical_crossentropy improved from 0.53747 to 0.49705, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.4971 - categorical_crossentropy: 0.4971 - val_loss: 0.4695 - val_categorical_crossentropy: 0.4695\n",
      "Epoch 10/250\n",
      "Epoch 00010: categorical_crossentropy improved from 0.49705 to 0.46121, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.4612 - categorical_crossentropy: 0.4612 - val_loss: 0.4352 - val_categorical_crossentropy: 0.4352\n",
      "Epoch 11/250\n",
      "Epoch 00011: categorical_crossentropy improved from 0.46121 to 0.42908, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.4291 - categorical_crossentropy: 0.4291 - val_loss: 0.4059 - val_categorical_crossentropy: 0.4059\n",
      "Epoch 12/250\n",
      "Epoch 00012: categorical_crossentropy improved from 0.42908 to 0.40161, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.4016 - categorical_crossentropy: 0.4016 - val_loss: 0.3834 - val_categorical_crossentropy: 0.3834\n",
      "Epoch 13/250\n",
      "Epoch 00013: categorical_crossentropy improved from 0.40161 to 0.37843, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.3784 - categorical_crossentropy: 0.3784 - val_loss: 0.3596 - val_categorical_crossentropy: 0.3596\n",
      "Epoch 14/250\n",
      "Epoch 00014: categorical_crossentropy improved from 0.37843 to 0.35756, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.3576 - categorical_crossentropy: 0.3576 - val_loss: 0.3419 - val_categorical_crossentropy: 0.3419\n",
      "Epoch 15/250\n",
      "Epoch 00015: categorical_crossentropy improved from 0.35756 to 0.34096, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.3410 - categorical_crossentropy: 0.3410 - val_loss: 0.3275 - val_categorical_crossentropy: 0.3275\n",
      "Epoch 16/250\n",
      "Epoch 00016: categorical_crossentropy improved from 0.34096 to 0.32700, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.3270 - categorical_crossentropy: 0.3270 - val_loss: 0.3146 - val_categorical_crossentropy: 0.3146\n",
      "Epoch 17/250\n",
      "Epoch 00017: categorical_crossentropy improved from 0.32700 to 0.31527, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.3153 - categorical_crossentropy: 0.3153 - val_loss: 0.3044 - val_categorical_crossentropy: 0.3044\n",
      "Epoch 18/250\n",
      "Epoch 00018: categorical_crossentropy improved from 0.31527 to 0.30553, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.3055 - categorical_crossentropy: 0.3055 - val_loss: 0.2955 - val_categorical_crossentropy: 0.2955\n",
      "Epoch 19/250\n",
      "Epoch 00019: categorical_crossentropy improved from 0.30553 to 0.29798, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2980 - categorical_crossentropy: 0.2980 - val_loss: 0.2884 - val_categorical_crossentropy: 0.2884\n",
      "Epoch 20/250\n",
      "Epoch 00020: categorical_crossentropy improved from 0.29798 to 0.29072, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2907 - categorical_crossentropy: 0.2907 - val_loss: 0.2824 - val_categorical_crossentropy: 0.2824\n",
      "Epoch 21/250\n",
      "Epoch 00021: categorical_crossentropy improved from 0.29072 to 0.28503, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2850 - categorical_crossentropy: 0.2850 - val_loss: 0.2772 - val_categorical_crossentropy: 0.2772\n",
      "Epoch 22/250\n",
      "Epoch 00022: categorical_crossentropy improved from 0.28503 to 0.28022, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2802 - categorical_crossentropy: 0.2802 - val_loss: 0.2728 - val_categorical_crossentropy: 0.2728\n",
      "Epoch 23/250\n",
      "Epoch 00023: categorical_crossentropy improved from 0.28022 to 0.27616, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2762 - categorical_crossentropy: 0.2762 - val_loss: 0.2691 - val_categorical_crossentropy: 0.2691\n",
      "Epoch 24/250\n",
      "Epoch 00024: categorical_crossentropy improved from 0.27616 to 0.27226, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2723 - categorical_crossentropy: 0.2723 - val_loss: 0.2653 - val_categorical_crossentropy: 0.2653\n",
      "Epoch 25/250\n",
      "Epoch 00025: categorical_crossentropy improved from 0.27226 to 0.26891, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2689 - categorical_crossentropy: 0.2689 - val_loss: 0.2623 - val_categorical_crossentropy: 0.2623\n",
      "Epoch 26/250\n",
      "Epoch 00026: categorical_crossentropy improved from 0.26891 to 0.26599, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2660 - categorical_crossentropy: 0.2660 - val_loss: 0.2597 - val_categorical_crossentropy: 0.2597\n",
      "Epoch 27/250\n",
      "Epoch 00027: categorical_crossentropy improved from 0.26599 to 0.26340, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2634 - categorical_crossentropy: 0.2634 - val_loss: 0.2573 - val_categorical_crossentropy: 0.2573\n",
      "Epoch 28/250\n",
      "Epoch 00028: categorical_crossentropy improved from 0.26340 to 0.26151, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2615 - categorical_crossentropy: 0.2615 - val_loss: 0.2563 - val_categorical_crossentropy: 0.2563\n",
      "Epoch 29/250\n",
      "Epoch 00029: categorical_crossentropy improved from 0.26151 to 0.25938, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2594 - categorical_crossentropy: 0.2594 - val_loss: 0.2533 - val_categorical_crossentropy: 0.2533\n",
      "Epoch 30/250\n",
      "Epoch 00030: categorical_crossentropy improved from 0.25938 to 0.25713, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2571 - categorical_crossentropy: 0.2571 - val_loss: 0.2514 - val_categorical_crossentropy: 0.2514\n",
      "Epoch 31/250\n",
      "Epoch 00031: categorical_crossentropy improved from 0.25713 to 0.25537, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2554 - categorical_crossentropy: 0.2554 - val_loss: 0.2498 - val_categorical_crossentropy: 0.2498\n",
      "Epoch 32/250\n",
      "Epoch 00032: categorical_crossentropy improved from 0.25537 to 0.25380, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2538 - categorical_crossentropy: 0.2538 - val_loss: 0.2482 - val_categorical_crossentropy: 0.2482\n",
      "Epoch 33/250\n",
      "Epoch 00033: categorical_crossentropy improved from 0.25380 to 0.25229, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2523 - categorical_crossentropy: 0.2523 - val_loss: 0.2468 - val_categorical_crossentropy: 0.2468\n",
      "Epoch 34/250\n",
      "Epoch 00034: categorical_crossentropy improved from 0.25229 to 0.25089, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2509 - categorical_crossentropy: 0.2509 - val_loss: 0.2458 - val_categorical_crossentropy: 0.2458\n",
      "Epoch 35/250\n",
      "Epoch 00035: categorical_crossentropy improved from 0.25089 to 0.24977, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2498 - categorical_crossentropy: 0.2498 - val_loss: 0.2444 - val_categorical_crossentropy: 0.2444\n",
      "Epoch 36/250\n",
      "Epoch 00036: categorical_crossentropy improved from 0.24977 to 0.24865, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2487 - categorical_crossentropy: 0.2487 - val_loss: 0.2435 - val_categorical_crossentropy: 0.2435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "Epoch 00037: categorical_crossentropy improved from 0.24865 to 0.24753, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2475 - categorical_crossentropy: 0.2475 - val_loss: 0.2424 - val_categorical_crossentropy: 0.2424\n",
      "Epoch 38/250\n",
      "Epoch 00038: categorical_crossentropy improved from 0.24753 to 0.24659, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2466 - categorical_crossentropy: 0.2466 - val_loss: 0.2415 - val_categorical_crossentropy: 0.2415\n",
      "Epoch 39/250\n",
      "Epoch 00039: categorical_crossentropy improved from 0.24659 to 0.24566, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2457 - categorical_crossentropy: 0.2457 - val_loss: 0.2406 - val_categorical_crossentropy: 0.2406\n",
      "Epoch 40/250\n",
      "Epoch 00040: categorical_crossentropy improved from 0.24566 to 0.24471, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2447 - categorical_crossentropy: 0.2447 - val_loss: 0.2397 - val_categorical_crossentropy: 0.2397\n",
      "Epoch 41/250\n",
      "Epoch 00041: categorical_crossentropy improved from 0.24471 to 0.24386, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2439 - categorical_crossentropy: 0.2439 - val_loss: 0.2389 - val_categorical_crossentropy: 0.2389\n",
      "Epoch 42/250\n",
      "Epoch 00042: categorical_crossentropy improved from 0.24386 to 0.24297, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2430 - categorical_crossentropy: 0.2430 - val_loss: 0.2382 - val_categorical_crossentropy: 0.2382\n",
      "Epoch 43/250\n",
      "Epoch 00043: categorical_crossentropy improved from 0.24297 to 0.24223, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2422 - categorical_crossentropy: 0.2422 - val_loss: 0.2373 - val_categorical_crossentropy: 0.2373\n",
      "Epoch 44/250\n",
      "Epoch 00044: categorical_crossentropy improved from 0.24223 to 0.24154, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2415 - categorical_crossentropy: 0.2415 - val_loss: 0.2365 - val_categorical_crossentropy: 0.2365\n",
      "Epoch 45/250\n",
      "Epoch 00045: categorical_crossentropy improved from 0.24154 to 0.24078, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2408 - categorical_crossentropy: 0.2408 - val_loss: 0.2359 - val_categorical_crossentropy: 0.2359\n",
      "Epoch 46/250\n",
      "Epoch 00046: categorical_crossentropy improved from 0.24078 to 0.24014, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2401 - categorical_crossentropy: 0.2401 - val_loss: 0.2352 - val_categorical_crossentropy: 0.2352\n",
      "Epoch 47/250\n",
      "Epoch 00047: categorical_crossentropy improved from 0.24014 to 0.23948, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2395 - categorical_crossentropy: 0.2395 - val_loss: 0.2345 - val_categorical_crossentropy: 0.2345\n",
      "Epoch 48/250\n",
      "Epoch 00048: categorical_crossentropy improved from 0.23948 to 0.23883, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2388 - categorical_crossentropy: 0.2388 - val_loss: 0.2339 - val_categorical_crossentropy: 0.2339\n",
      "Epoch 49/250\n",
      "Epoch 00049: categorical_crossentropy improved from 0.23883 to 0.23822, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2382 - categorical_crossentropy: 0.2382 - val_loss: 0.2334 - val_categorical_crossentropy: 0.2334\n",
      "Epoch 50/250\n",
      "Epoch 00050: categorical_crossentropy improved from 0.23822 to 0.23770, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2377 - categorical_crossentropy: 0.2377 - val_loss: 0.2327 - val_categorical_crossentropy: 0.2327\n",
      "Epoch 51/250\n",
      "Epoch 00051: categorical_crossentropy improved from 0.23770 to 0.23712, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2371 - categorical_crossentropy: 0.2371 - val_loss: 0.2324 - val_categorical_crossentropy: 0.2324\n",
      "Epoch 52/250\n",
      "Epoch 00052: categorical_crossentropy improved from 0.23712 to 0.23657, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2366 - categorical_crossentropy: 0.2366 - val_loss: 0.2316 - val_categorical_crossentropy: 0.2316\n",
      "Epoch 53/250\n",
      "Epoch 00053: categorical_crossentropy improved from 0.23657 to 0.23605, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2360 - categorical_crossentropy: 0.2360 - val_loss: 0.2310 - val_categorical_crossentropy: 0.2310\n",
      "Epoch 54/250\n",
      "Epoch 00054: categorical_crossentropy improved from 0.23605 to 0.23554, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2355 - categorical_crossentropy: 0.2355 - val_loss: 0.2304 - val_categorical_crossentropy: 0.2304\n",
      "Epoch 55/250\n",
      "Epoch 00055: categorical_crossentropy improved from 0.23554 to 0.23501, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2350 - categorical_crossentropy: 0.2350 - val_loss: 0.2299 - val_categorical_crossentropy: 0.2299\n",
      "Epoch 56/250\n",
      "Epoch 00056: categorical_crossentropy improved from 0.23501 to 0.23448, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2345 - categorical_crossentropy: 0.2345 - val_loss: 0.2295 - val_categorical_crossentropy: 0.2295\n",
      "Epoch 57/250\n",
      "Epoch 00057: categorical_crossentropy improved from 0.23448 to 0.23410, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2341 - categorical_crossentropy: 0.2341 - val_loss: 0.2290 - val_categorical_crossentropy: 0.2290\n",
      "Epoch 58/250\n",
      "Epoch 00058: categorical_crossentropy improved from 0.23410 to 0.23363, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2336 - categorical_crossentropy: 0.2336 - val_loss: 0.2286 - val_categorical_crossentropy: 0.2286\n",
      "Epoch 59/250\n",
      "Epoch 00059: categorical_crossentropy improved from 0.23363 to 0.23324, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2332 - categorical_crossentropy: 0.2332 - val_loss: 0.2283 - val_categorical_crossentropy: 0.2283\n",
      "Epoch 60/250\n",
      "Epoch 00060: categorical_crossentropy improved from 0.23324 to 0.23279, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2328 - categorical_crossentropy: 0.2328 - val_loss: 0.2277 - val_categorical_crossentropy: 0.2277\n",
      "Epoch 61/250\n",
      "Epoch 00061: categorical_crossentropy improved from 0.23279 to 0.23238, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2324 - categorical_crossentropy: 0.2324 - val_loss: 0.2276 - val_categorical_crossentropy: 0.2276\n",
      "Epoch 62/250\n",
      "Epoch 00062: categorical_crossentropy improved from 0.23238 to 0.23205, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2320 - categorical_crossentropy: 0.2320 - val_loss: 0.2270 - val_categorical_crossentropy: 0.2270\n",
      "Epoch 63/250\n",
      "Epoch 00063: categorical_crossentropy improved from 0.23205 to 0.23171, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2317 - categorical_crossentropy: 0.2317 - val_loss: 0.2268 - val_categorical_crossentropy: 0.2268\n",
      "Epoch 64/250\n",
      "Epoch 00064: categorical_crossentropy improved from 0.23171 to 0.23138, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2314 - categorical_crossentropy: 0.2314 - val_loss: 0.2260 - val_categorical_crossentropy: 0.2260\n",
      "Epoch 65/250\n",
      "Epoch 00065: categorical_crossentropy improved from 0.23138 to 0.23102, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2310 - categorical_crossentropy: 0.2310 - val_loss: 0.2261 - val_categorical_crossentropy: 0.2261\n",
      "Epoch 66/250\n",
      "Epoch 00066: categorical_crossentropy improved from 0.23102 to 0.23071, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2307 - categorical_crossentropy: 0.2307 - val_loss: 0.2255 - val_categorical_crossentropy: 0.2255\n",
      "Epoch 67/250\n",
      "Epoch 00067: categorical_crossentropy improved from 0.23071 to 0.23043, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2304 - categorical_crossentropy: 0.2304 - val_loss: 0.2253 - val_categorical_crossentropy: 0.2253\n",
      "Epoch 68/250\n",
      "Epoch 00068: categorical_crossentropy improved from 0.23043 to 0.23018, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2302 - categorical_crossentropy: 0.2302 - val_loss: 0.2248 - val_categorical_crossentropy: 0.2248\n",
      "Epoch 69/250\n",
      "Epoch 00069: categorical_crossentropy improved from 0.23018 to 0.22990, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2299 - categorical_crossentropy: 0.2299 - val_loss: 0.2245 - val_categorical_crossentropy: 0.2245\n",
      "Epoch 70/250\n",
      "Epoch 00070: categorical_crossentropy improved from 0.22990 to 0.22965, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2297 - categorical_crossentropy: 0.2297 - val_loss: 0.2243 - val_categorical_crossentropy: 0.2243\n",
      "Epoch 71/250\n",
      "Epoch 00071: categorical_crossentropy improved from 0.22965 to 0.22941, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2294 - categorical_crossentropy: 0.2294 - val_loss: 0.2239 - val_categorical_crossentropy: 0.2239\n",
      "Epoch 72/250\n",
      "Epoch 00072: categorical_crossentropy improved from 0.22941 to 0.22913, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2291 - categorical_crossentropy: 0.2291 - val_loss: 0.2238 - val_categorical_crossentropy: 0.2238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/250\n",
      "Epoch 00073: categorical_crossentropy improved from 0.22913 to 0.22898, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2290 - categorical_crossentropy: 0.2290 - val_loss: 0.2236 - val_categorical_crossentropy: 0.2236\n",
      "Epoch 74/250\n",
      "Epoch 00074: categorical_crossentropy improved from 0.22898 to 0.22874, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2287 - categorical_crossentropy: 0.2287 - val_loss: 0.2233 - val_categorical_crossentropy: 0.2233\n",
      "Epoch 75/250\n",
      "Epoch 00075: categorical_crossentropy improved from 0.22874 to 0.22856, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2286 - categorical_crossentropy: 0.2286 - val_loss: 0.2233 - val_categorical_crossentropy: 0.2233\n",
      "Epoch 76/250\n",
      "Epoch 00076: categorical_crossentropy improved from 0.22856 to 0.22835, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2284 - categorical_crossentropy: 0.2284 - val_loss: 0.2229 - val_categorical_crossentropy: 0.2229\n",
      "Epoch 77/250\n",
      "Epoch 00077: categorical_crossentropy improved from 0.22835 to 0.22812, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2281 - categorical_crossentropy: 0.2281 - val_loss: 0.2230 - val_categorical_crossentropy: 0.2230\n",
      "Epoch 78/250\n",
      "Epoch 00078: categorical_crossentropy improved from 0.22812 to 0.22805, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2281 - categorical_crossentropy: 0.2281 - val_loss: 0.2228 - val_categorical_crossentropy: 0.2228\n",
      "Epoch 79/250\n",
      "Epoch 00079: categorical_crossentropy improved from 0.22805 to 0.22783, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2278 - categorical_crossentropy: 0.2278 - val_loss: 0.2225 - val_categorical_crossentropy: 0.2225\n",
      "Epoch 80/250\n",
      "Epoch 00080: categorical_crossentropy improved from 0.22783 to 0.22765, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2276 - categorical_crossentropy: 0.2276 - val_loss: 0.2222 - val_categorical_crossentropy: 0.2222\n",
      "Epoch 81/250\n",
      "Epoch 00081: categorical_crossentropy improved from 0.22765 to 0.22748, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2275 - categorical_crossentropy: 0.2275 - val_loss: 0.2223 - val_categorical_crossentropy: 0.2223\n",
      "Epoch 82/250\n",
      "Epoch 00082: categorical_crossentropy improved from 0.22748 to 0.22727, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2273 - categorical_crossentropy: 0.2273 - val_loss: 0.2223 - val_categorical_crossentropy: 0.2223\n",
      "Epoch 83/250\n",
      "Epoch 00083: categorical_crossentropy improved from 0.22727 to 0.22715, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2271 - categorical_crossentropy: 0.2271 - val_loss: 0.2219 - val_categorical_crossentropy: 0.2219\n",
      "Epoch 84/250\n",
      "Epoch 00084: categorical_crossentropy improved from 0.22715 to 0.22706, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2271 - categorical_crossentropy: 0.2271 - val_loss: 0.2216 - val_categorical_crossentropy: 0.2216\n",
      "Epoch 85/250\n",
      "Epoch 00085: categorical_crossentropy improved from 0.22706 to 0.22688, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2269 - categorical_crossentropy: 0.2269 - val_loss: 0.2216 - val_categorical_crossentropy: 0.2216\n",
      "Epoch 86/250\n",
      "Epoch 00086: categorical_crossentropy improved from 0.22688 to 0.22673, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2267 - categorical_crossentropy: 0.2267 - val_loss: 0.2212 - val_categorical_crossentropy: 0.2212\n",
      "Epoch 87/250\n",
      "Epoch 00087: categorical_crossentropy improved from 0.22673 to 0.22667, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2267 - categorical_crossentropy: 0.2267 - val_loss: 0.2213 - val_categorical_crossentropy: 0.2213\n",
      "Epoch 88/250\n",
      "Epoch 00088: categorical_crossentropy improved from 0.22667 to 0.22651, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2265 - categorical_crossentropy: 0.2265 - val_loss: 0.2212 - val_categorical_crossentropy: 0.2212\n",
      "Epoch 89/250\n",
      "Epoch 00089: categorical_crossentropy improved from 0.22651 to 0.22630, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2263 - categorical_crossentropy: 0.2263 - val_loss: 0.2211 - val_categorical_crossentropy: 0.2211\n",
      "Epoch 90/250\n",
      "Epoch 00090: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2263 - categorical_crossentropy: 0.2263 - val_loss: 0.2208 - val_categorical_crossentropy: 0.2208\n",
      "Epoch 91/250\n",
      "Epoch 00091: categorical_crossentropy improved from 0.22630 to 0.22615, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2262 - categorical_crossentropy: 0.2262 - val_loss: 0.2206 - val_categorical_crossentropy: 0.2206\n",
      "Epoch 92/250\n",
      "Epoch 00092: categorical_crossentropy improved from 0.22615 to 0.22600, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2260 - categorical_crossentropy: 0.2260 - val_loss: 0.2204 - val_categorical_crossentropy: 0.2204\n",
      "Epoch 93/250\n",
      "Epoch 00093: categorical_crossentropy improved from 0.22600 to 0.22592, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2259 - categorical_crossentropy: 0.2259 - val_loss: 0.2205 - val_categorical_crossentropy: 0.2205\n",
      "Epoch 94/250\n",
      "Epoch 00094: categorical_crossentropy improved from 0.22592 to 0.22577, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2258 - categorical_crossentropy: 0.2258 - val_loss: 0.2206 - val_categorical_crossentropy: 0.2206\n",
      "Epoch 95/250\n",
      "Epoch 00095: categorical_crossentropy improved from 0.22577 to 0.22570, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2257 - categorical_crossentropy: 0.2257 - val_loss: 0.2208 - val_categorical_crossentropy: 0.2208\n",
      "Epoch 96/250\n",
      "Epoch 00096: categorical_crossentropy improved from 0.22570 to 0.22549, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2255 - categorical_crossentropy: 0.2255 - val_loss: 0.2199 - val_categorical_crossentropy: 0.2199\n",
      "Epoch 97/250\n",
      "Epoch 00097: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2255 - categorical_crossentropy: 0.2255 - val_loss: 0.2203 - val_categorical_crossentropy: 0.2203\n",
      "Epoch 98/250\n",
      "Epoch 00098: categorical_crossentropy improved from 0.22549 to 0.22540, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2254 - categorical_crossentropy: 0.2254 - val_loss: 0.2197 - val_categorical_crossentropy: 0.2197\n",
      "Epoch 99/250\n",
      "Epoch 00099: categorical_crossentropy improved from 0.22540 to 0.22535, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2254 - categorical_crossentropy: 0.2254 - val_loss: 0.2196 - val_categorical_crossentropy: 0.2196\n",
      "Epoch 100/250\n",
      "Epoch 00100: categorical_crossentropy improved from 0.22535 to 0.22509, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2251 - categorical_crossentropy: 0.2251 - val_loss: 0.2196 - val_categorical_crossentropy: 0.2196\n",
      "Epoch 101/250\n",
      "Epoch 00101: categorical_crossentropy improved from 0.22509 to 0.22501, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2250 - categorical_crossentropy: 0.2250 - val_loss: 0.2194 - val_categorical_crossentropy: 0.2194\n",
      "Epoch 102/250\n",
      "Epoch 00102: categorical_crossentropy improved from 0.22501 to 0.22490, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2249 - categorical_crossentropy: 0.2249 - val_loss: 0.2194 - val_categorical_crossentropy: 0.2194\n",
      "Epoch 103/250\n",
      "Epoch 00103: categorical_crossentropy improved from 0.22490 to 0.22482, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2248 - categorical_crossentropy: 0.2248 - val_loss: 0.2193 - val_categorical_crossentropy: 0.2193\n",
      "Epoch 104/250\n",
      "Epoch 00104: categorical_crossentropy improved from 0.22482 to 0.22466, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2247 - categorical_crossentropy: 0.2247 - val_loss: 0.2193 - val_categorical_crossentropy: 0.2193\n",
      "Epoch 105/250\n",
      "Epoch 00105: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2247 - categorical_crossentropy: 0.2247 - val_loss: 0.2191 - val_categorical_crossentropy: 0.2191\n",
      "Epoch 106/250\n",
      "Epoch 00106: categorical_crossentropy improved from 0.22466 to 0.22461, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2246 - categorical_crossentropy: 0.2246 - val_loss: 0.2193 - val_categorical_crossentropy: 0.2193\n",
      "Epoch 107/250\n",
      "Epoch 00107: categorical_crossentropy improved from 0.22461 to 0.22447, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2245 - categorical_crossentropy: 0.2245 - val_loss: 0.2195 - val_categorical_crossentropy: 0.2195\n",
      "Epoch 108/250\n",
      "Epoch 00108: categorical_crossentropy improved from 0.22447 to 0.22439, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2244 - categorical_crossentropy: 0.2244 - val_loss: 0.2190 - val_categorical_crossentropy: 0.2190\n",
      "Epoch 109/250\n",
      "Epoch 00109: categorical_crossentropy improved from 0.22439 to 0.22431, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2243 - categorical_crossentropy: 0.2243 - val_loss: 0.2191 - val_categorical_crossentropy: 0.2191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/250\n",
      "Epoch 00110: categorical_crossentropy improved from 0.22431 to 0.22416, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2242 - categorical_crossentropy: 0.2242 - val_loss: 0.2188 - val_categorical_crossentropy: 0.2188\n",
      "Epoch 111/250\n",
      "Epoch 00111: categorical_crossentropy improved from 0.22416 to 0.22412, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2241 - categorical_crossentropy: 0.2241 - val_loss: 0.2185 - val_categorical_crossentropy: 0.2185\n",
      "Epoch 112/250\n",
      "Epoch 00112: categorical_crossentropy improved from 0.22412 to 0.22402, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2240 - categorical_crossentropy: 0.2240 - val_loss: 0.2185 - val_categorical_crossentropy: 0.2185\n",
      "Epoch 113/250\n",
      "Epoch 00113: categorical_crossentropy improved from 0.22402 to 0.22391, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2239 - categorical_crossentropy: 0.2239 - val_loss: 0.2186 - val_categorical_crossentropy: 0.2186\n",
      "Epoch 114/250\n",
      "Epoch 00114: categorical_crossentropy improved from 0.22391 to 0.22387, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2239 - categorical_crossentropy: 0.2239 - val_loss: 0.2182 - val_categorical_crossentropy: 0.2182\n",
      "Epoch 115/250\n",
      "Epoch 00115: categorical_crossentropy improved from 0.22387 to 0.22372, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2237 - categorical_crossentropy: 0.2237 - val_loss: 0.2189 - val_categorical_crossentropy: 0.2189\n",
      "Epoch 116/250\n",
      "Epoch 00116: categorical_crossentropy improved from 0.22372 to 0.22366, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2237 - categorical_crossentropy: 0.2237 - val_loss: 0.2182 - val_categorical_crossentropy: 0.2182\n",
      "Epoch 117/250\n",
      "Epoch 00117: categorical_crossentropy improved from 0.22366 to 0.22360, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2236 - categorical_crossentropy: 0.2236 - val_loss: 0.2186 - val_categorical_crossentropy: 0.2186\n",
      "Epoch 118/250\n",
      "Epoch 00118: categorical_crossentropy improved from 0.22360 to 0.22354, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2235 - categorical_crossentropy: 0.2235 - val_loss: 0.2185 - val_categorical_crossentropy: 0.2185\n",
      "Epoch 119/250\n",
      "Epoch 00119: categorical_crossentropy improved from 0.22354 to 0.22345, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2234 - categorical_crossentropy: 0.2234 - val_loss: 0.2183 - val_categorical_crossentropy: 0.2183\n",
      "Epoch 120/250\n",
      "Epoch 00120: categorical_crossentropy improved from 0.22345 to 0.22336, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2234 - categorical_crossentropy: 0.2234 - val_loss: 0.2179 - val_categorical_crossentropy: 0.2179\n",
      "Epoch 121/250\n",
      "Epoch 00121: categorical_crossentropy improved from 0.22336 to 0.22324, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2232 - categorical_crossentropy: 0.2232 - val_loss: 0.2180 - val_categorical_crossentropy: 0.2180\n",
      "Epoch 122/250\n",
      "Epoch 00122: categorical_crossentropy improved from 0.22324 to 0.22323, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2232 - categorical_crossentropy: 0.2232 - val_loss: 0.2178 - val_categorical_crossentropy: 0.2178\n",
      "Epoch 123/250\n",
      "Epoch 00123: categorical_crossentropy improved from 0.22323 to 0.22318, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2232 - categorical_crossentropy: 0.2232 - val_loss: 0.2176 - val_categorical_crossentropy: 0.2176\n",
      "Epoch 124/250\n",
      "Epoch 00124: categorical_crossentropy improved from 0.22318 to 0.22309, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2231 - categorical_crossentropy: 0.2231 - val_loss: 0.2176 - val_categorical_crossentropy: 0.2176\n",
      "Epoch 125/250\n",
      "Epoch 00125: categorical_crossentropy improved from 0.22309 to 0.22302, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2230 - categorical_crossentropy: 0.2230 - val_loss: 0.2181 - val_categorical_crossentropy: 0.2181\n",
      "Epoch 126/250\n",
      "Epoch 00126: categorical_crossentropy improved from 0.22302 to 0.22295, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2229 - categorical_crossentropy: 0.2229 - val_loss: 0.2178 - val_categorical_crossentropy: 0.2178\n",
      "Epoch 127/250\n",
      "Epoch 00127: categorical_crossentropy improved from 0.22295 to 0.22291, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2229 - categorical_crossentropy: 0.2229 - val_loss: 0.2177 - val_categorical_crossentropy: 0.2177\n",
      "Epoch 128/250\n",
      "Epoch 00128: categorical_crossentropy improved from 0.22291 to 0.22282, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2228 - categorical_crossentropy: 0.2228 - val_loss: 0.2177 - val_categorical_crossentropy: 0.2177\n",
      "Epoch 129/250\n",
      "Epoch 00129: categorical_crossentropy improved from 0.22282 to 0.22276, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2228 - categorical_crossentropy: 0.2228 - val_loss: 0.2173 - val_categorical_crossentropy: 0.2173\n",
      "Epoch 130/250\n",
      "Epoch 00130: categorical_crossentropy improved from 0.22276 to 0.22273, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2227 - categorical_crossentropy: 0.2227 - val_loss: 0.2177 - val_categorical_crossentropy: 0.2177\n",
      "Epoch 131/250\n",
      "Epoch 00131: categorical_crossentropy improved from 0.22273 to 0.22266, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2227 - categorical_crossentropy: 0.2227 - val_loss: 0.2173 - val_categorical_crossentropy: 0.2173\n",
      "Epoch 132/250\n",
      "Epoch 00132: categorical_crossentropy improved from 0.22266 to 0.22254, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2225 - categorical_crossentropy: 0.2225 - val_loss: 0.2173 - val_categorical_crossentropy: 0.2173\n",
      "Epoch 133/250\n",
      "Epoch 00133: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2226 - categorical_crossentropy: 0.2226 - val_loss: 0.2172 - val_categorical_crossentropy: 0.2172\n",
      "Epoch 134/250\n",
      "Epoch 00134: categorical_crossentropy improved from 0.22254 to 0.22247, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2225 - categorical_crossentropy: 0.2225 - val_loss: 0.2171 - val_categorical_crossentropy: 0.2171\n",
      "Epoch 135/250\n",
      "Epoch 00135: categorical_crossentropy improved from 0.22247 to 0.22241, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2224 - categorical_crossentropy: 0.2224 - val_loss: 0.2170 - val_categorical_crossentropy: 0.2170\n",
      "Epoch 136/250\n",
      "Epoch 00136: categorical_crossentropy improved from 0.22241 to 0.22225, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2222 - categorical_crossentropy: 0.2222 - val_loss: 0.2168 - val_categorical_crossentropy: 0.2168\n",
      "Epoch 137/250\n",
      "Epoch 00137: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2223 - categorical_crossentropy: 0.2223 - val_loss: 0.2167 - val_categorical_crossentropy: 0.2167\n",
      "Epoch 138/250\n",
      "Epoch 00138: categorical_crossentropy improved from 0.22225 to 0.22224, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2222 - categorical_crossentropy: 0.2222 - val_loss: 0.2168 - val_categorical_crossentropy: 0.2168\n",
      "Epoch 139/250\n",
      "Epoch 00139: categorical_crossentropy improved from 0.22224 to 0.22223, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2222 - categorical_crossentropy: 0.2222 - val_loss: 0.2168 - val_categorical_crossentropy: 0.2168\n",
      "Epoch 140/250\n",
      "Epoch 00140: categorical_crossentropy improved from 0.22223 to 0.22216, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2222 - categorical_crossentropy: 0.2222 - val_loss: 0.2170 - val_categorical_crossentropy: 0.2170\n",
      "Epoch 141/250\n",
      "Epoch 00141: categorical_crossentropy improved from 0.22216 to 0.22205, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2220 - categorical_crossentropy: 0.2220 - val_loss: 0.2167 - val_categorical_crossentropy: 0.2167\n",
      "Epoch 142/250\n",
      "Epoch 00142: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2221 - categorical_crossentropy: 0.2221 - val_loss: 0.2168 - val_categorical_crossentropy: 0.2168\n",
      "Epoch 143/250\n",
      "Epoch 00143: categorical_crossentropy improved from 0.22205 to 0.22199, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2220 - categorical_crossentropy: 0.2220 - val_loss: 0.2165 - val_categorical_crossentropy: 0.2165\n",
      "Epoch 144/250\n",
      "Epoch 00144: categorical_crossentropy improved from 0.22199 to 0.22191, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2219 - categorical_crossentropy: 0.2219 - val_loss: 0.2166 - val_categorical_crossentropy: 0.2166\n",
      "Epoch 145/250\n",
      "Epoch 00145: categorical_crossentropy improved from 0.22191 to 0.22186, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2219 - categorical_crossentropy: 0.2219 - val_loss: 0.2166 - val_categorical_crossentropy: 0.2166\n",
      "Epoch 146/250\n",
      "Epoch 00146: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2219 - categorical_crossentropy: 0.2219 - val_loss: 0.2166 - val_categorical_crossentropy: 0.2166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/250\n",
      "Epoch 00147: categorical_crossentropy improved from 0.22186 to 0.22179, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2218 - categorical_crossentropy: 0.2218 - val_loss: 0.2164 - val_categorical_crossentropy: 0.2164\n",
      "Epoch 148/250\n",
      "Epoch 00148: categorical_crossentropy improved from 0.22179 to 0.22169, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2217 - categorical_crossentropy: 0.2217 - val_loss: 0.2164 - val_categorical_crossentropy: 0.2164\n",
      "Epoch 149/250\n",
      "Epoch 00149: categorical_crossentropy improved from 0.22169 to 0.22167, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2217 - categorical_crossentropy: 0.2217 - val_loss: 0.2167 - val_categorical_crossentropy: 0.2167\n",
      "Epoch 150/250\n",
      "Epoch 00150: categorical_crossentropy improved from 0.22167 to 0.22165, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2217 - categorical_crossentropy: 0.2217 - val_loss: 0.2164 - val_categorical_crossentropy: 0.2164\n",
      "Epoch 151/250\n",
      "Epoch 00151: categorical_crossentropy improved from 0.22165 to 0.22161, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2216 - categorical_crossentropy: 0.2216 - val_loss: 0.2163 - val_categorical_crossentropy: 0.2163\n",
      "Epoch 152/250\n",
      "Epoch 00152: categorical_crossentropy improved from 0.22161 to 0.22153, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2215 - categorical_crossentropy: 0.2215 - val_loss: 0.2166 - val_categorical_crossentropy: 0.2166\n",
      "Epoch 153/250\n",
      "Epoch 00153: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2215 - categorical_crossentropy: 0.2215 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 154/250\n",
      "Epoch 00154: categorical_crossentropy improved from 0.22153 to 0.22146, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2215 - categorical_crossentropy: 0.2215 - val_loss: 0.2163 - val_categorical_crossentropy: 0.2163\n",
      "Epoch 155/250\n",
      "Epoch 00155: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2215 - categorical_crossentropy: 0.2215 - val_loss: 0.2159 - val_categorical_crossentropy: 0.2159\n",
      "Epoch 156/250\n",
      "Epoch 00156: categorical_crossentropy improved from 0.22146 to 0.22137, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2214 - categorical_crossentropy: 0.2214 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 157/250\n",
      "Epoch 00157: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2215 - categorical_crossentropy: 0.2215 - val_loss: 0.2162 - val_categorical_crossentropy: 0.2162\n",
      "Epoch 158/250\n",
      "Epoch 00158: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2214 - categorical_crossentropy: 0.2214 - val_loss: 0.2160 - val_categorical_crossentropy: 0.2160\n",
      "Epoch 159/250\n",
      "Epoch 00159: categorical_crossentropy improved from 0.22137 to 0.22128, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2213 - categorical_crossentropy: 0.2213 - val_loss: 0.2159 - val_categorical_crossentropy: 0.2159\n",
      "Epoch 160/250\n",
      "Epoch 00160: categorical_crossentropy improved from 0.22128 to 0.22125, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2213 - categorical_crossentropy: 0.2213 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 161/250\n",
      "Epoch 00161: categorical_crossentropy improved from 0.22125 to 0.22121, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2212 - categorical_crossentropy: 0.2212 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 162/250\n",
      "Epoch 00162: categorical_crossentropy improved from 0.22121 to 0.22110, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2211 - categorical_crossentropy: 0.2211 - val_loss: 0.2165 - val_categorical_crossentropy: 0.2165\n",
      "Epoch 163/250\n",
      "Epoch 00163: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2211 - categorical_crossentropy: 0.2211 - val_loss: 0.2157 - val_categorical_crossentropy: 0.2157\n",
      "Epoch 164/250\n",
      "Epoch 00164: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2212 - categorical_crossentropy: 0.2212 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 165/250\n",
      "Epoch 00165: categorical_crossentropy improved from 0.22110 to 0.22103, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2210 - categorical_crossentropy: 0.2210 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 166/250\n",
      "Epoch 00166: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2211 - categorical_crossentropy: 0.2211 - val_loss: 0.2157 - val_categorical_crossentropy: 0.2157\n",
      "Epoch 167/250\n",
      "Epoch 00167: categorical_crossentropy improved from 0.22103 to 0.22101, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2210 - categorical_crossentropy: 0.2210 - val_loss: 0.2160 - val_categorical_crossentropy: 0.2160\n",
      "Epoch 168/250\n",
      "Epoch 00168: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2211 - categorical_crossentropy: 0.2211 - val_loss: 0.2157 - val_categorical_crossentropy: 0.2157\n",
      "Epoch 169/250\n",
      "Epoch 00169: categorical_crossentropy improved from 0.22101 to 0.22090, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2209 - categorical_crossentropy: 0.2209 - val_loss: 0.2156 - val_categorical_crossentropy: 0.2156\n",
      "Epoch 170/250\n",
      "Epoch 00170: categorical_crossentropy improved from 0.22090 to 0.22084, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 171/250\n",
      "Epoch 00171: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 172/250\n",
      "Epoch 00172: categorical_crossentropy improved from 0.22084 to 0.22070, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2207 - categorical_crossentropy: 0.2207 - val_loss: 0.2157 - val_categorical_crossentropy: 0.2157\n",
      "Epoch 173/250\n",
      "Epoch 00173: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 174/250\n",
      "Epoch 00174: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2207 - categorical_crossentropy: 0.2207 - val_loss: 0.2157 - val_categorical_crossentropy: 0.2157\n",
      "Epoch 175/250\n",
      "Epoch 00175: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 176/250\n",
      "Epoch 00176: categorical_crossentropy improved from 0.22070 to 0.22065, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2206 - categorical_crossentropy: 0.2206 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 177/250\n",
      "Epoch 00177: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2207 - categorical_crossentropy: 0.2207 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 178/250\n",
      "Epoch 00178: categorical_crossentropy improved from 0.22065 to 0.22058, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2206 - categorical_crossentropy: 0.2206 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 179/250\n",
      "Epoch 00179: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2206 - categorical_crossentropy: 0.2206 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 180/250\n",
      "Epoch 00180: categorical_crossentropy improved from 0.22058 to 0.22054, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2205 - categorical_crossentropy: 0.2205 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 181/250\n",
      "Epoch 00181: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2206 - categorical_crossentropy: 0.2206 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 182/250\n",
      "Epoch 00182: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2205 - categorical_crossentropy: 0.2205 - val_loss: 0.2152 - val_categorical_crossentropy: 0.2152\n",
      "Epoch 183/250\n",
      "Epoch 00183: categorical_crossentropy improved from 0.22054 to 0.22039, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 184/250\n",
      "Epoch 00184: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2205 - categorical_crossentropy: 0.2205 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 185/250\n",
      "Epoch 00185: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 186/250\n",
      "Epoch 00186: categorical_crossentropy improved from 0.22039 to 0.22036, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/250\n",
      "Epoch 00187: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2205 - categorical_crossentropy: 0.2205 - val_loss: 0.2150 - val_categorical_crossentropy: 0.2150\n",
      "Epoch 188/250\n",
      "Epoch 00188: categorical_crossentropy improved from 0.22036 to 0.22029, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2203 - categorical_crossentropy: 0.2203 - val_loss: 0.2150 - val_categorical_crossentropy: 0.2150\n",
      "Epoch 189/250\n",
      "Epoch 00189: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 190/250\n",
      "Epoch 00190: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2203 - categorical_crossentropy: 0.2203 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 191/250\n",
      "Epoch 00191: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2203 - categorical_crossentropy: 0.2203 - val_loss: 0.2150 - val_categorical_crossentropy: 0.2150\n",
      "Epoch 192/250\n",
      "Epoch 00192: categorical_crossentropy improved from 0.22029 to 0.22022, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2150 - val_categorical_crossentropy: 0.2150\n",
      "Epoch 193/250\n",
      "Epoch 00193: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 194/250\n",
      "Epoch 00194: categorical_crossentropy improved from 0.22022 to 0.22021, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2156 - val_categorical_crossentropy: 0.2156\n",
      "Epoch 195/250\n",
      "Epoch 00195: categorical_crossentropy improved from 0.22021 to 0.22019, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 196/250\n",
      "Epoch 00196: categorical_crossentropy improved from 0.22019 to 0.22005, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 197/250\n",
      "Epoch 00197: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 198/250\n",
      "Epoch 00198: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 199/250\n",
      "Epoch 00199: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 200/250\n",
      "Epoch 00200: categorical_crossentropy improved from 0.22005 to 0.22005, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2150 - val_categorical_crossentropy: 0.2150\n",
      "Epoch 201/250\n",
      "Epoch 00201: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 202/250\n",
      "Epoch 00202: categorical_crossentropy improved from 0.22005 to 0.22003, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 203/250\n",
      "Epoch 00203: categorical_crossentropy improved from 0.22003 to 0.21998, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 204/250\n",
      "Epoch 00204: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 205/250\n",
      "Epoch 00205: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 206/250\n",
      "Epoch 00206: categorical_crossentropy improved from 0.21998 to 0.21995, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2150 - val_categorical_crossentropy: 0.2150\n",
      "Epoch 207/250\n",
      "Epoch 00207: categorical_crossentropy improved from 0.21995 to 0.21992, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 208/250\n",
      "Epoch 00208: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 209/250\n",
      "Epoch 00209: categorical_crossentropy improved from 0.21992 to 0.21991, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 210/250\n",
      "Epoch 00210: categorical_crossentropy improved from 0.21991 to 0.21986, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2147 - val_categorical_crossentropy: 0.2147\n",
      "Epoch 211/250\n",
      "Epoch 00211: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2147 - val_categorical_crossentropy: 0.2147\n",
      "Epoch 212/250\n",
      "Epoch 00212: categorical_crossentropy improved from 0.21986 to 0.21981, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 213/250\n",
      "Epoch 00213: categorical_crossentropy improved from 0.21981 to 0.21978, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 214/250\n",
      "Epoch 00214: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2147 - val_categorical_crossentropy: 0.2147\n",
      "Epoch 215/250\n",
      "Epoch 00215: categorical_crossentropy improved from 0.21978 to 0.21977, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 216/250\n",
      "Epoch 00216: categorical_crossentropy improved from 0.21977 to 0.21974, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2197 - categorical_crossentropy: 0.2197 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 217/250\n",
      "Epoch 00217: categorical_crossentropy improved from 0.21974 to 0.21968, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2197 - categorical_crossentropy: 0.2197 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 218/250\n",
      "Epoch 00218: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2197 - categorical_crossentropy: 0.2197 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 219/250\n",
      "Epoch 00219: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2145 - val_categorical_crossentropy: 0.2145\n",
      "Epoch 220/250\n",
      "Epoch 00220: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2197 - categorical_crossentropy: 0.2197 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 221/250\n",
      "Epoch 00221: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2197 - categorical_crossentropy: 0.2197 - val_loss: 0.2145 - val_categorical_crossentropy: 0.2145\n",
      "Epoch 222/250\n",
      "Epoch 00222: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 223/250\n",
      "Epoch 00223: categorical_crossentropy improved from 0.21968 to 0.21964, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 224/250\n",
      "Epoch 00224: categorical_crossentropy improved from 0.21964 to 0.21960, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 225/250\n",
      "Epoch 00225: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2145 - val_categorical_crossentropy: 0.2145\n",
      "Epoch 226/250\n",
      "Epoch 00226: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/250\n",
      "Epoch 00227: categorical_crossentropy improved from 0.21960 to 0.21960, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 228/250\n",
      "Epoch 00228: categorical_crossentropy improved from 0.21960 to 0.21957, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 229/250\n",
      "Epoch 00229: categorical_crossentropy improved from 0.21957 to 0.21953, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2195 - categorical_crossentropy: 0.2195 - val_loss: 0.2145 - val_categorical_crossentropy: 0.2145\n",
      "Epoch 230/250\n",
      "Epoch 00230: categorical_crossentropy improved from 0.21953 to 0.21952, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2195 - categorical_crossentropy: 0.2195 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 231/250\n",
      "Epoch 00231: categorical_crossentropy improved from 0.21952 to 0.21950, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2195 - categorical_crossentropy: 0.2195 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 232/250\n",
      "Epoch 00232: categorical_crossentropy improved from 0.21950 to 0.21947, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2195 - categorical_crossentropy: 0.2195 - val_loss: 0.2143 - val_categorical_crossentropy: 0.2143\n",
      "Epoch 233/250\n",
      "Epoch 00233: categorical_crossentropy improved from 0.21947 to 0.21946, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2195 - categorical_crossentropy: 0.2195 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 234/250\n",
      "Epoch 00234: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2195 - categorical_crossentropy: 0.2195 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 235/250\n",
      "Epoch 00235: categorical_crossentropy improved from 0.21946 to 0.21945, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2194 - categorical_crossentropy: 0.2194 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 236/250\n",
      "Epoch 00236: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2195 - categorical_crossentropy: 0.2195 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 237/250\n",
      "Epoch 00237: categorical_crossentropy improved from 0.21945 to 0.21941, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2194 - categorical_crossentropy: 0.2194 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 238/250\n",
      "Epoch 00238: categorical_crossentropy improved from 0.21941 to 0.21936, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2194 - categorical_crossentropy: 0.2194 - val_loss: 0.2143 - val_categorical_crossentropy: 0.2143\n",
      "Epoch 239/250\n",
      "Epoch 00239: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2194 - categorical_crossentropy: 0.2194 - val_loss: 0.2143 - val_categorical_crossentropy: 0.2143\n",
      "Epoch 240/250\n",
      "Epoch 00240: categorical_crossentropy improved from 0.21936 to 0.21935, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2193 - categorical_crossentropy: 0.2193 - val_loss: 0.2143 - val_categorical_crossentropy: 0.2143\n",
      "Epoch 241/250\n",
      "Epoch 00241: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2194 - categorical_crossentropy: 0.2194 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 242/250\n",
      "Epoch 00242: categorical_crossentropy improved from 0.21935 to 0.21934, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2193 - categorical_crossentropy: 0.2193 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 243/250\n",
      "Epoch 00243: categorical_crossentropy improved from 0.21934 to 0.21928, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2193 - categorical_crossentropy: 0.2193 - val_loss: 0.2141 - val_categorical_crossentropy: 0.2141\n",
      "Epoch 244/250\n",
      "Epoch 00244: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2193 - categorical_crossentropy: 0.2193 - val_loss: 0.2143 - val_categorical_crossentropy: 0.2143\n",
      "Epoch 245/250\n",
      "Epoch 00245: categorical_crossentropy improved from 0.21928 to 0.21925, saving model to lstm_simple.h5\n",
      " - 1s - loss: 0.2192 - categorical_crossentropy: 0.2192 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 246/250\n",
      "Epoch 00246: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2194 - categorical_crossentropy: 0.2194 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 247/250\n",
      "Epoch 00247: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2194 - categorical_crossentropy: 0.2194 - val_loss: 0.2141 - val_categorical_crossentropy: 0.2141\n",
      "Epoch 248/250\n",
      "Epoch 00248: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2193 - categorical_crossentropy: 0.2193 - val_loss: 0.2141 - val_categorical_crossentropy: 0.2141\n",
      "Epoch 249/250\n",
      "Epoch 00249: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2193 - categorical_crossentropy: 0.2193 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 250/250\n",
      "Epoch 00250: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2193 - categorical_crossentropy: 0.2193 - val_loss: 0.2141 - val_categorical_crossentropy: 0.2141\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 36, 7)             420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36, 7)             56        \n",
      "=================================================================\n",
      "Total params: 476\n",
      "Trainable params: 476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training time : 333.7961356639862s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    callbacks = [checkpoint, early])\n",
    "stop = time.time()\n",
    "t1 = stop-start\n",
    "print(model.summary())\n",
    "print(\"Training time : {}s\".format(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_steps = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN\n",
    "\n",
    "Using the same code, we can train the standard RNN. The principle is that every output of every hidden layers, are also feed as entry for the next step\n",
    "\n",
    "<img src=\"SimpleRNN.png\"/>\n",
    "\n",
    "This allows a \"short term memory\". It creates a kind of hysteresis used as memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(SimpleRNN(units=nb_unit, input_shape=inp_shape, return_sequences=True))\n",
    "model2.add(Dense(7, activation='softmax'))\n",
    "model2.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"srnn_simple.h5\",\n",
    "    monitor=loss_,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 256 samples\n",
      "Epoch 1/250\n",
      "Epoch 00001: categorical_crossentropy improved from inf to 0.91417, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.9142 - categorical_crossentropy: 0.9142 - val_loss: 0.8603 - val_categorical_crossentropy: 0.8603\n",
      "Epoch 2/250\n",
      "Epoch 00002: categorical_crossentropy improved from 0.91417 to 0.83965, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.8396 - categorical_crossentropy: 0.8396 - val_loss: 0.7900 - val_categorical_crossentropy: 0.7900\n",
      "Epoch 3/250\n",
      "Epoch 00003: categorical_crossentropy improved from 0.83965 to 0.77719, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.7772 - categorical_crossentropy: 0.7772 - val_loss: 0.7372 - val_categorical_crossentropy: 0.7372\n",
      "Epoch 4/250\n",
      "Epoch 00004: categorical_crossentropy improved from 0.77719 to 0.72912, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.7291 - categorical_crossentropy: 0.7291 - val_loss: 0.6942 - val_categorical_crossentropy: 0.6942\n",
      "Epoch 5/250\n",
      "Epoch 00005: categorical_crossentropy improved from 0.72912 to 0.68880, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.6888 - categorical_crossentropy: 0.6888 - val_loss: 0.6568 - val_categorical_crossentropy: 0.6568\n",
      "Epoch 6/250\n",
      "Epoch 00006: categorical_crossentropy improved from 0.68880 to 0.65163, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.6516 - categorical_crossentropy: 0.6516 - val_loss: 0.6203 - val_categorical_crossentropy: 0.6203\n",
      "Epoch 7/250\n",
      "Epoch 00007: categorical_crossentropy improved from 0.65163 to 0.61318, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.6132 - categorical_crossentropy: 0.6132 - val_loss: 0.5816 - val_categorical_crossentropy: 0.5816\n",
      "Epoch 8/250\n",
      "Epoch 00008: categorical_crossentropy improved from 0.61318 to 0.57157, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.5716 - categorical_crossentropy: 0.5716 - val_loss: 0.5390 - val_categorical_crossentropy: 0.5390\n",
      "Epoch 9/250\n",
      "Epoch 00009: categorical_crossentropy improved from 0.57157 to 0.52853, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.5285 - categorical_crossentropy: 0.5285 - val_loss: 0.4979 - val_categorical_crossentropy: 0.4979\n",
      "Epoch 10/250\n",
      "Epoch 00010: categorical_crossentropy improved from 0.52853 to 0.48900, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.4890 - categorical_crossentropy: 0.4890 - val_loss: 0.4624 - val_categorical_crossentropy: 0.4624\n",
      "Epoch 11/250\n",
      "Epoch 00011: categorical_crossentropy improved from 0.48900 to 0.45607, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.4561 - categorical_crossentropy: 0.4561 - val_loss: 0.4341 - val_categorical_crossentropy: 0.4341\n",
      "Epoch 12/250\n",
      "Epoch 00012: categorical_crossentropy improved from 0.45607 to 0.42972, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.4297 - categorical_crossentropy: 0.4297 - val_loss: 0.4114 - val_categorical_crossentropy: 0.4114\n",
      "Epoch 13/250\n",
      "Epoch 00013: categorical_crossentropy improved from 0.42972 to 0.40801, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.4080 - categorical_crossentropy: 0.4080 - val_loss: 0.3914 - val_categorical_crossentropy: 0.3914\n",
      "Epoch 14/250\n",
      "Epoch 00014: categorical_crossentropy improved from 0.40801 to 0.39007, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3901 - categorical_crossentropy: 0.3901 - val_loss: 0.3752 - val_categorical_crossentropy: 0.3752\n",
      "Epoch 15/250\n",
      "Epoch 00015: categorical_crossentropy improved from 0.39007 to 0.37473, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3747 - categorical_crossentropy: 0.3747 - val_loss: 0.3611 - val_categorical_crossentropy: 0.3611\n",
      "Epoch 16/250\n",
      "Epoch 00016: categorical_crossentropy improved from 0.37473 to 0.36134, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3613 - categorical_crossentropy: 0.3613 - val_loss: 0.3485 - val_categorical_crossentropy: 0.3485\n",
      "Epoch 17/250\n",
      "Epoch 00017: categorical_crossentropy improved from 0.36134 to 0.34928, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3493 - categorical_crossentropy: 0.3493 - val_loss: 0.3372 - val_categorical_crossentropy: 0.3372\n",
      "Epoch 18/250\n",
      "Epoch 00018: categorical_crossentropy improved from 0.34928 to 0.33819, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3382 - categorical_crossentropy: 0.3382 - val_loss: 0.3266 - val_categorical_crossentropy: 0.3266\n",
      "Epoch 19/250\n",
      "Epoch 00019: categorical_crossentropy improved from 0.33819 to 0.32785, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3279 - categorical_crossentropy: 0.3279 - val_loss: 0.3167 - val_categorical_crossentropy: 0.3167\n",
      "Epoch 20/250\n",
      "Epoch 00020: categorical_crossentropy improved from 0.32785 to 0.31827, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3183 - categorical_crossentropy: 0.3183 - val_loss: 0.3077 - val_categorical_crossentropy: 0.3077\n",
      "Epoch 21/250\n",
      "Epoch 00021: categorical_crossentropy improved from 0.31827 to 0.30954, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3095 - categorical_crossentropy: 0.3095 - val_loss: 0.2995 - val_categorical_crossentropy: 0.2995\n",
      "Epoch 22/250\n",
      "Epoch 00022: categorical_crossentropy improved from 0.30954 to 0.30175, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.3018 - categorical_crossentropy: 0.3018 - val_loss: 0.2923 - val_categorical_crossentropy: 0.2923\n",
      "Epoch 23/250\n",
      "Epoch 00023: categorical_crossentropy improved from 0.30175 to 0.29500, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2950 - categorical_crossentropy: 0.2950 - val_loss: 0.2861 - val_categorical_crossentropy: 0.2861\n",
      "Epoch 24/250\n",
      "Epoch 00024: categorical_crossentropy improved from 0.29500 to 0.28912, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2891 - categorical_crossentropy: 0.2891 - val_loss: 0.2806 - val_categorical_crossentropy: 0.2806\n",
      "Epoch 25/250\n",
      "Epoch 00025: categorical_crossentropy improved from 0.28912 to 0.28401, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2840 - categorical_crossentropy: 0.2840 - val_loss: 0.2760 - val_categorical_crossentropy: 0.2760\n",
      "Epoch 26/250\n",
      "Epoch 00026: categorical_crossentropy improved from 0.28401 to 0.27959, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2796 - categorical_crossentropy: 0.2796 - val_loss: 0.2718 - val_categorical_crossentropy: 0.2718\n",
      "Epoch 27/250\n",
      "Epoch 00027: categorical_crossentropy improved from 0.27959 to 0.27562, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2756 - categorical_crossentropy: 0.2756 - val_loss: 0.2683 - val_categorical_crossentropy: 0.2683\n",
      "Epoch 28/250\n",
      "Epoch 00028: categorical_crossentropy improved from 0.27562 to 0.27211, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2721 - categorical_crossentropy: 0.2721 - val_loss: 0.2648 - val_categorical_crossentropy: 0.2648\n",
      "Epoch 29/250\n",
      "Epoch 00029: categorical_crossentropy improved from 0.27211 to 0.26895, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2689 - categorical_crossentropy: 0.2689 - val_loss: 0.2617 - val_categorical_crossentropy: 0.2617\n",
      "Epoch 30/250\n",
      "Epoch 00030: categorical_crossentropy improved from 0.26895 to 0.26611, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2661 - categorical_crossentropy: 0.2661 - val_loss: 0.2589 - val_categorical_crossentropy: 0.2589\n",
      "Epoch 31/250\n",
      "Epoch 00031: categorical_crossentropy improved from 0.26611 to 0.26348, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2635 - categorical_crossentropy: 0.2635 - val_loss: 0.2566 - val_categorical_crossentropy: 0.2566\n",
      "Epoch 32/250\n",
      "Epoch 00032: categorical_crossentropy improved from 0.26348 to 0.26106, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2611 - categorical_crossentropy: 0.2611 - val_loss: 0.2545 - val_categorical_crossentropy: 0.2545\n",
      "Epoch 33/250\n",
      "Epoch 00033: categorical_crossentropy improved from 0.26106 to 0.25887, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2589 - categorical_crossentropy: 0.2589 - val_loss: 0.2519 - val_categorical_crossentropy: 0.2519\n",
      "Epoch 34/250\n",
      "Epoch 00034: categorical_crossentropy improved from 0.25887 to 0.25667, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2567 - categorical_crossentropy: 0.2567 - val_loss: 0.2502 - val_categorical_crossentropy: 0.2502\n",
      "Epoch 35/250\n",
      "Epoch 00035: categorical_crossentropy improved from 0.25667 to 0.25480, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2548 - categorical_crossentropy: 0.2548 - val_loss: 0.2492 - val_categorical_crossentropy: 0.2492\n",
      "Epoch 36/250\n",
      "Epoch 00036: categorical_crossentropy improved from 0.25480 to 0.25304, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2530 - categorical_crossentropy: 0.2530 - val_loss: 0.2464 - val_categorical_crossentropy: 0.2464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "Epoch 00037: categorical_crossentropy improved from 0.25304 to 0.25115, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2511 - categorical_crossentropy: 0.2511 - val_loss: 0.2448 - val_categorical_crossentropy: 0.2448\n",
      "Epoch 38/250\n",
      "Epoch 00038: categorical_crossentropy improved from 0.25115 to 0.24957, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2496 - categorical_crossentropy: 0.2496 - val_loss: 0.2429 - val_categorical_crossentropy: 0.2429\n",
      "Epoch 39/250\n",
      "Epoch 00039: categorical_crossentropy improved from 0.24957 to 0.24801, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2480 - categorical_crossentropy: 0.2480 - val_loss: 0.2413 - val_categorical_crossentropy: 0.2413\n",
      "Epoch 40/250\n",
      "Epoch 00040: categorical_crossentropy improved from 0.24801 to 0.24665, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2466 - categorical_crossentropy: 0.2466 - val_loss: 0.2400 - val_categorical_crossentropy: 0.2400\n",
      "Epoch 41/250\n",
      "Epoch 00041: categorical_crossentropy improved from 0.24665 to 0.24538, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2454 - categorical_crossentropy: 0.2454 - val_loss: 0.2389 - val_categorical_crossentropy: 0.2389\n",
      "Epoch 42/250\n",
      "Epoch 00042: categorical_crossentropy improved from 0.24538 to 0.24432, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2443 - categorical_crossentropy: 0.2443 - val_loss: 0.2378 - val_categorical_crossentropy: 0.2378\n",
      "Epoch 43/250\n",
      "Epoch 00043: categorical_crossentropy improved from 0.24432 to 0.24311, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2431 - categorical_crossentropy: 0.2431 - val_loss: 0.2368 - val_categorical_crossentropy: 0.2368\n",
      "Epoch 44/250\n",
      "Epoch 00044: categorical_crossentropy improved from 0.24311 to 0.24214, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2421 - categorical_crossentropy: 0.2421 - val_loss: 0.2357 - val_categorical_crossentropy: 0.2357\n",
      "Epoch 45/250\n",
      "Epoch 00045: categorical_crossentropy improved from 0.24214 to 0.24113, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2411 - categorical_crossentropy: 0.2411 - val_loss: 0.2347 - val_categorical_crossentropy: 0.2347\n",
      "Epoch 46/250\n",
      "Epoch 00046: categorical_crossentropy improved from 0.24113 to 0.24037, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2404 - categorical_crossentropy: 0.2404 - val_loss: 0.2339 - val_categorical_crossentropy: 0.2339\n",
      "Epoch 47/250\n",
      "Epoch 00047: categorical_crossentropy improved from 0.24037 to 0.23935, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2394 - categorical_crossentropy: 0.2394 - val_loss: 0.2332 - val_categorical_crossentropy: 0.2332\n",
      "Epoch 48/250\n",
      "Epoch 00048: categorical_crossentropy improved from 0.23935 to 0.23866, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2387 - categorical_crossentropy: 0.2387 - val_loss: 0.2322 - val_categorical_crossentropy: 0.2322\n",
      "Epoch 49/250\n",
      "Epoch 00049: categorical_crossentropy improved from 0.23866 to 0.23799, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2380 - categorical_crossentropy: 0.2380 - val_loss: 0.2316 - val_categorical_crossentropy: 0.2316\n",
      "Epoch 50/250\n",
      "Epoch 00050: categorical_crossentropy improved from 0.23799 to 0.23746, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2375 - categorical_crossentropy: 0.2375 - val_loss: 0.2311 - val_categorical_crossentropy: 0.2311\n",
      "Epoch 51/250\n",
      "Epoch 00051: categorical_crossentropy improved from 0.23746 to 0.23665, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2366 - categorical_crossentropy: 0.2366 - val_loss: 0.2301 - val_categorical_crossentropy: 0.2301\n",
      "Epoch 52/250\n",
      "Epoch 00052: categorical_crossentropy improved from 0.23665 to 0.23608, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2361 - categorical_crossentropy: 0.2361 - val_loss: 0.2301 - val_categorical_crossentropy: 0.2301\n",
      "Epoch 53/250\n",
      "Epoch 00053: categorical_crossentropy improved from 0.23608 to 0.23557, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2356 - categorical_crossentropy: 0.2356 - val_loss: 0.2298 - val_categorical_crossentropy: 0.2298\n",
      "Epoch 54/250\n",
      "Epoch 00054: categorical_crossentropy improved from 0.23557 to 0.23520, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2352 - categorical_crossentropy: 0.2352 - val_loss: 0.2286 - val_categorical_crossentropy: 0.2286\n",
      "Epoch 55/250\n",
      "Epoch 00055: categorical_crossentropy improved from 0.23520 to 0.23469, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2347 - categorical_crossentropy: 0.2347 - val_loss: 0.2282 - val_categorical_crossentropy: 0.2282\n",
      "Epoch 56/250\n",
      "Epoch 00056: categorical_crossentropy improved from 0.23469 to 0.23409, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2341 - categorical_crossentropy: 0.2341 - val_loss: 0.2277 - val_categorical_crossentropy: 0.2277\n",
      "Epoch 57/250\n",
      "Epoch 00057: categorical_crossentropy improved from 0.23409 to 0.23361, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2336 - categorical_crossentropy: 0.2336 - val_loss: 0.2271 - val_categorical_crossentropy: 0.2271\n",
      "Epoch 58/250\n",
      "Epoch 00058: categorical_crossentropy improved from 0.23361 to 0.23352, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2335 - categorical_crossentropy: 0.2335 - val_loss: 0.2273 - val_categorical_crossentropy: 0.2273\n",
      "Epoch 59/250\n",
      "Epoch 00059: categorical_crossentropy improved from 0.23352 to 0.23282, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2328 - categorical_crossentropy: 0.2328 - val_loss: 0.2267 - val_categorical_crossentropy: 0.2267\n",
      "Epoch 60/250\n",
      "Epoch 00060: categorical_crossentropy improved from 0.23282 to 0.23247, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2325 - categorical_crossentropy: 0.2325 - val_loss: 0.2261 - val_categorical_crossentropy: 0.2261\n",
      "Epoch 61/250\n",
      "Epoch 00061: categorical_crossentropy improved from 0.23247 to 0.23216, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2322 - categorical_crossentropy: 0.2322 - val_loss: 0.2256 - val_categorical_crossentropy: 0.2256\n",
      "Epoch 62/250\n",
      "Epoch 00062: categorical_crossentropy improved from 0.23216 to 0.23170, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2317 - categorical_crossentropy: 0.2317 - val_loss: 0.2254 - val_categorical_crossentropy: 0.2254\n",
      "Epoch 63/250\n",
      "Epoch 00063: categorical_crossentropy improved from 0.23170 to 0.23156, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2316 - categorical_crossentropy: 0.2316 - val_loss: 0.2252 - val_categorical_crossentropy: 0.2252\n",
      "Epoch 64/250\n",
      "Epoch 00064: categorical_crossentropy improved from 0.23156 to 0.23123, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2312 - categorical_crossentropy: 0.2312 - val_loss: 0.2249 - val_categorical_crossentropy: 0.2249\n",
      "Epoch 65/250\n",
      "Epoch 00065: categorical_crossentropy improved from 0.23123 to 0.23089, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2309 - categorical_crossentropy: 0.2309 - val_loss: 0.2245 - val_categorical_crossentropy: 0.2245\n",
      "Epoch 66/250\n",
      "Epoch 00066: categorical_crossentropy improved from 0.23089 to 0.23072, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2307 - categorical_crossentropy: 0.2307 - val_loss: 0.2244 - val_categorical_crossentropy: 0.2244\n",
      "Epoch 67/250\n",
      "Epoch 00067: categorical_crossentropy improved from 0.23072 to 0.23049, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2305 - categorical_crossentropy: 0.2305 - val_loss: 0.2240 - val_categorical_crossentropy: 0.2240\n",
      "Epoch 68/250\n",
      "Epoch 00068: categorical_crossentropy improved from 0.23049 to 0.23017, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2302 - categorical_crossentropy: 0.2302 - val_loss: 0.2238 - val_categorical_crossentropy: 0.2238\n",
      "Epoch 69/250\n",
      "Epoch 00069: categorical_crossentropy improved from 0.23017 to 0.22982, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2298 - categorical_crossentropy: 0.2298 - val_loss: 0.2237 - val_categorical_crossentropy: 0.2237\n",
      "Epoch 70/250\n",
      "Epoch 00070: categorical_crossentropy improved from 0.22982 to 0.22955, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2295 - categorical_crossentropy: 0.2295 - val_loss: 0.2233 - val_categorical_crossentropy: 0.2233\n",
      "Epoch 71/250\n",
      "Epoch 00071: categorical_crossentropy improved from 0.22955 to 0.22944, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2294 - categorical_crossentropy: 0.2294 - val_loss: 0.2233 - val_categorical_crossentropy: 0.2233\n",
      "Epoch 72/250\n",
      "Epoch 00072: categorical_crossentropy improved from 0.22944 to 0.22914, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2291 - categorical_crossentropy: 0.2291 - val_loss: 0.2232 - val_categorical_crossentropy: 0.2232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/250\n",
      "Epoch 00073: categorical_crossentropy improved from 0.22914 to 0.22899, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2290 - categorical_crossentropy: 0.2290 - val_loss: 0.2226 - val_categorical_crossentropy: 0.2226\n",
      "Epoch 74/250\n",
      "Epoch 00074: categorical_crossentropy improved from 0.22899 to 0.22866, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2287 - categorical_crossentropy: 0.2287 - val_loss: 0.2231 - val_categorical_crossentropy: 0.2231\n",
      "Epoch 75/250\n",
      "Epoch 00075: categorical_crossentropy improved from 0.22866 to 0.22862, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2286 - categorical_crossentropy: 0.2286 - val_loss: 0.2224 - val_categorical_crossentropy: 0.2224\n",
      "Epoch 76/250\n",
      "Epoch 00076: categorical_crossentropy improved from 0.22862 to 0.22842, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2284 - categorical_crossentropy: 0.2284 - val_loss: 0.2223 - val_categorical_crossentropy: 0.2223\n",
      "Epoch 77/250\n",
      "Epoch 00077: categorical_crossentropy improved from 0.22842 to 0.22807, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2281 - categorical_crossentropy: 0.2281 - val_loss: 0.2220 - val_categorical_crossentropy: 0.2220\n",
      "Epoch 78/250\n",
      "Epoch 00078: categorical_crossentropy improved from 0.22807 to 0.22795, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2279 - categorical_crossentropy: 0.2279 - val_loss: 0.2227 - val_categorical_crossentropy: 0.2227\n",
      "Epoch 79/250\n",
      "Epoch 00079: categorical_crossentropy improved from 0.22795 to 0.22770, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2277 - categorical_crossentropy: 0.2277 - val_loss: 0.2216 - val_categorical_crossentropy: 0.2216\n",
      "Epoch 80/250\n",
      "Epoch 00080: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2278 - categorical_crossentropy: 0.2278 - val_loss: 0.2216 - val_categorical_crossentropy: 0.2216\n",
      "Epoch 81/250\n",
      "Epoch 00081: categorical_crossentropy improved from 0.22770 to 0.22750, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2275 - categorical_crossentropy: 0.2275 - val_loss: 0.2215 - val_categorical_crossentropy: 0.2215\n",
      "Epoch 82/250\n",
      "Epoch 00082: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2275 - categorical_crossentropy: 0.2275 - val_loss: 0.2213 - val_categorical_crossentropy: 0.2213\n",
      "Epoch 83/250\n",
      "Epoch 00083: categorical_crossentropy improved from 0.22750 to 0.22739, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2274 - categorical_crossentropy: 0.2274 - val_loss: 0.2215 - val_categorical_crossentropy: 0.2215\n",
      "Epoch 84/250\n",
      "Epoch 00084: categorical_crossentropy improved from 0.22739 to 0.22705, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2271 - categorical_crossentropy: 0.2271 - val_loss: 0.2212 - val_categorical_crossentropy: 0.2212\n",
      "Epoch 85/250\n",
      "Epoch 00085: categorical_crossentropy improved from 0.22705 to 0.22691, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2269 - categorical_crossentropy: 0.2269 - val_loss: 0.2208 - val_categorical_crossentropy: 0.2208\n",
      "Epoch 86/250\n",
      "Epoch 00086: categorical_crossentropy improved from 0.22691 to 0.22690, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2269 - categorical_crossentropy: 0.2269 - val_loss: 0.2208 - val_categorical_crossentropy: 0.2208\n",
      "Epoch 87/250\n",
      "Epoch 00087: categorical_crossentropy improved from 0.22690 to 0.22677, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2268 - categorical_crossentropy: 0.2268 - val_loss: 0.2214 - val_categorical_crossentropy: 0.2214\n",
      "Epoch 88/250\n",
      "Epoch 00088: categorical_crossentropy improved from 0.22677 to 0.22656, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2266 - categorical_crossentropy: 0.2266 - val_loss: 0.2205 - val_categorical_crossentropy: 0.2205\n",
      "Epoch 89/250\n",
      "Epoch 00089: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2266 - categorical_crossentropy: 0.2266 - val_loss: 0.2207 - val_categorical_crossentropy: 0.2207\n",
      "Epoch 90/250\n",
      "Epoch 00090: categorical_crossentropy improved from 0.22656 to 0.22636, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2264 - categorical_crossentropy: 0.2264 - val_loss: 0.2204 - val_categorical_crossentropy: 0.2204\n",
      "Epoch 91/250\n",
      "Epoch 00091: categorical_crossentropy improved from 0.22636 to 0.22621, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2262 - categorical_crossentropy: 0.2262 - val_loss: 0.2202 - val_categorical_crossentropy: 0.2202\n",
      "Epoch 92/250\n",
      "Epoch 00092: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2265 - categorical_crossentropy: 0.2265 - val_loss: 0.2220 - val_categorical_crossentropy: 0.2220\n",
      "Epoch 93/250\n",
      "Epoch 00093: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2263 - categorical_crossentropy: 0.2263 - val_loss: 0.2200 - val_categorical_crossentropy: 0.2200\n",
      "Epoch 94/250\n",
      "Epoch 00094: categorical_crossentropy improved from 0.22621 to 0.22598, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2260 - categorical_crossentropy: 0.2260 - val_loss: 0.2201 - val_categorical_crossentropy: 0.2201\n",
      "Epoch 95/250\n",
      "Epoch 00095: categorical_crossentropy improved from 0.22598 to 0.22592, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2259 - categorical_crossentropy: 0.2259 - val_loss: 0.2203 - val_categorical_crossentropy: 0.2203\n",
      "Epoch 96/250\n",
      "Epoch 00096: categorical_crossentropy improved from 0.22592 to 0.22567, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2257 - categorical_crossentropy: 0.2257 - val_loss: 0.2196 - val_categorical_crossentropy: 0.2196\n",
      "Epoch 97/250\n",
      "Epoch 00097: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2257 - categorical_crossentropy: 0.2257 - val_loss: 0.2197 - val_categorical_crossentropy: 0.2197\n",
      "Epoch 98/250\n",
      "Epoch 00098: categorical_crossentropy improved from 0.22567 to 0.22550, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2255 - categorical_crossentropy: 0.2255 - val_loss: 0.2199 - val_categorical_crossentropy: 0.2199\n",
      "Epoch 99/250\n",
      "Epoch 00099: categorical_crossentropy improved from 0.22550 to 0.22541, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2254 - categorical_crossentropy: 0.2254 - val_loss: 0.2216 - val_categorical_crossentropy: 0.2216\n",
      "Epoch 100/250\n",
      "Epoch 00100: categorical_crossentropy improved from 0.22541 to 0.22536, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2254 - categorical_crossentropy: 0.2254 - val_loss: 0.2202 - val_categorical_crossentropy: 0.2202\n",
      "Epoch 101/250\n",
      "Epoch 00101: categorical_crossentropy improved from 0.22536 to 0.22516, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2252 - categorical_crossentropy: 0.2252 - val_loss: 0.2193 - val_categorical_crossentropy: 0.2193\n",
      "Epoch 102/250\n",
      "Epoch 00102: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2252 - categorical_crossentropy: 0.2252 - val_loss: 0.2192 - val_categorical_crossentropy: 0.2192\n",
      "Epoch 103/250\n",
      "Epoch 00103: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2252 - categorical_crossentropy: 0.2252 - val_loss: 0.2191 - val_categorical_crossentropy: 0.2191\n",
      "Epoch 104/250\n",
      "Epoch 00104: categorical_crossentropy improved from 0.22516 to 0.22497, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2250 - categorical_crossentropy: 0.2250 - val_loss: 0.2194 - val_categorical_crossentropy: 0.2194\n",
      "Epoch 105/250\n",
      "Epoch 00105: categorical_crossentropy improved from 0.22497 to 0.22493, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2249 - categorical_crossentropy: 0.2249 - val_loss: 0.2192 - val_categorical_crossentropy: 0.2192\n",
      "Epoch 106/250\n",
      "Epoch 00106: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2252 - categorical_crossentropy: 0.2252 - val_loss: 0.2189 - val_categorical_crossentropy: 0.2189\n",
      "Epoch 107/250\n",
      "Epoch 00107: categorical_crossentropy improved from 0.22493 to 0.22475, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2247 - categorical_crossentropy: 0.2247 - val_loss: 0.2202 - val_categorical_crossentropy: 0.2202\n",
      "Epoch 108/250\n",
      "Epoch 00108: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2247 - categorical_crossentropy: 0.2247 - val_loss: 0.2191 - val_categorical_crossentropy: 0.2191\n",
      "Epoch 109/250\n",
      "Epoch 00109: categorical_crossentropy improved from 0.22475 to 0.22468, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2247 - categorical_crossentropy: 0.2247 - val_loss: 0.2187 - val_categorical_crossentropy: 0.2187\n",
      "Epoch 110/250\n",
      "Epoch 00110: categorical_crossentropy improved from 0.22468 to 0.22460, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2246 - categorical_crossentropy: 0.2246 - val_loss: 0.2187 - val_categorical_crossentropy: 0.2187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/250\n",
      "Epoch 00111: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2249 - categorical_crossentropy: 0.2249 - val_loss: 0.2189 - val_categorical_crossentropy: 0.2189\n",
      "Epoch 112/250\n",
      "Epoch 00112: categorical_crossentropy improved from 0.22460 to 0.22438, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2244 - categorical_crossentropy: 0.2244 - val_loss: 0.2185 - val_categorical_crossentropy: 0.2185\n",
      "Epoch 113/250\n",
      "Epoch 00113: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2246 - categorical_crossentropy: 0.2246 - val_loss: 0.2186 - val_categorical_crossentropy: 0.2186\n",
      "Epoch 114/250\n",
      "Epoch 00114: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2244 - categorical_crossentropy: 0.2244 - val_loss: 0.2187 - val_categorical_crossentropy: 0.2187\n",
      "Epoch 115/250\n",
      "Epoch 00115: categorical_crossentropy improved from 0.22438 to 0.22422, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2242 - categorical_crossentropy: 0.2242 - val_loss: 0.2184 - val_categorical_crossentropy: 0.2184\n",
      "Epoch 116/250\n",
      "Epoch 00116: categorical_crossentropy improved from 0.22422 to 0.22420, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2242 - categorical_crossentropy: 0.2242 - val_loss: 0.2182 - val_categorical_crossentropy: 0.2182\n",
      "Epoch 117/250\n",
      "Epoch 00117: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2244 - categorical_crossentropy: 0.2244 - val_loss: 0.2183 - val_categorical_crossentropy: 0.2183\n",
      "Epoch 118/250\n",
      "Epoch 00118: categorical_crossentropy improved from 0.22420 to 0.22410, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2241 - categorical_crossentropy: 0.2241 - val_loss: 0.2189 - val_categorical_crossentropy: 0.2189\n",
      "Epoch 119/250\n",
      "Epoch 00119: categorical_crossentropy improved from 0.22410 to 0.22393, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2239 - categorical_crossentropy: 0.2239 - val_loss: 0.2182 - val_categorical_crossentropy: 0.2182\n",
      "Epoch 120/250\n",
      "Epoch 00120: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2240 - categorical_crossentropy: 0.2240 - val_loss: 0.2182 - val_categorical_crossentropy: 0.2182\n",
      "Epoch 121/250\n",
      "Epoch 00121: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2240 - categorical_crossentropy: 0.2240 - val_loss: 0.2180 - val_categorical_crossentropy: 0.2180\n",
      "Epoch 122/250\n",
      "Epoch 00122: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2241 - categorical_crossentropy: 0.2241 - val_loss: 0.2178 - val_categorical_crossentropy: 0.2178\n",
      "Epoch 123/250\n",
      "Epoch 00123: categorical_crossentropy improved from 0.22393 to 0.22383, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2238 - categorical_crossentropy: 0.2238 - val_loss: 0.2179 - val_categorical_crossentropy: 0.2179\n",
      "Epoch 124/250\n",
      "Epoch 00124: categorical_crossentropy improved from 0.22383 to 0.22360, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2236 - categorical_crossentropy: 0.2236 - val_loss: 0.2181 - val_categorical_crossentropy: 0.2181\n",
      "Epoch 125/250\n",
      "Epoch 00125: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2237 - categorical_crossentropy: 0.2237 - val_loss: 0.2190 - val_categorical_crossentropy: 0.2190\n",
      "Epoch 126/250\n",
      "Epoch 00126: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2240 - categorical_crossentropy: 0.2240 - val_loss: 0.2178 - val_categorical_crossentropy: 0.2178\n",
      "Epoch 127/250\n",
      "Epoch 00127: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2236 - categorical_crossentropy: 0.2236 - val_loss: 0.2178 - val_categorical_crossentropy: 0.2178\n",
      "Epoch 128/250\n",
      "Epoch 00128: categorical_crossentropy improved from 0.22360 to 0.22354, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2235 - categorical_crossentropy: 0.2235 - val_loss: 0.2176 - val_categorical_crossentropy: 0.2176\n",
      "Epoch 129/250\n",
      "Epoch 00129: categorical_crossentropy improved from 0.22354 to 0.22352, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2235 - categorical_crossentropy: 0.2235 - val_loss: 0.2180 - val_categorical_crossentropy: 0.2180\n",
      "Epoch 130/250\n",
      "Epoch 00130: categorical_crossentropy improved from 0.22352 to 0.22341, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2234 - categorical_crossentropy: 0.2234 - val_loss: 0.2175 - val_categorical_crossentropy: 0.2175\n",
      "Epoch 131/250\n",
      "Epoch 00131: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2235 - categorical_crossentropy: 0.2235 - val_loss: 0.2178 - val_categorical_crossentropy: 0.2178\n",
      "Epoch 132/250\n",
      "Epoch 00132: categorical_crossentropy improved from 0.22341 to 0.22338, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2234 - categorical_crossentropy: 0.2234 - val_loss: 0.2179 - val_categorical_crossentropy: 0.2179\n",
      "Epoch 133/250\n",
      "Epoch 00133: categorical_crossentropy improved from 0.22338 to 0.22328, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2233 - categorical_crossentropy: 0.2233 - val_loss: 0.2177 - val_categorical_crossentropy: 0.2177\n",
      "Epoch 134/250\n",
      "Epoch 00134: categorical_crossentropy improved from 0.22328 to 0.22321, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2232 - categorical_crossentropy: 0.2232 - val_loss: 0.2174 - val_categorical_crossentropy: 0.2174\n",
      "Epoch 135/250\n",
      "Epoch 00135: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2233 - categorical_crossentropy: 0.2233 - val_loss: 0.2174 - val_categorical_crossentropy: 0.2174\n",
      "Epoch 136/250\n",
      "Epoch 00136: categorical_crossentropy improved from 0.22321 to 0.22306, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2231 - categorical_crossentropy: 0.2231 - val_loss: 0.2176 - val_categorical_crossentropy: 0.2176\n",
      "Epoch 137/250\n",
      "Epoch 00137: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2232 - categorical_crossentropy: 0.2232 - val_loss: 0.2173 - val_categorical_crossentropy: 0.2173\n",
      "Epoch 138/250\n",
      "Epoch 00138: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2232 - categorical_crossentropy: 0.2232 - val_loss: 0.2172 - val_categorical_crossentropy: 0.2172\n",
      "Epoch 139/250\n",
      "Epoch 00139: categorical_crossentropy improved from 0.22306 to 0.22296, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2230 - categorical_crossentropy: 0.2230 - val_loss: 0.2188 - val_categorical_crossentropy: 0.2188\n",
      "Epoch 140/250\n",
      "Epoch 00140: categorical_crossentropy improved from 0.22296 to 0.22288, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2229 - categorical_crossentropy: 0.2229 - val_loss: 0.2172 - val_categorical_crossentropy: 0.2172\n",
      "Epoch 141/250\n",
      "Epoch 00141: categorical_crossentropy improved from 0.22288 to 0.22279, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2228 - categorical_crossentropy: 0.2228 - val_loss: 0.2170 - val_categorical_crossentropy: 0.2170\n",
      "Epoch 142/250\n",
      "Epoch 00142: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2231 - categorical_crossentropy: 0.2231 - val_loss: 0.2171 - val_categorical_crossentropy: 0.2171\n",
      "Epoch 143/250\n",
      "Epoch 00143: categorical_crossentropy improved from 0.22279 to 0.22276, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2228 - categorical_crossentropy: 0.2228 - val_loss: 0.2174 - val_categorical_crossentropy: 0.2174\n",
      "Epoch 144/250\n",
      "Epoch 00144: categorical_crossentropy improved from 0.22276 to 0.22272, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2227 - categorical_crossentropy: 0.2227 - val_loss: 0.2172 - val_categorical_crossentropy: 0.2172\n",
      "Epoch 145/250\n",
      "Epoch 00145: categorical_crossentropy improved from 0.22272 to 0.22271, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2227 - categorical_crossentropy: 0.2227 - val_loss: 0.2170 - val_categorical_crossentropy: 0.2170\n",
      "Epoch 146/250\n",
      "Epoch 00146: categorical_crossentropy improved from 0.22271 to 0.22268, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2227 - categorical_crossentropy: 0.2227 - val_loss: 0.2168 - val_categorical_crossentropy: 0.2168\n",
      "Epoch 147/250\n",
      "Epoch 00147: categorical_crossentropy improved from 0.22268 to 0.22261, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2226 - categorical_crossentropy: 0.2226 - val_loss: 0.2169 - val_categorical_crossentropy: 0.2169\n",
      "Epoch 148/250\n",
      "Epoch 00148: categorical_crossentropy improved from 0.22261 to 0.22260, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2226 - categorical_crossentropy: 0.2226 - val_loss: 0.2180 - val_categorical_crossentropy: 0.2180\n",
      "Epoch 149/250\n",
      "Epoch 00149: categorical_crossentropy improved from 0.22260 to 0.22258, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2226 - categorical_crossentropy: 0.2226 - val_loss: 0.2169 - val_categorical_crossentropy: 0.2169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/250\n",
      "Epoch 00150: categorical_crossentropy improved from 0.22258 to 0.22245, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2224 - categorical_crossentropy: 0.2224 - val_loss: 0.2168 - val_categorical_crossentropy: 0.2168\n",
      "Epoch 151/250\n",
      "Epoch 00151: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2225 - categorical_crossentropy: 0.2225 - val_loss: 0.2166 - val_categorical_crossentropy: 0.2166\n",
      "Epoch 152/250\n",
      "Epoch 00152: categorical_crossentropy improved from 0.22245 to 0.22239, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2224 - categorical_crossentropy: 0.2224 - val_loss: 0.2174 - val_categorical_crossentropy: 0.2174\n",
      "Epoch 153/250\n",
      "Epoch 00153: categorical_crossentropy improved from 0.22239 to 0.22239, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2224 - categorical_crossentropy: 0.2224 - val_loss: 0.2167 - val_categorical_crossentropy: 0.2167\n",
      "Epoch 154/250\n",
      "Epoch 00154: categorical_crossentropy improved from 0.22239 to 0.22234, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2223 - categorical_crossentropy: 0.2223 - val_loss: 0.2169 - val_categorical_crossentropy: 0.2169\n",
      "Epoch 155/250\n",
      "Epoch 00155: categorical_crossentropy improved from 0.22234 to 0.22223, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2222 - categorical_crossentropy: 0.2222 - val_loss: 0.2167 - val_categorical_crossentropy: 0.2167\n",
      "Epoch 156/250\n",
      "Epoch 00156: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2223 - categorical_crossentropy: 0.2223 - val_loss: 0.2165 - val_categorical_crossentropy: 0.2165\n",
      "Epoch 157/250\n",
      "Epoch 00157: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2222 - categorical_crossentropy: 0.2222 - val_loss: 0.2165 - val_categorical_crossentropy: 0.2165\n",
      "Epoch 158/250\n",
      "Epoch 00158: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2224 - categorical_crossentropy: 0.2224 - val_loss: 0.2176 - val_categorical_crossentropy: 0.2176\n",
      "Epoch 159/250\n",
      "Epoch 00159: categorical_crossentropy improved from 0.22223 to 0.22221, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2222 - categorical_crossentropy: 0.2222 - val_loss: 0.2172 - val_categorical_crossentropy: 0.2172\n",
      "Epoch 160/250\n",
      "Epoch 00160: categorical_crossentropy improved from 0.22221 to 0.22214, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2221 - categorical_crossentropy: 0.2221 - val_loss: 0.2164 - val_categorical_crossentropy: 0.2164\n",
      "Epoch 161/250\n",
      "Epoch 00161: categorical_crossentropy improved from 0.22214 to 0.22206, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2221 - categorical_crossentropy: 0.2221 - val_loss: 0.2164 - val_categorical_crossentropy: 0.2164\n",
      "Epoch 162/250\n",
      "Epoch 00162: categorical_crossentropy improved from 0.22206 to 0.22200, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2220 - categorical_crossentropy: 0.2220 - val_loss: 0.2165 - val_categorical_crossentropy: 0.2165\n",
      "Epoch 163/250\n",
      "Epoch 00163: categorical_crossentropy improved from 0.22200 to 0.22197, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2220 - categorical_crossentropy: 0.2220 - val_loss: 0.2168 - val_categorical_crossentropy: 0.2168\n",
      "Epoch 164/250\n",
      "Epoch 00164: categorical_crossentropy improved from 0.22197 to 0.22191, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2219 - categorical_crossentropy: 0.2219 - val_loss: 0.2163 - val_categorical_crossentropy: 0.2163\n",
      "Epoch 165/250\n",
      "Epoch 00165: categorical_crossentropy improved from 0.22191 to 0.22183, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2218 - categorical_crossentropy: 0.2218 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 166/250\n",
      "Epoch 00166: categorical_crossentropy improved from 0.22183 to 0.22183, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2218 - categorical_crossentropy: 0.2218 - val_loss: 0.2164 - val_categorical_crossentropy: 0.2164\n",
      "Epoch 167/250\n",
      "Epoch 00167: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2219 - categorical_crossentropy: 0.2219 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 168/250\n",
      "Epoch 00168: categorical_crossentropy improved from 0.22183 to 0.22171, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2217 - categorical_crossentropy: 0.2217 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 169/250\n",
      "Epoch 00169: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2218 - categorical_crossentropy: 0.2218 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 170/250\n",
      "Epoch 00170: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2218 - categorical_crossentropy: 0.2218 - val_loss: 0.2162 - val_categorical_crossentropy: 0.2162\n",
      "Epoch 171/250\n",
      "Epoch 00171: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2218 - categorical_crossentropy: 0.2218 - val_loss: 0.2160 - val_categorical_crossentropy: 0.2160\n",
      "Epoch 172/250\n",
      "Epoch 00172: categorical_crossentropy improved from 0.22171 to 0.22166, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2217 - categorical_crossentropy: 0.2217 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 173/250\n",
      "Epoch 00173: categorical_crossentropy improved from 0.22166 to 0.22158, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2216 - categorical_crossentropy: 0.2216 - val_loss: 0.2160 - val_categorical_crossentropy: 0.2160\n",
      "Epoch 174/250\n",
      "Epoch 00174: categorical_crossentropy improved from 0.22158 to 0.22156, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2216 - categorical_crossentropy: 0.2216 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 175/250\n",
      "Epoch 00175: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2216 - categorical_crossentropy: 0.2216 - val_loss: 0.2161 - val_categorical_crossentropy: 0.2161\n",
      "Epoch 176/250\n",
      "Epoch 00176: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2216 - categorical_crossentropy: 0.2216 - val_loss: 0.2160 - val_categorical_crossentropy: 0.2160\n",
      "Epoch 177/250\n",
      "Epoch 00177: categorical_crossentropy improved from 0.22156 to 0.22152, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2215 - categorical_crossentropy: 0.2215 - val_loss: 0.2159 - val_categorical_crossentropy: 0.2159\n",
      "Epoch 178/250\n",
      "Epoch 00178: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2216 - categorical_crossentropy: 0.2216 - val_loss: 0.2159 - val_categorical_crossentropy: 0.2159\n",
      "Epoch 179/250\n",
      "Epoch 00179: categorical_crossentropy improved from 0.22152 to 0.22143, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2214 - categorical_crossentropy: 0.2214 - val_loss: 0.2163 - val_categorical_crossentropy: 0.2163\n",
      "Epoch 180/250\n",
      "Epoch 00180: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2214 - categorical_crossentropy: 0.2214 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 181/250\n",
      "Epoch 00181: categorical_crossentropy improved from 0.22143 to 0.22131, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2213 - categorical_crossentropy: 0.2213 - val_loss: 0.2159 - val_categorical_crossentropy: 0.2159\n",
      "Epoch 182/250\n",
      "Epoch 00182: categorical_crossentropy improved from 0.22131 to 0.22129, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2213 - categorical_crossentropy: 0.2213 - val_loss: 0.2157 - val_categorical_crossentropy: 0.2157\n",
      "Epoch 183/250\n",
      "Epoch 00183: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2213 - categorical_crossentropy: 0.2213 - val_loss: 0.2159 - val_categorical_crossentropy: 0.2159\n",
      "Epoch 184/250\n",
      "Epoch 00184: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2214 - categorical_crossentropy: 0.2214 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 185/250\n",
      "Epoch 00185: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2214 - categorical_crossentropy: 0.2214 - val_loss: 0.2160 - val_categorical_crossentropy: 0.2160\n",
      "Epoch 186/250\n",
      "Epoch 00186: categorical_crossentropy improved from 0.22129 to 0.22124, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2212 - categorical_crossentropy: 0.2212 - val_loss: 0.2157 - val_categorical_crossentropy: 0.2157\n",
      "Epoch 187/250\n",
      "Epoch 00187: categorical_crossentropy improved from 0.22124 to 0.22116, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2212 - categorical_crossentropy: 0.2212 - val_loss: 0.2156 - val_categorical_crossentropy: 0.2156\n",
      "Epoch 188/250\n",
      "Epoch 00188: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2212 - categorical_crossentropy: 0.2212 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/250\n",
      "Epoch 00189: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2213 - categorical_crossentropy: 0.2213 - val_loss: 0.2156 - val_categorical_crossentropy: 0.2156\n",
      "Epoch 190/250\n",
      "Epoch 00190: categorical_crossentropy improved from 0.22116 to 0.22101, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2210 - categorical_crossentropy: 0.2210 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 191/250\n",
      "Epoch 00191: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2211 - categorical_crossentropy: 0.2211 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 192/250\n",
      "Epoch 00192: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2210 - categorical_crossentropy: 0.2210 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 193/250\n",
      "Epoch 00193: categorical_crossentropy improved from 0.22101 to 0.22092, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2209 - categorical_crossentropy: 0.2209 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 194/250\n",
      "Epoch 00194: categorical_crossentropy improved from 0.22092 to 0.22090, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2209 - categorical_crossentropy: 0.2209 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 195/250\n",
      "Epoch 00195: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2210 - categorical_crossentropy: 0.2210 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 196/250\n",
      "Epoch 00196: categorical_crossentropy improved from 0.22090 to 0.22082, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 197/250\n",
      "Epoch 00197: categorical_crossentropy improved from 0.22082 to 0.22076, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 198/250\n",
      "Epoch 00198: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 199/250\n",
      "Epoch 00199: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2209 - categorical_crossentropy: 0.2209 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 200/250\n",
      "Epoch 00200: categorical_crossentropy improved from 0.22076 to 0.22075, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 201/250\n",
      "Epoch 00201: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2209 - categorical_crossentropy: 0.2209 - val_loss: 0.2156 - val_categorical_crossentropy: 0.2156\n",
      "Epoch 202/250\n",
      "Epoch 00202: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2153 - val_categorical_crossentropy: 0.2153\n",
      "Epoch 203/250\n",
      "Epoch 00203: categorical_crossentropy improved from 0.22075 to 0.22066, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2207 - categorical_crossentropy: 0.2207 - val_loss: 0.2152 - val_categorical_crossentropy: 0.2152\n",
      "Epoch 204/250\n",
      "Epoch 00204: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2207 - categorical_crossentropy: 0.2207 - val_loss: 0.2156 - val_categorical_crossentropy: 0.2156\n",
      "Epoch 205/250\n",
      "Epoch 00205: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2157 - val_categorical_crossentropy: 0.2157\n",
      "Epoch 206/250\n",
      "Epoch 00206: categorical_crossentropy improved from 0.22066 to 0.22056, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2206 - categorical_crossentropy: 0.2206 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 207/250\n",
      "Epoch 00207: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2207 - categorical_crossentropy: 0.2207 - val_loss: 0.2150 - val_categorical_crossentropy: 0.2150\n",
      "Epoch 208/250\n",
      "Epoch 00208: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2206 - categorical_crossentropy: 0.2206 - val_loss: 0.2150 - val_categorical_crossentropy: 0.2150\n",
      "Epoch 209/250\n",
      "Epoch 00209: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2206 - categorical_crossentropy: 0.2206 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 210/250\n",
      "Epoch 00210: categorical_crossentropy improved from 0.22056 to 0.22041, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 211/250\n",
      "Epoch 00211: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2205 - categorical_crossentropy: 0.2205 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 212/250\n",
      "Epoch 00212: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2206 - categorical_crossentropy: 0.2206 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 213/250\n",
      "Epoch 00213: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2205 - categorical_crossentropy: 0.2205 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 214/250\n",
      "Epoch 00214: categorical_crossentropy improved from 0.22041 to 0.22040, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 215/250\n",
      "Epoch 00215: categorical_crossentropy improved from 0.22040 to 0.22036, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2156 - val_categorical_crossentropy: 0.2156\n",
      "Epoch 216/250\n",
      "Epoch 00216: categorical_crossentropy improved from 0.22036 to 0.22036, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 217/250\n",
      "Epoch 00217: categorical_crossentropy improved from 0.22036 to 0.22025, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 218/250\n",
      "Epoch 00218: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2205 - categorical_crossentropy: 0.2205 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 219/250\n",
      "Epoch 00219: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2203 - categorical_crossentropy: 0.2203 - val_loss: 0.2152 - val_categorical_crossentropy: 0.2152\n",
      "Epoch 220/250\n",
      "Epoch 00220: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2203 - categorical_crossentropy: 0.2203 - val_loss: 0.2152 - val_categorical_crossentropy: 0.2152\n",
      "Epoch 221/250\n",
      "Epoch 00221: categorical_crossentropy improved from 0.22025 to 0.22024, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 222/250\n",
      "Epoch 00222: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 223/250\n",
      "Epoch 00223: categorical_crossentropy improved from 0.22024 to 0.22020, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 224/250\n",
      "Epoch 00224: categorical_crossentropy improved from 0.22020 to 0.22014, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 225/250\n",
      "Epoch 00225: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 226/250\n",
      "Epoch 00226: categorical_crossentropy improved from 0.22014 to 0.22011, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 227/250\n",
      "Epoch 00227: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 228/250\n",
      "Epoch 00228: categorical_crossentropy improved from 0.22011 to 0.22004, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 229/250\n",
      "Epoch 00229: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/250\n",
      "Epoch 00230: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2147 - val_categorical_crossentropy: 0.2147\n",
      "Epoch 231/250\n",
      "Epoch 00231: categorical_crossentropy improved from 0.22004 to 0.21998, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 232/250\n",
      "Epoch 00232: categorical_crossentropy improved from 0.21998 to 0.21996, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 233/250\n",
      "Epoch 00233: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 234/250\n",
      "Epoch 00234: categorical_crossentropy improved from 0.21996 to 0.21991, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 235/250\n",
      "Epoch 00235: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 236/250\n",
      "Epoch 00236: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 237/250\n",
      "Epoch 00237: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 238/250\n",
      "Epoch 00238: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2147 - val_categorical_crossentropy: 0.2147\n",
      "Epoch 239/250\n",
      "Epoch 00239: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2145 - val_categorical_crossentropy: 0.2145\n",
      "Epoch 240/250\n",
      "Epoch 00240: categorical_crossentropy improved from 0.21991 to 0.21987, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 241/250\n",
      "Epoch 00241: categorical_crossentropy improved from 0.21987 to 0.21977, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2145 - val_categorical_crossentropy: 0.2145\n",
      "Epoch 242/250\n",
      "Epoch 00242: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2143 - val_categorical_crossentropy: 0.2143\n",
      "Epoch 243/250\n",
      "Epoch 00243: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 244/250\n",
      "Epoch 00244: categorical_crossentropy improved from 0.21977 to 0.21976, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 245/250\n",
      "Epoch 00245: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 246/250\n",
      "Epoch 00246: categorical_crossentropy improved from 0.21976 to 0.21965, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 247/250\n",
      "Epoch 00247: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2197 - categorical_crossentropy: 0.2197 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 248/250\n",
      "Epoch 00248: categorical_crossentropy improved from 0.21965 to 0.21964, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 249/250\n",
      "Epoch 00249: categorical_crossentropy improved from 0.21964 to 0.21956, saving model to srnn_simple.h5\n",
      " - 0s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 250/250\n",
      "Epoch 00250: categorical_crossentropy did not improve\n",
      " - 0s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 36, 7)             105       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 36, 7)             56        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None Training time : 99.2117395401001s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history2 = model2.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    callbacks = [checkpoint, early])\n",
    "stop = time.time()\n",
    "t2 = stop-start\n",
    "print(model2.summary(), end=\" \")\n",
    "print(\"Training time : {}s\".format(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SRNN_steps = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "Finally, we can train a <b>GRU</b> (<b>G</b>ated <b>R</b>ecurrent <b>U</b>nits). It's a simplification of LSTMs. They also have a memory mechanism but with less parameters. As a result they are faster to train. You can find differences on <a href=\"https://datascience.stackexchange.com/questions/14581/what-is-difference-between-gru-and-lstm\" target=\"_blank\">this topic</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(GRU(units=nb_unit, input_shape=inp_shape, return_sequences=True))\n",
    "model3.add(Dense(7, activation='softmax'))\n",
    "model3.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"gru_simple.h5\",\n",
    "    monitor=loss_,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 256 samples\n",
      "Epoch 1/250\n",
      "Epoch 00001: categorical_crossentropy improved from inf to 0.88138, saving model to gru_simple.h5\n",
      " - 2s - loss: 0.8814 - categorical_crossentropy: 0.8814 - val_loss: 0.8391 - val_categorical_crossentropy: 0.8391\n",
      "Epoch 2/250\n",
      "Epoch 00002: categorical_crossentropy improved from 0.88138 to 0.82684, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.8268 - categorical_crossentropy: 0.8268 - val_loss: 0.7851 - val_categorical_crossentropy: 0.7851\n",
      "Epoch 3/250\n",
      "Epoch 00003: categorical_crossentropy improved from 0.82684 to 0.76929, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.7693 - categorical_crossentropy: 0.7693 - val_loss: 0.7266 - val_categorical_crossentropy: 0.7266\n",
      "Epoch 4/250\n",
      "Epoch 00004: categorical_crossentropy improved from 0.76929 to 0.71084, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.7108 - categorical_crossentropy: 0.7108 - val_loss: 0.6697 - val_categorical_crossentropy: 0.6697\n",
      "Epoch 5/250\n",
      "Epoch 00005: categorical_crossentropy improved from 0.71084 to 0.64981, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.6498 - categorical_crossentropy: 0.6498 - val_loss: 0.6044 - val_categorical_crossentropy: 0.6044\n",
      "Epoch 6/250\n",
      "Epoch 00006: categorical_crossentropy improved from 0.64981 to 0.57846, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.5785 - categorical_crossentropy: 0.5785 - val_loss: 0.5332 - val_categorical_crossentropy: 0.5332\n",
      "Epoch 7/250\n",
      "Epoch 00007: categorical_crossentropy improved from 0.57846 to 0.51060, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.5106 - categorical_crossentropy: 0.5106 - val_loss: 0.4741 - val_categorical_crossentropy: 0.4741\n",
      "Epoch 8/250\n",
      "Epoch 00008: categorical_crossentropy improved from 0.51060 to 0.45832, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4583 - categorical_crossentropy: 0.4583 - val_loss: 0.4300 - val_categorical_crossentropy: 0.4300\n",
      "Epoch 9/250\n",
      "Epoch 00009: categorical_crossentropy improved from 0.45832 to 0.41880, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4188 - categorical_crossentropy: 0.4188 - val_loss: 0.3966 - val_categorical_crossentropy: 0.3966\n",
      "Epoch 10/250\n",
      "Epoch 00010: categorical_crossentropy improved from 0.41880 to 0.38824, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3882 - categorical_crossentropy: 0.3882 - val_loss: 0.3687 - val_categorical_crossentropy: 0.3687\n",
      "Epoch 11/250\n",
      "Epoch 00011: categorical_crossentropy improved from 0.38824 to 0.36241, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3624 - categorical_crossentropy: 0.3624 - val_loss: 0.3454 - val_categorical_crossentropy: 0.3454\n",
      "Epoch 12/250\n",
      "Epoch 00012: categorical_crossentropy improved from 0.36241 to 0.34014, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3401 - categorical_crossentropy: 0.3401 - val_loss: 0.3252 - val_categorical_crossentropy: 0.3252\n",
      "Epoch 13/250\n",
      "Epoch 00013: categorical_crossentropy improved from 0.34014 to 0.32166, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3217 - categorical_crossentropy: 0.3217 - val_loss: 0.3084 - val_categorical_crossentropy: 0.3084\n",
      "Epoch 14/250\n",
      "Epoch 00014: categorical_crossentropy improved from 0.32166 to 0.30715, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3072 - categorical_crossentropy: 0.3072 - val_loss: 0.2956 - val_categorical_crossentropy: 0.2956\n",
      "Epoch 15/250\n",
      "Epoch 00015: categorical_crossentropy improved from 0.30715 to 0.29566, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2957 - categorical_crossentropy: 0.2957 - val_loss: 0.2855 - val_categorical_crossentropy: 0.2855\n",
      "Epoch 16/250\n",
      "Epoch 00016: categorical_crossentropy improved from 0.29566 to 0.28650, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2865 - categorical_crossentropy: 0.2865 - val_loss: 0.2776 - val_categorical_crossentropy: 0.2776\n",
      "Epoch 17/250\n",
      "Epoch 00017: categorical_crossentropy improved from 0.28650 to 0.27904, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2790 - categorical_crossentropy: 0.2790 - val_loss: 0.2706 - val_categorical_crossentropy: 0.2706\n",
      "Epoch 18/250\n",
      "Epoch 00018: categorical_crossentropy improved from 0.27904 to 0.27274, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2727 - categorical_crossentropy: 0.2727 - val_loss: 0.2651 - val_categorical_crossentropy: 0.2651\n",
      "Epoch 19/250\n",
      "Epoch 00019: categorical_crossentropy improved from 0.27274 to 0.26738, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2674 - categorical_crossentropy: 0.2674 - val_loss: 0.2600 - val_categorical_crossentropy: 0.2600\n",
      "Epoch 20/250\n",
      "Epoch 00020: categorical_crossentropy improved from 0.26738 to 0.26266, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2627 - categorical_crossentropy: 0.2627 - val_loss: 0.2561 - val_categorical_crossentropy: 0.2561\n",
      "Epoch 21/250\n",
      "Epoch 00021: categorical_crossentropy improved from 0.26266 to 0.25854, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2585 - categorical_crossentropy: 0.2585 - val_loss: 0.2522 - val_categorical_crossentropy: 0.2522\n",
      "Epoch 22/250\n",
      "Epoch 00022: categorical_crossentropy improved from 0.25854 to 0.25488, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2549 - categorical_crossentropy: 0.2549 - val_loss: 0.2488 - val_categorical_crossentropy: 0.2488\n",
      "Epoch 23/250\n",
      "Epoch 00023: categorical_crossentropy improved from 0.25488 to 0.25175, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2517 - categorical_crossentropy: 0.2517 - val_loss: 0.2456 - val_categorical_crossentropy: 0.2456\n",
      "Epoch 24/250\n",
      "Epoch 00024: categorical_crossentropy improved from 0.25175 to 0.24906, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2491 - categorical_crossentropy: 0.2491 - val_loss: 0.2432 - val_categorical_crossentropy: 0.2432\n",
      "Epoch 25/250\n",
      "Epoch 00025: categorical_crossentropy improved from 0.24906 to 0.24663, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2466 - categorical_crossentropy: 0.2466 - val_loss: 0.2411 - val_categorical_crossentropy: 0.2411\n",
      "Epoch 26/250\n",
      "Epoch 00026: categorical_crossentropy improved from 0.24663 to 0.24458, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2446 - categorical_crossentropy: 0.2446 - val_loss: 0.2395 - val_categorical_crossentropy: 0.2395\n",
      "Epoch 27/250\n",
      "Epoch 00027: categorical_crossentropy improved from 0.24458 to 0.24268, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2427 - categorical_crossentropy: 0.2427 - val_loss: 0.2375 - val_categorical_crossentropy: 0.2375\n",
      "Epoch 28/250\n",
      "Epoch 00028: categorical_crossentropy improved from 0.24268 to 0.24106, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2411 - categorical_crossentropy: 0.2411 - val_loss: 0.2357 - val_categorical_crossentropy: 0.2357\n",
      "Epoch 29/250\n",
      "Epoch 00029: categorical_crossentropy improved from 0.24106 to 0.23955, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2395 - categorical_crossentropy: 0.2395 - val_loss: 0.2340 - val_categorical_crossentropy: 0.2340\n",
      "Epoch 30/250\n",
      "Epoch 00030: categorical_crossentropy improved from 0.23955 to 0.23812, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2381 - categorical_crossentropy: 0.2381 - val_loss: 0.2327 - val_categorical_crossentropy: 0.2327\n",
      "Epoch 31/250\n",
      "Epoch 00031: categorical_crossentropy improved from 0.23812 to 0.23681, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2368 - categorical_crossentropy: 0.2368 - val_loss: 0.2314 - val_categorical_crossentropy: 0.2314\n",
      "Epoch 32/250\n",
      "Epoch 00032: categorical_crossentropy improved from 0.23681 to 0.23562, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2356 - categorical_crossentropy: 0.2356 - val_loss: 0.2304 - val_categorical_crossentropy: 0.2304\n",
      "Epoch 33/250\n",
      "Epoch 00033: categorical_crossentropy improved from 0.23562 to 0.23454, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2345 - categorical_crossentropy: 0.2345 - val_loss: 0.2295 - val_categorical_crossentropy: 0.2295\n",
      "Epoch 34/250\n",
      "Epoch 00034: categorical_crossentropy improved from 0.23454 to 0.23356, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2336 - categorical_crossentropy: 0.2336 - val_loss: 0.2283 - val_categorical_crossentropy: 0.2283\n",
      "Epoch 35/250\n",
      "Epoch 00035: categorical_crossentropy improved from 0.23356 to 0.23257, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2326 - categorical_crossentropy: 0.2326 - val_loss: 0.2272 - val_categorical_crossentropy: 0.2272\n",
      "Epoch 36/250\n",
      "Epoch 00036: categorical_crossentropy improved from 0.23257 to 0.23193, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2319 - categorical_crossentropy: 0.2319 - val_loss: 0.2266 - val_categorical_crossentropy: 0.2266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "Epoch 00037: categorical_crossentropy improved from 0.23193 to 0.23124, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2312 - categorical_crossentropy: 0.2312 - val_loss: 0.2256 - val_categorical_crossentropy: 0.2256\n",
      "Epoch 38/250\n",
      "Epoch 00038: categorical_crossentropy improved from 0.23124 to 0.23053, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2305 - categorical_crossentropy: 0.2305 - val_loss: 0.2249 - val_categorical_crossentropy: 0.2249\n",
      "Epoch 39/250\n",
      "Epoch 00039: categorical_crossentropy improved from 0.23053 to 0.22994, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2299 - categorical_crossentropy: 0.2299 - val_loss: 0.2242 - val_categorical_crossentropy: 0.2242\n",
      "Epoch 40/250\n",
      "Epoch 00040: categorical_crossentropy improved from 0.22994 to 0.22936, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2294 - categorical_crossentropy: 0.2294 - val_loss: 0.2244 - val_categorical_crossentropy: 0.2244\n",
      "Epoch 41/250\n",
      "Epoch 00041: categorical_crossentropy improved from 0.22936 to 0.22895, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2289 - categorical_crossentropy: 0.2289 - val_loss: 0.2235 - val_categorical_crossentropy: 0.2235\n",
      "Epoch 42/250\n",
      "Epoch 00042: categorical_crossentropy improved from 0.22895 to 0.22838, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2284 - categorical_crossentropy: 0.2284 - val_loss: 0.2226 - val_categorical_crossentropy: 0.2226\n",
      "Epoch 43/250\n",
      "Epoch 00043: categorical_crossentropy improved from 0.22838 to 0.22795, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2280 - categorical_crossentropy: 0.2280 - val_loss: 0.2225 - val_categorical_crossentropy: 0.2225\n",
      "Epoch 44/250\n",
      "Epoch 00044: categorical_crossentropy improved from 0.22795 to 0.22763, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2276 - categorical_crossentropy: 0.2276 - val_loss: 0.2226 - val_categorical_crossentropy: 0.2226\n",
      "Epoch 45/250\n",
      "Epoch 00045: categorical_crossentropy improved from 0.22763 to 0.22716, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2272 - categorical_crossentropy: 0.2272 - val_loss: 0.2221 - val_categorical_crossentropy: 0.2221\n",
      "Epoch 46/250\n",
      "Epoch 00046: categorical_crossentropy improved from 0.22716 to 0.22689, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2269 - categorical_crossentropy: 0.2269 - val_loss: 0.2213 - val_categorical_crossentropy: 0.2213\n",
      "Epoch 47/250\n",
      "Epoch 00047: categorical_crossentropy improved from 0.22689 to 0.22653, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2265 - categorical_crossentropy: 0.2265 - val_loss: 0.2210 - val_categorical_crossentropy: 0.2210\n",
      "Epoch 48/250\n",
      "Epoch 00048: categorical_crossentropy improved from 0.22653 to 0.22622, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2262 - categorical_crossentropy: 0.2262 - val_loss: 0.2206 - val_categorical_crossentropy: 0.2206\n",
      "Epoch 49/250\n",
      "Epoch 00049: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2264 - categorical_crossentropy: 0.2264 - val_loss: 0.2207 - val_categorical_crossentropy: 0.2207\n",
      "Epoch 50/250\n",
      "Epoch 00050: categorical_crossentropy improved from 0.22622 to 0.22574, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2257 - categorical_crossentropy: 0.2257 - val_loss: 0.2204 - val_categorical_crossentropy: 0.2204\n",
      "Epoch 51/250\n",
      "Epoch 00051: categorical_crossentropy improved from 0.22574 to 0.22535, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2253 - categorical_crossentropy: 0.2253 - val_loss: 0.2201 - val_categorical_crossentropy: 0.2201\n",
      "Epoch 52/250\n",
      "Epoch 00052: categorical_crossentropy improved from 0.22535 to 0.22518, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2252 - categorical_crossentropy: 0.2252 - val_loss: 0.2198 - val_categorical_crossentropy: 0.2198\n",
      "Epoch 53/250\n",
      "Epoch 00053: categorical_crossentropy improved from 0.22518 to 0.22502, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2250 - categorical_crossentropy: 0.2250 - val_loss: 0.2193 - val_categorical_crossentropy: 0.2193\n",
      "Epoch 54/250\n",
      "Epoch 00054: categorical_crossentropy improved from 0.22502 to 0.22460, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2246 - categorical_crossentropy: 0.2246 - val_loss: 0.2193 - val_categorical_crossentropy: 0.2193\n",
      "Epoch 55/250\n",
      "Epoch 00055: categorical_crossentropy improved from 0.22460 to 0.22455, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2245 - categorical_crossentropy: 0.2245 - val_loss: 0.2189 - val_categorical_crossentropy: 0.2189\n",
      "Epoch 56/250\n",
      "Epoch 00056: categorical_crossentropy improved from 0.22455 to 0.22422, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2242 - categorical_crossentropy: 0.2242 - val_loss: 0.2189 - val_categorical_crossentropy: 0.2189\n",
      "Epoch 57/250\n",
      "Epoch 00057: categorical_crossentropy improved from 0.22422 to 0.22407, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2241 - categorical_crossentropy: 0.2241 - val_loss: 0.2188 - val_categorical_crossentropy: 0.2188\n",
      "Epoch 58/250\n",
      "Epoch 00058: categorical_crossentropy improved from 0.22407 to 0.22390, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2239 - categorical_crossentropy: 0.2239 - val_loss: 0.2185 - val_categorical_crossentropy: 0.2185\n",
      "Epoch 59/250\n",
      "Epoch 00059: categorical_crossentropy improved from 0.22390 to 0.22372, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2237 - categorical_crossentropy: 0.2237 - val_loss: 0.2182 - val_categorical_crossentropy: 0.2182\n",
      "Epoch 60/250\n",
      "Epoch 00060: categorical_crossentropy improved from 0.22372 to 0.22363, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2236 - categorical_crossentropy: 0.2236 - val_loss: 0.2182 - val_categorical_crossentropy: 0.2182\n",
      "Epoch 61/250\n",
      "Epoch 00061: categorical_crossentropy improved from 0.22363 to 0.22341, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2234 - categorical_crossentropy: 0.2234 - val_loss: 0.2179 - val_categorical_crossentropy: 0.2179\n",
      "Epoch 62/250\n",
      "Epoch 00062: categorical_crossentropy improved from 0.22341 to 0.22321, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2232 - categorical_crossentropy: 0.2232 - val_loss: 0.2185 - val_categorical_crossentropy: 0.2185\n",
      "Epoch 63/250\n",
      "Epoch 00063: categorical_crossentropy improved from 0.22321 to 0.22313, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2231 - categorical_crossentropy: 0.2231 - val_loss: 0.2180 - val_categorical_crossentropy: 0.2180\n",
      "Epoch 64/250\n",
      "Epoch 00064: categorical_crossentropy improved from 0.22313 to 0.22294, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2229 - categorical_crossentropy: 0.2229 - val_loss: 0.2176 - val_categorical_crossentropy: 0.2176\n",
      "Epoch 65/250\n",
      "Epoch 00065: categorical_crossentropy improved from 0.22294 to 0.22278, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2228 - categorical_crossentropy: 0.2228 - val_loss: 0.2188 - val_categorical_crossentropy: 0.2188\n",
      "Epoch 66/250\n",
      "Epoch 00066: categorical_crossentropy improved from 0.22278 to 0.22274, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2227 - categorical_crossentropy: 0.2227 - val_loss: 0.2173 - val_categorical_crossentropy: 0.2173\n",
      "Epoch 67/250\n",
      "Epoch 00067: categorical_crossentropy improved from 0.22274 to 0.22251, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2225 - categorical_crossentropy: 0.2225 - val_loss: 0.2170 - val_categorical_crossentropy: 0.2170\n",
      "Epoch 68/250\n",
      "Epoch 00068: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2225 - categorical_crossentropy: 0.2225 - val_loss: 0.2170 - val_categorical_crossentropy: 0.2170\n",
      "Epoch 69/250\n",
      "Epoch 00069: categorical_crossentropy improved from 0.22251 to 0.22231, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2223 - categorical_crossentropy: 0.2223 - val_loss: 0.2169 - val_categorical_crossentropy: 0.2169\n",
      "Epoch 70/250\n",
      "Epoch 00070: categorical_crossentropy improved from 0.22231 to 0.22231, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2223 - categorical_crossentropy: 0.2223 - val_loss: 0.2167 - val_categorical_crossentropy: 0.2167\n",
      "Epoch 71/250\n",
      "Epoch 00071: categorical_crossentropy improved from 0.22231 to 0.22211, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2221 - categorical_crossentropy: 0.2221 - val_loss: 0.2169 - val_categorical_crossentropy: 0.2169\n",
      "Epoch 72/250\n",
      "Epoch 00072: categorical_crossentropy improved from 0.22211 to 0.22199, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2220 - categorical_crossentropy: 0.2220 - val_loss: 0.2175 - val_categorical_crossentropy: 0.2175\n",
      "Epoch 73/250\n",
      "Epoch 00073: categorical_crossentropy improved from 0.22199 to 0.22197, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2220 - categorical_crossentropy: 0.2220 - val_loss: 0.2170 - val_categorical_crossentropy: 0.2170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/250\n",
      "Epoch 00074: categorical_crossentropy improved from 0.22197 to 0.22193, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2219 - categorical_crossentropy: 0.2219 - val_loss: 0.2166 - val_categorical_crossentropy: 0.2166\n",
      "Epoch 75/250\n",
      "Epoch 00075: categorical_crossentropy improved from 0.22193 to 0.22173, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2217 - categorical_crossentropy: 0.2217 - val_loss: 0.2163 - val_categorical_crossentropy: 0.2163\n",
      "Epoch 76/250\n",
      "Epoch 00076: categorical_crossentropy improved from 0.22173 to 0.22166, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2217 - categorical_crossentropy: 0.2217 - val_loss: 0.2162 - val_categorical_crossentropy: 0.2162\n",
      "Epoch 77/250\n",
      "Epoch 00077: categorical_crossentropy improved from 0.22166 to 0.22164, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2216 - categorical_crossentropy: 0.2216 - val_loss: 0.2163 - val_categorical_crossentropy: 0.2163\n",
      "Epoch 78/250\n",
      "Epoch 00078: categorical_crossentropy improved from 0.22164 to 0.22148, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2215 - categorical_crossentropy: 0.2215 - val_loss: 0.2159 - val_categorical_crossentropy: 0.2159\n",
      "Epoch 79/250\n",
      "Epoch 00079: categorical_crossentropy improved from 0.22148 to 0.22148, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2215 - categorical_crossentropy: 0.2215 - val_loss: 0.2160 - val_categorical_crossentropy: 0.2160\n",
      "Epoch 80/250\n",
      "Epoch 00080: categorical_crossentropy improved from 0.22148 to 0.22136, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2214 - categorical_crossentropy: 0.2214 - val_loss: 0.2156 - val_categorical_crossentropy: 0.2156\n",
      "Epoch 81/250\n",
      "Epoch 00081: categorical_crossentropy improved from 0.22136 to 0.22109, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2211 - categorical_crossentropy: 0.2211 - val_loss: 0.2158 - val_categorical_crossentropy: 0.2158\n",
      "Epoch 82/250\n",
      "Epoch 00082: categorical_crossentropy improved from 0.22109 to 0.22109, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2211 - categorical_crossentropy: 0.2211 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 83/250\n",
      "Epoch 00083: categorical_crossentropy improved from 0.22109 to 0.22105, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2210 - categorical_crossentropy: 0.2210 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 84/250\n",
      "Epoch 00084: categorical_crossentropy improved from 0.22105 to 0.22089, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2209 - categorical_crossentropy: 0.2209 - val_loss: 0.2156 - val_categorical_crossentropy: 0.2156\n",
      "Epoch 85/250\n",
      "Epoch 00085: categorical_crossentropy improved from 0.22089 to 0.22085, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2209 - categorical_crossentropy: 0.2209 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 86/250\n",
      "Epoch 00086: categorical_crossentropy improved from 0.22085 to 0.22083, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 87/250\n",
      "Epoch 00087: categorical_crossentropy improved from 0.22083 to 0.22073, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2207 - categorical_crossentropy: 0.2207 - val_loss: 0.2162 - val_categorical_crossentropy: 0.2162\n",
      "Epoch 88/250\n",
      "Epoch 00088: categorical_crossentropy improved from 0.22073 to 0.22060, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2206 - categorical_crossentropy: 0.2206 - val_loss: 0.2172 - val_categorical_crossentropy: 0.2172\n",
      "Epoch 89/250\n",
      "Epoch 00089: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2208 - categorical_crossentropy: 0.2208 - val_loss: 0.2154 - val_categorical_crossentropy: 0.2154\n",
      "Epoch 90/250\n",
      "Epoch 00090: categorical_crossentropy improved from 0.22060 to 0.22046, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2205 - categorical_crossentropy: 0.2205 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 91/250\n",
      "Epoch 00091: categorical_crossentropy improved from 0.22046 to 0.22045, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2204 - categorical_crossentropy: 0.2204 - val_loss: 0.2146 - val_categorical_crossentropy: 0.2146\n",
      "Epoch 92/250\n",
      "Epoch 00092: categorical_crossentropy improved from 0.22045 to 0.22034, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2203 - categorical_crossentropy: 0.2203 - val_loss: 0.2145 - val_categorical_crossentropy: 0.2145\n",
      "Epoch 93/250\n",
      "Epoch 00093: categorical_crossentropy improved from 0.22034 to 0.22019, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2155 - val_categorical_crossentropy: 0.2155\n",
      "Epoch 94/250\n",
      "Epoch 00094: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2203 - categorical_crossentropy: 0.2203 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 95/250\n",
      "Epoch 00095: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2202 - categorical_crossentropy: 0.2202 - val_loss: 0.2144 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 96/250\n",
      "Epoch 00096: categorical_crossentropy improved from 0.22019 to 0.22009, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 97/250\n",
      "Epoch 00097: categorical_crossentropy improved from 0.22009 to 0.22003, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2151 - val_categorical_crossentropy: 0.2151\n",
      "Epoch 98/250\n",
      "Epoch 00098: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2149 - val_categorical_crossentropy: 0.2149\n",
      "Epoch 99/250\n",
      "Epoch 00099: categorical_crossentropy improved from 0.22003 to 0.21999, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 100/250\n",
      "Epoch 00100: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2201 - categorical_crossentropy: 0.2201 - val_loss: 0.2141 - val_categorical_crossentropy: 0.2141\n",
      "Epoch 101/250\n",
      "Epoch 00101: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2200 - categorical_crossentropy: 0.2200 - val_loss: 0.2141 - val_categorical_crossentropy: 0.2141\n",
      "Epoch 102/250\n",
      "Epoch 00102: categorical_crossentropy improved from 0.21999 to 0.21969, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2197 - categorical_crossentropy: 0.2197 - val_loss: 0.2148 - val_categorical_crossentropy: 0.2148\n",
      "Epoch 103/250\n",
      "Epoch 00103: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2198 - categorical_crossentropy: 0.2198 - val_loss: 0.2140 - val_categorical_crossentropy: 0.2140\n",
      "Epoch 104/250\n",
      "Epoch 00104: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2199 - categorical_crossentropy: 0.2199 - val_loss: 0.2137 - val_categorical_crossentropy: 0.2137\n",
      "Epoch 105/250\n",
      "Epoch 00105: categorical_crossentropy improved from 0.21969 to 0.21962, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2140 - val_categorical_crossentropy: 0.2140\n",
      "Epoch 106/250\n",
      "Epoch 00106: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2143 - val_categorical_crossentropy: 0.2143\n",
      "Epoch 107/250\n",
      "Epoch 00107: categorical_crossentropy improved from 0.21962 to 0.21954, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2195 - categorical_crossentropy: 0.2195 - val_loss: 0.2138 - val_categorical_crossentropy: 0.2138\n",
      "Epoch 108/250\n",
      "Epoch 00108: categorical_crossentropy improved from 0.21954 to 0.21948, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2195 - categorical_crossentropy: 0.2195 - val_loss: 0.2134 - val_categorical_crossentropy: 0.2134\n",
      "Epoch 109/250\n",
      "Epoch 00109: categorical_crossentropy improved from 0.21948 to 0.21945, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2194 - categorical_crossentropy: 0.2194 - val_loss: 0.2137 - val_categorical_crossentropy: 0.2137\n",
      "Epoch 110/250\n",
      "Epoch 00110: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2196 - categorical_crossentropy: 0.2196 - val_loss: 0.2134 - val_categorical_crossentropy: 0.2134\n",
      "Epoch 111/250\n",
      "Epoch 00111: categorical_crossentropy improved from 0.21945 to 0.21927, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2193 - categorical_crossentropy: 0.2193 - val_loss: 0.2136 - val_categorical_crossentropy: 0.2136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/250\n",
      "Epoch 00112: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2194 - categorical_crossentropy: 0.2194 - val_loss: 0.2136 - val_categorical_crossentropy: 0.2136\n",
      "Epoch 113/250\n",
      "Epoch 00113: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2193 - categorical_crossentropy: 0.2193 - val_loss: 0.2135 - val_categorical_crossentropy: 0.2135\n",
      "Epoch 114/250\n",
      "Epoch 00114: categorical_crossentropy improved from 0.21927 to 0.21923, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2192 - categorical_crossentropy: 0.2192 - val_loss: 0.2134 - val_categorical_crossentropy: 0.2134\n",
      "Epoch 115/250\n",
      "Epoch 00115: categorical_crossentropy improved from 0.21923 to 0.21914, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2191 - categorical_crossentropy: 0.2191 - val_loss: 0.2136 - val_categorical_crossentropy: 0.2136\n",
      "Epoch 116/250\n",
      "Epoch 00116: categorical_crossentropy improved from 0.21914 to 0.21908, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2191 - categorical_crossentropy: 0.2191 - val_loss: 0.2142 - val_categorical_crossentropy: 0.2142\n",
      "Epoch 117/250\n",
      "Epoch 00117: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2192 - categorical_crossentropy: 0.2192 - val_loss: 0.2133 - val_categorical_crossentropy: 0.2133\n",
      "Epoch 118/250\n",
      "Epoch 00118: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2192 - categorical_crossentropy: 0.2192 - val_loss: 0.2137 - val_categorical_crossentropy: 0.2137\n",
      "Epoch 119/250\n",
      "Epoch 00119: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2191 - categorical_crossentropy: 0.2191 - val_loss: 0.2135 - val_categorical_crossentropy: 0.2135\n",
      "Epoch 120/250\n",
      "Epoch 00120: categorical_crossentropy improved from 0.21908 to 0.21894, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2189 - categorical_crossentropy: 0.2189 - val_loss: 0.2130 - val_categorical_crossentropy: 0.2130\n",
      "Epoch 121/250\n",
      "Epoch 00121: categorical_crossentropy improved from 0.21894 to 0.21889, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2189 - categorical_crossentropy: 0.2189 - val_loss: 0.2128 - val_categorical_crossentropy: 0.2128\n",
      "Epoch 122/250\n",
      "Epoch 00122: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2190 - categorical_crossentropy: 0.2190 - val_loss: 0.2128 - val_categorical_crossentropy: 0.2128\n",
      "Epoch 123/250\n",
      "Epoch 00123: categorical_crossentropy improved from 0.21889 to 0.21881, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2188 - categorical_crossentropy: 0.2188 - val_loss: 0.2126 - val_categorical_crossentropy: 0.2126\n",
      "Epoch 124/250\n",
      "Epoch 00124: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2188 - categorical_crossentropy: 0.2188 - val_loss: 0.2130 - val_categorical_crossentropy: 0.2130\n",
      "Epoch 125/250\n",
      "Epoch 00125: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2188 - categorical_crossentropy: 0.2188 - val_loss: 0.2126 - val_categorical_crossentropy: 0.2126\n",
      "Epoch 126/250\n",
      "Epoch 00126: categorical_crossentropy improved from 0.21881 to 0.21865, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2186 - categorical_crossentropy: 0.2186 - val_loss: 0.2130 - val_categorical_crossentropy: 0.2130\n",
      "Epoch 127/250\n",
      "Epoch 00127: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2187 - categorical_crossentropy: 0.2187 - val_loss: 0.2123 - val_categorical_crossentropy: 0.2123\n",
      "Epoch 128/250\n",
      "Epoch 00128: categorical_crossentropy improved from 0.21865 to 0.21859, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2186 - categorical_crossentropy: 0.2186 - val_loss: 0.2122 - val_categorical_crossentropy: 0.2122\n",
      "Epoch 129/250\n",
      "Epoch 00129: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2186 - categorical_crossentropy: 0.2186 - val_loss: 0.2132 - val_categorical_crossentropy: 0.2132\n",
      "Epoch 130/250\n",
      "Epoch 00130: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2187 - categorical_crossentropy: 0.2187 - val_loss: 0.2133 - val_categorical_crossentropy: 0.2133\n",
      "Epoch 131/250\n",
      "Epoch 00131: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2187 - categorical_crossentropy: 0.2187 - val_loss: 0.2128 - val_categorical_crossentropy: 0.2128\n",
      "Epoch 132/250\n",
      "Epoch 00132: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2186 - categorical_crossentropy: 0.2186 - val_loss: 0.2123 - val_categorical_crossentropy: 0.2123\n",
      "Epoch 133/250\n",
      "Epoch 00133: categorical_crossentropy improved from 0.21859 to 0.21847, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2185 - categorical_crossentropy: 0.2185 - val_loss: 0.2127 - val_categorical_crossentropy: 0.2127\n",
      "Epoch 134/250\n",
      "Epoch 00134: categorical_crossentropy improved from 0.21847 to 0.21847, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2185 - categorical_crossentropy: 0.2185 - val_loss: 0.2123 - val_categorical_crossentropy: 0.2123\n",
      "Epoch 135/250\n",
      "Epoch 00135: categorical_crossentropy improved from 0.21847 to 0.21825, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2182 - categorical_crossentropy: 0.2182 - val_loss: 0.2128 - val_categorical_crossentropy: 0.2128\n",
      "Epoch 136/250\n",
      "Epoch 00136: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2183 - categorical_crossentropy: 0.2183 - val_loss: 0.2121 - val_categorical_crossentropy: 0.2121\n",
      "Epoch 137/250\n",
      "Epoch 00137: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2184 - categorical_crossentropy: 0.2184 - val_loss: 0.2122 - val_categorical_crossentropy: 0.2122\n",
      "Epoch 138/250\n",
      "Epoch 00138: categorical_crossentropy improved from 0.21825 to 0.21821, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2182 - categorical_crossentropy: 0.2182 - val_loss: 0.2124 - val_categorical_crossentropy: 0.2124\n",
      "Epoch 139/250\n",
      "Epoch 00139: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2184 - categorical_crossentropy: 0.2184 - val_loss: 0.2120 - val_categorical_crossentropy: 0.2120\n",
      "Epoch 140/250\n",
      "Epoch 00140: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2184 - categorical_crossentropy: 0.2184 - val_loss: 0.2122 - val_categorical_crossentropy: 0.2122\n",
      "Epoch 141/250\n",
      "Epoch 00141: categorical_crossentropy improved from 0.21821 to 0.21810, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2181 - categorical_crossentropy: 0.2181 - val_loss: 0.2124 - val_categorical_crossentropy: 0.2124\n",
      "Epoch 142/250\n",
      "Epoch 00142: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2183 - categorical_crossentropy: 0.2183 - val_loss: 0.2120 - val_categorical_crossentropy: 0.2120\n",
      "Epoch 143/250\n",
      "Epoch 00143: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2183 - categorical_crossentropy: 0.2183 - val_loss: 0.2122 - val_categorical_crossentropy: 0.2122\n",
      "Epoch 144/250\n",
      "Epoch 00144: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2181 - categorical_crossentropy: 0.2181 - val_loss: 0.2126 - val_categorical_crossentropy: 0.2126\n",
      "Epoch 145/250\n",
      "Epoch 00145: categorical_crossentropy improved from 0.21810 to 0.21804, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2180 - categorical_crossentropy: 0.2180 - val_loss: 0.2124 - val_categorical_crossentropy: 0.2124\n",
      "Epoch 146/250\n",
      "Epoch 00146: categorical_crossentropy improved from 0.21804 to 0.21794, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2179 - categorical_crossentropy: 0.2179 - val_loss: 0.2119 - val_categorical_crossentropy: 0.2119\n",
      "Epoch 147/250\n",
      "Epoch 00147: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2180 - categorical_crossentropy: 0.2180 - val_loss: 0.2120 - val_categorical_crossentropy: 0.2120\n",
      "Epoch 148/250\n",
      "Epoch 00148: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2180 - categorical_crossentropy: 0.2180 - val_loss: 0.2116 - val_categorical_crossentropy: 0.2116\n",
      "Epoch 149/250\n",
      "Epoch 00149: categorical_crossentropy improved from 0.21794 to 0.21792, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2179 - categorical_crossentropy: 0.2179 - val_loss: 0.2121 - val_categorical_crossentropy: 0.2121\n",
      "Epoch 150/250\n",
      "Epoch 00150: categorical_crossentropy improved from 0.21792 to 0.21785, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2179 - categorical_crossentropy: 0.2179 - val_loss: 0.2116 - val_categorical_crossentropy: 0.2116\n",
      "Epoch 151/250\n",
      "Epoch 00151: categorical_crossentropy improved from 0.21785 to 0.21784, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2178 - categorical_crossentropy: 0.2178 - val_loss: 0.2117 - val_categorical_crossentropy: 0.2117\n",
      "Epoch 152/250\n",
      "Epoch 00152: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2179 - categorical_crossentropy: 0.2179 - val_loss: 0.2122 - val_categorical_crossentropy: 0.2122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/250\n",
      "Epoch 00153: categorical_crossentropy improved from 0.21784 to 0.21777, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2178 - categorical_crossentropy: 0.2178 - val_loss: 0.2119 - val_categorical_crossentropy: 0.2119\n",
      "Epoch 154/250\n",
      "Epoch 00154: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2179 - categorical_crossentropy: 0.2179 - val_loss: 0.2120 - val_categorical_crossentropy: 0.2120\n",
      "Epoch 155/250\n",
      "Epoch 00155: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2178 - categorical_crossentropy: 0.2178 - val_loss: 0.2113 - val_categorical_crossentropy: 0.2113\n",
      "Epoch 156/250\n",
      "Epoch 00156: categorical_crossentropy improved from 0.21777 to 0.21774, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2177 - categorical_crossentropy: 0.2177 - val_loss: 0.2119 - val_categorical_crossentropy: 0.2119\n",
      "Epoch 157/250\n",
      "Epoch 00157: categorical_crossentropy improved from 0.21774 to 0.21771, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2177 - categorical_crossentropy: 0.2177 - val_loss: 0.2118 - val_categorical_crossentropy: 0.2118\n",
      "Epoch 158/250\n",
      "Epoch 00158: categorical_crossentropy improved from 0.21771 to 0.21759, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2176 - categorical_crossentropy: 0.2176 - val_loss: 0.2119 - val_categorical_crossentropy: 0.2119\n",
      "Epoch 159/250\n",
      "Epoch 00159: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2176 - categorical_crossentropy: 0.2176 - val_loss: 0.2117 - val_categorical_crossentropy: 0.2117\n",
      "Epoch 160/250\n",
      "Epoch 00160: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2176 - categorical_crossentropy: 0.2176 - val_loss: 0.2111 - val_categorical_crossentropy: 0.2111\n",
      "Epoch 161/250\n",
      "Epoch 00161: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2176 - categorical_crossentropy: 0.2176 - val_loss: 0.2115 - val_categorical_crossentropy: 0.2115\n",
      "Epoch 162/250\n",
      "Epoch 00162: categorical_crossentropy improved from 0.21759 to 0.21748, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2175 - categorical_crossentropy: 0.2175 - val_loss: 0.2121 - val_categorical_crossentropy: 0.2121\n",
      "Epoch 163/250\n",
      "Epoch 00163: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2176 - categorical_crossentropy: 0.2176 - val_loss: 0.2113 - val_categorical_crossentropy: 0.2113\n",
      "Epoch 164/250\n",
      "Epoch 00164: categorical_crossentropy improved from 0.21748 to 0.21742, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2174 - categorical_crossentropy: 0.2174 - val_loss: 0.2115 - val_categorical_crossentropy: 0.2115\n",
      "Epoch 165/250\n",
      "Epoch 00165: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2174 - categorical_crossentropy: 0.2174 - val_loss: 0.2119 - val_categorical_crossentropy: 0.2119\n",
      "Epoch 166/250\n",
      "Epoch 00166: categorical_crossentropy improved from 0.21742 to 0.21741, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2174 - categorical_crossentropy: 0.2174 - val_loss: 0.2112 - val_categorical_crossentropy: 0.2112\n",
      "Epoch 167/250\n",
      "Epoch 00167: categorical_crossentropy improved from 0.21741 to 0.21740, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2174 - categorical_crossentropy: 0.2174 - val_loss: 0.2113 - val_categorical_crossentropy: 0.2113\n",
      "Epoch 168/250\n",
      "Epoch 00168: categorical_crossentropy improved from 0.21740 to 0.21731, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2173 - categorical_crossentropy: 0.2173 - val_loss: 0.2110 - val_categorical_crossentropy: 0.2110\n",
      "Epoch 169/250\n",
      "Epoch 00169: categorical_crossentropy improved from 0.21731 to 0.21730, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2173 - categorical_crossentropy: 0.2173 - val_loss: 0.2113 - val_categorical_crossentropy: 0.2113\n",
      "Epoch 170/250\n",
      "Epoch 00170: categorical_crossentropy improved from 0.21730 to 0.21717, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2172 - categorical_crossentropy: 0.2172 - val_loss: 0.2124 - val_categorical_crossentropy: 0.2124\n",
      "Epoch 171/250\n",
      "Epoch 00171: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2173 - categorical_crossentropy: 0.2173 - val_loss: 0.2110 - val_categorical_crossentropy: 0.2110\n",
      "Epoch 172/250\n",
      "Epoch 00172: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2173 - categorical_crossentropy: 0.2173 - val_loss: 0.2109 - val_categorical_crossentropy: 0.2109\n",
      "Epoch 173/250\n",
      "Epoch 00173: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2174 - categorical_crossentropy: 0.2174 - val_loss: 0.2109 - val_categorical_crossentropy: 0.2109\n",
      "Epoch 174/250\n",
      "Epoch 00174: categorical_crossentropy improved from 0.21717 to 0.21714, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2171 - categorical_crossentropy: 0.2171 - val_loss: 0.2108 - val_categorical_crossentropy: 0.2108\n",
      "Epoch 175/250\n",
      "Epoch 00175: categorical_crossentropy improved from 0.21714 to 0.21710, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2171 - categorical_crossentropy: 0.2171 - val_loss: 0.2111 - val_categorical_crossentropy: 0.2111\n",
      "Epoch 176/250\n",
      "Epoch 00176: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2171 - categorical_crossentropy: 0.2171 - val_loss: 0.2110 - val_categorical_crossentropy: 0.2110\n",
      "Epoch 177/250\n",
      "Epoch 00177: categorical_crossentropy improved from 0.21710 to 0.21703, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2170 - categorical_crossentropy: 0.2170 - val_loss: 0.2110 - val_categorical_crossentropy: 0.2110\n",
      "Epoch 178/250\n",
      "Epoch 00178: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2172 - categorical_crossentropy: 0.2172 - val_loss: 0.2110 - val_categorical_crossentropy: 0.2110\n",
      "Epoch 179/250\n",
      "Epoch 00179: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2171 - categorical_crossentropy: 0.2171 - val_loss: 0.2105 - val_categorical_crossentropy: 0.2105\n",
      "Epoch 180/250\n",
      "Epoch 00180: categorical_crossentropy improved from 0.21703 to 0.21692, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2169 - categorical_crossentropy: 0.2169 - val_loss: 0.2114 - val_categorical_crossentropy: 0.2114\n",
      "Epoch 181/250\n",
      "Epoch 00181: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2170 - categorical_crossentropy: 0.2170 - val_loss: 0.2109 - val_categorical_crossentropy: 0.2109\n",
      "Epoch 182/250\n",
      "Epoch 00182: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2169 - categorical_crossentropy: 0.2169 - val_loss: 0.2111 - val_categorical_crossentropy: 0.2111\n",
      "Epoch 183/250\n",
      "Epoch 00183: categorical_crossentropy improved from 0.21692 to 0.21685, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2169 - categorical_crossentropy: 0.2169 - val_loss: 0.2113 - val_categorical_crossentropy: 0.2113\n",
      "Epoch 184/250\n",
      "Epoch 00184: categorical_crossentropy improved from 0.21685 to 0.21674, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2167 - categorical_crossentropy: 0.2167 - val_loss: 0.2108 - val_categorical_crossentropy: 0.2108\n",
      "Epoch 185/250\n",
      "Epoch 00185: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2169 - categorical_crossentropy: 0.2169 - val_loss: 0.2102 - val_categorical_crossentropy: 0.2102\n",
      "Epoch 186/250\n",
      "Epoch 00186: categorical_crossentropy improved from 0.21674 to 0.21671, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2167 - categorical_crossentropy: 0.2167 - val_loss: 0.2115 - val_categorical_crossentropy: 0.2115\n",
      "Epoch 187/250\n",
      "Epoch 00187: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2168 - categorical_crossentropy: 0.2168 - val_loss: 0.2107 - val_categorical_crossentropy: 0.2107\n",
      "Epoch 188/250\n",
      "Epoch 00188: categorical_crossentropy improved from 0.21671 to 0.21671, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2167 - categorical_crossentropy: 0.2167 - val_loss: 0.2108 - val_categorical_crossentropy: 0.2108\n",
      "Epoch 189/250\n",
      "Epoch 00189: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2168 - categorical_crossentropy: 0.2168 - val_loss: 0.2111 - val_categorical_crossentropy: 0.2111\n",
      "Epoch 190/250\n",
      "Epoch 00190: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2168 - categorical_crossentropy: 0.2168 - val_loss: 0.2111 - val_categorical_crossentropy: 0.2111\n",
      "Epoch 191/250\n",
      "Epoch 00191: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2167 - categorical_crossentropy: 0.2167 - val_loss: 0.2109 - val_categorical_crossentropy: 0.2109\n",
      "Epoch 192/250\n",
      "Epoch 00192: categorical_crossentropy improved from 0.21671 to 0.21648, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2165 - categorical_crossentropy: 0.2165 - val_loss: 0.2107 - val_categorical_crossentropy: 0.2107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/250\n",
      "Epoch 00193: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2167 - categorical_crossentropy: 0.2167 - val_loss: 0.2106 - val_categorical_crossentropy: 0.2106\n",
      "Epoch 194/250\n",
      "Epoch 00194: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2166 - categorical_crossentropy: 0.2166 - val_loss: 0.2105 - val_categorical_crossentropy: 0.2105\n",
      "Epoch 195/250\n",
      "Epoch 00195: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2166 - categorical_crossentropy: 0.2166 - val_loss: 0.2100 - val_categorical_crossentropy: 0.2100\n",
      "Epoch 196/250\n",
      "Epoch 00196: categorical_crossentropy improved from 0.21648 to 0.21643, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2164 - categorical_crossentropy: 0.2164 - val_loss: 0.2103 - val_categorical_crossentropy: 0.2103\n",
      "Epoch 197/250\n",
      "Epoch 00197: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2164 - categorical_crossentropy: 0.2164 - val_loss: 0.2103 - val_categorical_crossentropy: 0.2103\n",
      "Epoch 198/250\n",
      "Epoch 00198: categorical_crossentropy improved from 0.21643 to 0.21636, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2164 - categorical_crossentropy: 0.2164 - val_loss: 0.2103 - val_categorical_crossentropy: 0.2103\n",
      "Epoch 199/250\n",
      "Epoch 00199: categorical_crossentropy improved from 0.21636 to 0.21629, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2163 - categorical_crossentropy: 0.2163 - val_loss: 0.2107 - val_categorical_crossentropy: 0.2107\n",
      "Epoch 200/250\n",
      "Epoch 00200: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2165 - categorical_crossentropy: 0.2165 - val_loss: 0.2099 - val_categorical_crossentropy: 0.2099\n",
      "Epoch 201/250\n",
      "Epoch 00201: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2164 - categorical_crossentropy: 0.2164 - val_loss: 0.2100 - val_categorical_crossentropy: 0.2100\n",
      "Epoch 202/250\n",
      "Epoch 00202: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2166 - categorical_crossentropy: 0.2166 - val_loss: 0.2108 - val_categorical_crossentropy: 0.2108\n",
      "Epoch 203/250\n",
      "Epoch 00203: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2164 - categorical_crossentropy: 0.2164 - val_loss: 0.2108 - val_categorical_crossentropy: 0.2108\n",
      "Epoch 204/250\n",
      "Epoch 00204: categorical_crossentropy improved from 0.21629 to 0.21622, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2162 - categorical_crossentropy: 0.2162 - val_loss: 0.2103 - val_categorical_crossentropy: 0.2103\n",
      "Epoch 205/250\n",
      "Epoch 00205: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2163 - categorical_crossentropy: 0.2163 - val_loss: 0.2099 - val_categorical_crossentropy: 0.2099\n",
      "Epoch 206/250\n",
      "Epoch 00206: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2163 - categorical_crossentropy: 0.2163 - val_loss: 0.2113 - val_categorical_crossentropy: 0.2113\n",
      "Epoch 207/250\n",
      "Epoch 00207: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2164 - categorical_crossentropy: 0.2164 - val_loss: 0.2098 - val_categorical_crossentropy: 0.2098\n",
      "Epoch 208/250\n",
      "Epoch 00208: categorical_crossentropy improved from 0.21622 to 0.21601, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2160 - categorical_crossentropy: 0.2160 - val_loss: 0.2106 - val_categorical_crossentropy: 0.2106\n",
      "Epoch 209/250\n",
      "Epoch 00209: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2162 - categorical_crossentropy: 0.2162 - val_loss: 0.2104 - val_categorical_crossentropy: 0.2104\n",
      "Epoch 210/250\n",
      "Epoch 00210: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2165 - categorical_crossentropy: 0.2165 - val_loss: 0.2130 - val_categorical_crossentropy: 0.2130\n",
      "Epoch 211/250\n",
      "Epoch 00211: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2165 - categorical_crossentropy: 0.2165 - val_loss: 0.2097 - val_categorical_crossentropy: 0.2097\n",
      "Epoch 212/250\n",
      "Epoch 00212: categorical_crossentropy improved from 0.21601 to 0.21600, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2160 - categorical_crossentropy: 0.2160 - val_loss: 0.2109 - val_categorical_crossentropy: 0.2109\n",
      "Epoch 213/250\n",
      "Epoch 00213: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2161 - categorical_crossentropy: 0.2161 - val_loss: 0.2100 - val_categorical_crossentropy: 0.2100\n",
      "Epoch 214/250\n",
      "Epoch 00214: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2161 - categorical_crossentropy: 0.2161 - val_loss: 0.2103 - val_categorical_crossentropy: 0.2103\n",
      "Epoch 215/250\n",
      "Epoch 00215: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2161 - categorical_crossentropy: 0.2161 - val_loss: 0.2105 - val_categorical_crossentropy: 0.2105\n",
      "Epoch 216/250\n",
      "Epoch 00216: categorical_crossentropy improved from 0.21600 to 0.21597, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2160 - categorical_crossentropy: 0.2160 - val_loss: 0.2105 - val_categorical_crossentropy: 0.2105\n",
      "Epoch 217/250\n",
      "Epoch 00217: categorical_crossentropy improved from 0.21597 to 0.21596, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2160 - categorical_crossentropy: 0.2160 - val_loss: 0.2096 - val_categorical_crossentropy: 0.2096\n",
      "Epoch 218/250\n",
      "Epoch 00218: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2161 - categorical_crossentropy: 0.2161 - val_loss: 0.2100 - val_categorical_crossentropy: 0.2100\n",
      "Epoch 219/250\n",
      "Epoch 00219: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2162 - categorical_crossentropy: 0.2162 - val_loss: 0.2105 - val_categorical_crossentropy: 0.2105\n",
      "Epoch 220/250\n",
      "Epoch 00220: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2161 - categorical_crossentropy: 0.2161 - val_loss: 0.2097 - val_categorical_crossentropy: 0.2097\n",
      "Epoch 221/250\n",
      "Epoch 00221: categorical_crossentropy improved from 0.21596 to 0.21584, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2158 - categorical_crossentropy: 0.2158 - val_loss: 0.2100 - val_categorical_crossentropy: 0.2100\n",
      "Epoch 222/250\n",
      "Epoch 00222: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2160 - categorical_crossentropy: 0.2160 - val_loss: 0.2097 - val_categorical_crossentropy: 0.2097\n",
      "Epoch 223/250\n",
      "Epoch 00223: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2159 - categorical_crossentropy: 0.2159 - val_loss: 0.2096 - val_categorical_crossentropy: 0.2096\n",
      "Epoch 224/250\n",
      "Epoch 00224: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2160 - categorical_crossentropy: 0.2160 - val_loss: 0.2118 - val_categorical_crossentropy: 0.2118\n",
      "Epoch 225/250\n",
      "Epoch 00225: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2159 - categorical_crossentropy: 0.2159 - val_loss: 0.2101 - val_categorical_crossentropy: 0.2101\n",
      "Epoch 226/250\n",
      "Epoch 00226: categorical_crossentropy improved from 0.21584 to 0.21582, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2158 - categorical_crossentropy: 0.2158 - val_loss: 0.2094 - val_categorical_crossentropy: 0.2094\n",
      "Epoch 227/250\n",
      "Epoch 00227: categorical_crossentropy improved from 0.21582 to 0.21574, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2157 - categorical_crossentropy: 0.2157 - val_loss: 0.2101 - val_categorical_crossentropy: 0.2101\n",
      "Epoch 228/250\n",
      "Epoch 00228: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2158 - categorical_crossentropy: 0.2158 - val_loss: 0.2101 - val_categorical_crossentropy: 0.2101\n",
      "Epoch 229/250\n",
      "Epoch 00229: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2158 - categorical_crossentropy: 0.2158 - val_loss: 0.2095 - val_categorical_crossentropy: 0.2095\n",
      "Epoch 230/250\n",
      "Epoch 00230: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2160 - categorical_crossentropy: 0.2160 - val_loss: 0.2113 - val_categorical_crossentropy: 0.2113\n",
      "Epoch 231/250\n",
      "Epoch 00231: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2160 - categorical_crossentropy: 0.2160 - val_loss: 0.2114 - val_categorical_crossentropy: 0.2114\n",
      "Epoch 232/250\n",
      "Epoch 00232: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2158 - categorical_crossentropy: 0.2158 - val_loss: 0.2099 - val_categorical_crossentropy: 0.2099\n",
      "Epoch 233/250\n",
      "Epoch 00233: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2161 - categorical_crossentropy: 0.2161 - val_loss: 0.2104 - val_categorical_crossentropy: 0.2104\n",
      "Epoch 234/250\n",
      "Epoch 00234: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2158 - categorical_crossentropy: 0.2158 - val_loss: 0.2094 - val_categorical_crossentropy: 0.2094\n",
      "Epoch 235/250\n",
      "Epoch 00235: categorical_crossentropy improved from 0.21574 to 0.21562, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2156 - categorical_crossentropy: 0.2156 - val_loss: 0.2098 - val_categorical_crossentropy: 0.2098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/250\n",
      "Epoch 00236: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2156 - categorical_crossentropy: 0.2156 - val_loss: 0.2104 - val_categorical_crossentropy: 0.2104\n",
      "Epoch 237/250\n",
      "Epoch 00237: categorical_crossentropy improved from 0.21562 to 0.21552, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2155 - categorical_crossentropy: 0.2155 - val_loss: 0.2095 - val_categorical_crossentropy: 0.2095\n",
      "Epoch 238/250\n",
      "Epoch 00238: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2157 - categorical_crossentropy: 0.2157 - val_loss: 0.2095 - val_categorical_crossentropy: 0.2095\n",
      "Epoch 239/250\n",
      "Epoch 00239: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2156 - categorical_crossentropy: 0.2156 - val_loss: 0.2093 - val_categorical_crossentropy: 0.2093\n",
      "Epoch 240/250\n",
      "Epoch 00240: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2159 - categorical_crossentropy: 0.2159 - val_loss: 0.2101 - val_categorical_crossentropy: 0.2101\n",
      "Epoch 241/250\n",
      "Epoch 00241: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2158 - categorical_crossentropy: 0.2158 - val_loss: 0.2092 - val_categorical_crossentropy: 0.2092\n",
      "Epoch 242/250\n",
      "Epoch 00242: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2156 - categorical_crossentropy: 0.2156 - val_loss: 0.2098 - val_categorical_crossentropy: 0.2098\n",
      "Epoch 243/250\n",
      "Epoch 00243: categorical_crossentropy improved from 0.21552 to 0.21541, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2154 - categorical_crossentropy: 0.2154 - val_loss: 0.2096 - val_categorical_crossentropy: 0.2096\n",
      "Epoch 244/250\n",
      "Epoch 00244: categorical_crossentropy improved from 0.21541 to 0.21539, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2154 - categorical_crossentropy: 0.2154 - val_loss: 0.2094 - val_categorical_crossentropy: 0.2094\n",
      "Epoch 245/250\n",
      "Epoch 00245: categorical_crossentropy improved from 0.21539 to 0.21538, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2154 - categorical_crossentropy: 0.2154 - val_loss: 0.2096 - val_categorical_crossentropy: 0.2096\n",
      "Epoch 246/250\n",
      "Epoch 00246: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2154 - categorical_crossentropy: 0.2154 - val_loss: 0.2100 - val_categorical_crossentropy: 0.2100\n",
      "Epoch 247/250\n",
      "Epoch 00247: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2159 - categorical_crossentropy: 0.2159 - val_loss: 0.2095 - val_categorical_crossentropy: 0.2095\n",
      "Epoch 248/250\n",
      "Epoch 00248: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2154 - categorical_crossentropy: 0.2154 - val_loss: 0.2093 - val_categorical_crossentropy: 0.2093\n",
      "Epoch 249/250\n",
      "Epoch 00249: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.2154 - categorical_crossentropy: 0.2154 - val_loss: 0.2091 - val_categorical_crossentropy: 0.2091\n",
      "Epoch 250/250\n",
      "Epoch 00250: categorical_crossentropy improved from 0.21538 to 0.21534, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.2153 - categorical_crossentropy: 0.2153 - val_loss: 0.2093 - val_categorical_crossentropy: 0.2093\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 36, 7)             315       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 36, 7)             56        \n",
      "=================================================================\n",
      "Total params: 371\n",
      "Trainable params: 371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None Training time : 271.2928719520569s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history3 = model3.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    callbacks = [checkpoint, early])\n",
    "stop = time.time()\n",
    "t3 = stop-start\n",
    "print(model3.summary(), end=\" \")\n",
    "print(\"Training time : {}s\".format(t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GRU_steps = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We can first check the time used to train them on the same dataset with the same number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-331fb464ae6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LSTM :       {:.2f}s\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Simple RNN : {:.2f}s\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GRU :        {:.2f}s\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't1' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"LSTM :       {:.2f}s\".format(t1))\n",
    "print(\"Simple RNN : {:.2f}s\".format(t2))\n",
    "print(\"GRU :        {:.2f}s\".format(t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the simple RNN is the fastest to train because there is nearly no impact of provide the output as input. It's only and addtion to do on Matrices. However, LSTM and GRU are slower to train and as expected, GRU trained faster than LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [207, 250, 250]\n",
      "time [164.06, 181.82, 330.12]\n"
     ]
    }
   ],
   "source": [
    "print(\"epoch\", [LSTM_steps, SRNN_steps, GRU_steps])\n",
    "print(\"time\", [164.06, 181.82, 330.12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a860639e91a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pastel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LSTM\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"SimpleRNN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"GRU\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training time\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"muted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAHUCAYAAADWXIWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njgEAIIljAABI4hgAAJI4BgCA9D9daMSaik5nvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bae9d19c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=[t1, t2, t3] , y=[\"LSTM\", \"SimpleRNN\", \"GRU\"], label=\"Training time\", color=\"b\")\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=[LSTM_steps, SRNN_steps, GRU_steps], y=[\"LSTM\", \"SimpleRNN\", \"GRU\"], label=\"Training Epoch\", color=\"b\")\n",
    "\n",
    "\n",
    "\n",
    "# Add a legend and informative axis label\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(xlim=(0, 350), ylabel=\"\",\n",
    "       xlabel=\"Epochs/Time(s)\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig(\"barplot_softmax.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In term of loss TO BE DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_crossentropy', 'loss', 'categorical_crossentropy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAK9CAYAAAAE1vtiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XmQZGd57/nfczJPZp7MrKW7qrob\ndUvqxkhCEi21UMNYIIseVnENkjGyWcI2AnyBGMvY8vWEWRwYa4K4F6MYBtsaRzAYy+MZWwYvjKzQ\nIPCi8ca11LIwRhJCsgBRLamXqu5acqnc3vnjZFbX1lJWVZ48uXw/ER1V+Z6TWU/VX794+jnva845\nAQAAANgaL+4CAAAAgH5GoAYAAAC2gUANAAAAbAOBGgAAANgGAjUAAACwDQRqAAAAYBsI1AAAAMA2\nEKgBAACAbSBQAwAAANuQjLuAzZqcnHT79++PuwwAAAAMuIceeuiUc27qhe7ru0C9f/9+HT16NO4y\nAAAAMODM7Aft3MfIBwAAALANBGoAAABgGwjUAAAAwDb03Qw1AADAMKhWq5qenla5XI67lIGXyWS0\nb98++b6/pfcTqAEAAHrQ9PS0RkZGtH//fplZ3OUMLOecZmZmND09rQMHDmzpMxj5AAAA6EHlclkT\nExOE6YiZmSYmJrb1PwEEagAAgB5FmO6O7f6dCdQAAADANhCoAQAAsKF8Pr9u7fHHH9eRI0d06NAh\nXXrppfrABz6g++67T4cOHdKhQ4eUz+d1ySWX6NChQ/q5n/s53X///TIz/f7v//7yZzz88MMyM91+\n++3d/HUiw0OJAAAAaNuHP/xh3XrrrbrxxhslSf/+7/+ugwcP6k1vepMk6ciRI7r99tt1+PBhSdL9\n99+vgwcP6k//9E/1/ve/X5J011136corr4znF4gAHWoAAAC07dlnn9W+ffuWXx88ePAF33PBBReo\nXC7r+PHjcs7pq1/9qt785jdHWWZX0aEGAADocb/5V4/o0WfmO/qZl503qt946+Wbft+tt96q1772\ntXrVq16lN77xjXrve9+r8fHxF3zfTTfdpC9/+cu66qqr9PKXv1zpdHorZfckOtQAAABo23vf+149\n9thj+qmf+indf//9+tEf/VEtLS294Pt++qd/Wl/+8pf1J3/yJ3rXu97VhUq7hw41AABAj9tKJzlK\n5513nt73vvfpfe97n172spfp29/+tq6++urnfc+ePXvk+76+/vWv63Of+5z++Z//uUvVRo9ADQAA\ngLZ99atf1ete9zr5vq/nnntOMzMz2rt3b1vvve2223TixAklEomIq+wuAjUAAAA2VCwWVz2A+Cu/\n8iuanp7WL/3SLymTyUiSPvOZz2jPnj1tfd6rXvWqSOqMmznn4q5hUw4fPuyOHj0adxkAAACReuyx\nx3TppZfGXcbQ2OjvbWYPOecOv9B7eSgRAAAA2AYCNQAAALANBGoAAABgGwjUAAAAwDYQqAEAAIBt\nIFADAAAA20CgBgAAwIY+9alP6fLLL9cVV1yhQ4cO6V/+5V/08z//83r00Uc78vn5fP4F70kkEjp0\n6JBe9rKX6a1vfavOnDkjSfr+978vM9Pv/M7vLN97yy236M4775Qk3Xzzzdq7d+/yseinTp3S/v37\nO1L3WgRqAAAArPONb3xD99xzj/71X/9V3/rWt/TXf/3XOv/88/WFL3xBl112WdfqCIJA3/zmN/Xt\nb39bO3fu1B133LF8bdeuXfrc5z6nSqWy4XsTiYS++MUvRl4jgRoAAADrPPvss5qcnFQ6nZYkTU5O\n6rzzztORI0fUOmQvn8/r137t13T11Vfr9a9/vR544AEdOXJEL37xi3X33XdLku68807deOONuv76\n63XJJZfoN3/zNzf8eZ/5zGf0ile8QldccYV+4zd+Y8N7rrnmGh07dmz59dTUlF73utfpD//wDze8\n/5d/+Zf12c9+VrVabct/h3Zw9DgAAECv+38/Ij337539zD0HpTf/t3NefuMb36jbbrtNF198sV7/\n+tfrHe94h17zmtesuqdQKOjIkSP69Kc/rbe97W369V//dX3961/Xo48+qve85z264YYbJEkPPPCA\nvv3tbyubzeoVr3iFfvzHf1yHD589gPBrX/uannjiCT3wwANyzumGG27Q3//93+u6665bvqder+tv\n/uZv9P73v39VDR/5yEf05je/We973/vW/Q4XXHCBrr32Wv3RH/2R3vrWt27pz9QOOtTtOPld6Sv/\nU/gVAABgCOTzeT300EP6/Oc/r6mpKb3jHe9Ynk9uSaVSuv766yVJBw8e1Gte8xr5vq+DBw/q+9//\n/vJ9b3jDGzQxMaEgCPSTP/mT+sd//MdVn/O1r31NX/va13TVVVfp5S9/ub7zne/oiSeekCSVSiUd\nOnRIExMTmp2d1Rve8IZV7z1w4IBe+cpX6o//+I83/D0+9rGP6TOf+YwajcY2/yLnRoe6HaXT0jf/\nb+llb5emLo67GgAAMGyep5McpUQioSNHjujIkSM6ePDgutEK3/dlZpIkz/OWx0M8z1s1ZtG651yv\nnXP66Ec/qg9+8IPramjNUM/Nzektb3mL7rjjDn34wx9edc/HPvYx3XTTTas62i0veclLdOjQIX3p\nS1/axG++OXSo2+EH4ddqKd46AAAAuuTxxx9f7hJL0je/+U1deOGFW/qsr3/965qdnVWpVNJXvvIV\nvfrVr151/U1vepO++MUvanFxUZJ07NgxnThxYtU9Y2Nj+u3f/m3dfvvtqlarq6699KUv1WWXXaZ7\n7rlnw5//8Y9/XLfffvuWam8Hgbodfjb8SqAGAABDYnFxUe95z3t02WWX6YorrtCjjz6qT37yk1v6\nrGuvvVY/+7M/q0OHDuntb3/7qvlpKZzXfve7361rrrlGBw8e1E033aSFhYV1n3PVVVfpyiuv1F13\n3bXu2sc//nFNT09v+PMvv/xyvfzlL99S7e0w51xkHx6Fw4cPu9aTpV0zd0z67GXSW39buvo93f3Z\nAABgKD322GO69NJL4y5j2+68804dPXpUv/u7vxt3Kc9ro7+3mT3knDt8jrcso0PdDkY+AAAAcA48\nlNiO1shHjUANAACwGTfffLNuvvnmuMuIFB3qdiTTkowONQAAANYhULfDLBz7qBbjrgQAAAA9JtJA\nbWbXm9njZvakmX1kg+sXmtnfmNm3zOx+M9sXZT3b4gd0qAEAALBOZIHazBKS7pD0ZkmXSXqXmV22\n5rbbJf2fzrkrJN0m6b9GVc+2+VkCNQAAANaJskP9SklPOueecs5VJN0l6cY191wm6W+a3//dBtd7\nByMfAABgyBw/flzvfve79eIXv1hXX321rrnmGv3lX/6l7r//fo2Njemqq67SS1/6Uv3qr/7q8ns+\n+clPrjtEZf/+/Tp16lS3y++aKAP1Xkk/XPF6urm20r9Jenvz+7dJGjGziQhr2jpGPgAAwBBxzukn\nfuIndN111+mpp57SQw89pLvuumv58JQf+7Ef08MPP6yHH35Y99xzj/7pn/4p5orjE2Wgtg3W1p4i\n86uSXmNmD0t6jaRjkmpr32RmHzCzo2Z29OTJk52vtB1+lg41AAAYGn/7t3+rVCqlD33oQ8trF154\noX7xF39x1X1BEOjQoUM6duxYt0vsGVHuQz0t6fwVr/dJemblDc65ZyT9pCSZWV7S251zc2s/yDn3\neUmfl8KTEqMq+Hn5gbS0/ghMAACAqH36gU/rO7Pf6ehnvnTnS/Vrr/y1c15/5JFH2jqu+/Tp03ri\niSd03XXXdbK8vhJlh/pBSReZ2QEzS0l6p6S7V95gZpNm1qrho5K+GGE928NDiQAAYIj9wi/8gq68\n8kq94hWvkCT9wz/8g6644grt2bNHb3nLW7Rnzx5JktlGQwrnXh8EkXWonXM1M7tF0n2SEpK+6Jx7\nxMxuk3TUOXe3pCOS/quZOUl/L+kXoqpn23goEQAAxOT5OslRufzyy/Xnf/7ny6/vuOMOnTp1SocP\nH5YUzlDfc889+u53v6trr71Wb3vb23To0CFNTEzo2WefXfVZCwsLGh8f72r93RTpPtTOuXudcxc7\n537EOfep5tonmmFazrk/c85d1Lzn551zS1HWsy3JjFQtx10FAABAV7z2ta9VuVzW7/3e7y2vFYvr\nm4sXX3yxPvrRj+rTn/60JOm6667T3XffrYWFcFT2L/7iL3TllVcqkUh0p/AYRDlDPVh4KBEAAAwR\nM9NXvvIV3Xrrrfqt3/otTU1NKZfLLQfnlT70oQ/p9ttv1/e+9z1dccUVuuWWW3TttdfKzLRr1y59\n4QtfiOE36B4CdbvYNg8AAAyZF73oRbrrrrs2vHbkyJHl74MgWLXLxwc/+EF98IMfjLq8nhHpyMdA\n8bNSfUlq1OOuBAAAAD2EQN0uPwi/0qUGAADACgTqdhGoAQBAlzkXz/Ebw2a7f2cCdbv8bPiVBxMB\nAEAXZDIZzczMEKoj5pzTzMyMMpnMlj+DhxLbRYcaAAB00b59+zQ9Pa2TJ0/GXcrAy2Qy2rdv35bf\nT6BuFx1qAADQRb7v68CBA3GXgTYw8tEuOtQAAADYAIG6XQRqAAAAbIBA3YZHZh7RO49+So+kUlKN\nQA0AAICzCNRtqDfqemT+Kc0kPDrUAAAAWIVA3Ya8n5ckFTyPhxIBAACwCoG6DdnmDh+LntGhBgAA\nwCoE6jY8czrcUL1odKgBAACwGoG6Da6ekiQtJBJ0qAEAALAKgboN49m0XD2lxYRPoAYAAMAqBOo2\njGSSco20FrwkIx8AAABYhUDdhtGML9fIaNFj5AMAAACrEajbkPETMpfWIg8lAgAAYA0CdZsSCrTo\ncbALAAAAViNQt8m3jAomAjUAAABWIVC3KeVlVSRQAwAAYA0CdZvSXlZFTwRqAAAArEKgblOQzKps\nDblqIe5SAAAA0EMI1G3KJnOqm1SpluMuBQAAAD2EQN2mvJ+TJBXqBGoAAACcRaBu00g6L0laJFAD\nAABgBQJ1m0abgbqoulSvxlwNAAAAegWBuk07MiOSxOEuAAAAWIVA3aZWoC6aEagBAACwjEDdponc\nqKRWh7oYczUAAADoFQTqNk1mw0Bd8Eyq8WAiAAAAQgTqNu3Kj0mSCkaHGgAAAGcRqNu0K9fqUPNQ\nIgAAAM4iULdpNEjJ6r4WPR5KBAAAwFkE6jYlPJPnUiryUCIAAABWIFBvQsKltci2eQAAAFiBQL0J\nCQXNGWo61AAAAAgRqDch6WV5KBEAAACrEKg3Ienlwn2o6VADAACgiUC9CelETotGhxoAAABnEag3\nIUjmGPkAAADAKgTqTcj54chHo8LIBwAAAEIE6k3I+znVzVRaWoy7FAAAAPQIAvUmjKZHJElzZQI1\nAAAAQgTqTRhL5yVJC5WFmCsBAABAryBQb8J4EHaoF9g2DwAAAE0E6k3Y2QzUxRqBGgAAACEC9SZM\nBKOSpGKdbfMAAAAQIlBvwq5cGKhLrhJzJQAAAOgVBOpN2JUfkySVCdQAAABoIlBvws7myEfZ1STn\nYq4GAAAAvYBAvQlZPys5qeCZVCvHXQ4AAAB6AIF6E8xMvkuGgbpSiLscAAAA9AAC9SaFgdqTKpyW\nCAAAAAL1pqWUVsFMqrAXNQAAAAjUm+ZbutmhZuQDAAAABOpNS3kZFT1j5AMAAACSCNSblvayKhgd\nagAAAIQI1JuUSeZV8DzVywtxlwIAAIAeQKDepIyfV9EzLZUY+QAAAACBetOy6TEVzbRUoEMNAAAA\nAvWm5TKjWvI8lYpn4i4FAAAAPYBAvUlj6VFJ0nyZQA0AAAAC9aaNZ0YkSYXyfMyVAAAAoBcQqDdp\nR5CXJBXYhxoAAAAiUG/aRDbsUJdq7EMNAAAAAvWmTWTDGepyvRhzJQAAAOgFBOpNGk2HIx/leinm\nSgAAANALCNSblE1mJUkVtxRzJQAAAOgFBOpNyvphoF5SNeZKAAAA0AsI1JuU83OSpAqBGgAAACJQ\nb1omkZE5aUm1uEsBAABADyBQb5KZKa2EKl5DatTjLgcAAAAxI1BvQVq+Cp4nVdk6DwAAYNhFGqjN\n7Hoze9zMnjSzj2xw/QIz+zsze9jMvmVm/ynKejolbSkVzeQqHO4CAAAw7CIL1GaWkHSHpDdLukzS\nu8zssjW3/bqkLznnrpL0Tkn/e1T1dFLaUip4npYKC3GXAgAAgJhF2aF+paQnnXNPOecqku6SdOOa\ne5yk0eb3Y5KeibCejgkSgYqeqbg4F3cpAAAAiFmUgXqvpB+ueD3dXFvpk5J+xsymJd0r6RcjrKdj\ngmSggnkqFgjUAAAAwy7KQG0brLk1r98l6U7n3D5J/0nSH5nZuprM7ANmdtTMjp48eTKCUjcnm8yr\n6JnKhfm4SwEAAEDMogzU05LOX/F6n9aPdLxf0pckyTn3DUkZSZNrP8g593nn3GHn3OGpqamIym1f\nLpVXwfNULjJDDQAAMOyiDNQPSrrIzA6YWUrhQ4d3r7nnaUmvkyQzu1RhoI6/Bf0CRjKjKpqpWlyM\nuxQAAADELLJA7ZyrSbpF0n2SHlO4m8cjZnabmd3QvO2/SPrPZvZvkv5E0s3OubVjIT1nNBhX2fNU\nKTFDDQAAMOySUX64c+5ehQ8brlz7xIrvH5X06ihriMJ4bockqVAmUAMAAAw7TkrcgrFsGKhLFQI1\nAADAsCNQb0E+lZcklao8lAgAADDsCNRbkPNzkqRKjaPHAQAAhh2BeguCZCBJWmoQqAEAAIYdgXoL\nWh3qaqMccyUAAACIG4F6C5YDtVuKuRIAAADEjUC9BdlkVpJUtUrMlQAAACBuBOotWO5Qi0ANAAAw\n7AjUWxAkA5mTql5d9UbPH+wIAACACBGot8DMlFFCdatrsVyLuxwAAADEiEC9RRlLqOI1NF+uxl0K\nAAAAYkSg3qLAUip7TgvFUtylAAAAIEYE6i0KvLSKnqdygePHAQAAhhmBeouyibQKZioX5uIuBQAA\nADEiUG9RLhk0O9TzcZcCAACAGBGotyiXyqvgmaqFM3GXAgAAgBgRqLdoJDOqonlqlBj5AAAAGGYE\n6i0ayYyp4JnqZQI1AADAMCNQb1E+M66S56lRYuQDAABgmBGotyiX2SFJqi2djrkSAAAAxIlAvUXZ\nZqCuVgnUAAAAw4xAvUVZPytJqtXZNg8AAGCYEai3KOfnJEn1OiclAgAADDMC9Ra1ArVzxZgrAQAA\nQJwI1FuUTYYjH3VXirkSAAAAxIlAvUWtGeqGlWOuBAAAAHEiUG/R8siHLck5F3M1AAAAiAuBeota\ngbrh1VSuNmKuBgAAAHEhUG9RkAwkSTWvpoXyUszVAAAAIC4E6i3yzFNaSRU9U2Ge48cBAACGFYF6\nGwJLqWimpUUCNQAAwLAiUG9DJpFSwfNUXuT4cQAAgGFFoN6GbCKrouepQqAGAAAYWgTqbcj5ORXM\nVCsy8gEAADCsCNTbkE+PqOiZGqW5uEsBAABATAjU25DPjKponhplAjUAAMCwIlBvw0hmTAXPpPJ8\n3KUAAAAgJgTqbcilR1X0PNkSgRoAAGBYEai3IZvMqmimRIWRDwAAgGFFoN6GnJ+TM1O9RocaAABg\nWBGotyHn5yRJ9TqBGgAAYFgRqLch62clSc4VY64EAAAAcSFQb0M2GQbqugjUAAAAw4pAvQ2tkQ+p\nHGsdAAAAiA+BehtagbqhpZgrAQAAQFwI1NuwPPKRqKtercRcDQAAAOJAoN6G1kOJBc9UXJiNuRoA\nAADEgUC9Da2Rj4J5Ks6fjrkaAAAAxIFAvQ2tkY+iZyovEqgBAACGEYF6GxJeQinzVTRPSwRqAACA\noUSg3qYgkVHBM1ULZ+IuBQAAADEgUG9TkMiq6HmqFQnUAAAAw4hAvU25VF4FMzVKc3GXAgAAgBgQ\nqLcplxpR0fPkygRqAACAYUSg3qaRdF4LlpAtzcddCgAAAGJAoN6mfCqnRS8hb4kONQAAwDAiUG9T\nNplVwfPkVwjUAAAAw4hAvU05P6eSJ6WrBGoAAIBhRKDepqyfVdmkdI1ADQAAMIwI1NuU83NyJiUa\nC3GXAgAAgBgQqLcpm8xKkswVJOdirgYAAADdRqDeppyfkyRVvIZUWYy5GgAAAHQbgXqbsn7YoS56\nJpVOx1wNAAAAuo1AvU2tkY+CeWoUZmOuBgAAAN1GoN6m1shHwTOVFmZirgYAAADdRqDeplagLnqe\nluZPxlwNAAAAuo1AvU3LgdpMlQVGPgAAAIYNgXqbgmQgSSp4nmoFRj4AAACGDYF6m1od6jPm81Ai\nAADAECJQb1PSSyrlpXTaS0klAjUAAMCwIVB3QJDM6oylZOUzcZcCAACALiNQd0DOz2nBkkouEagB\nAACGDYG6A3J+VgteQn6FQA0AADBsCNQdkPWzKiUSSlfn4y4FAAAAXUag7oBsMquyZwpq85JzcZcD\nAACALiJQd0DWz2rJMyVVkyqLcZcDAACALoo0UJvZ9Wb2uJk9aWYf2eD6Z83sm81/3zWzvhxCziaz\nqnqN8EXpdLzFAAAAoKuSUX2wmSUk3SHpDZKmJT1oZnc75x5t3eOcu3XF/b8o6aqo6olS1s+qYisC\n9fgF8RYEAACAromyQ/1KSU86555yzlUk3SXpxue5/12S/iTCeiKTTWZVtVr4osjhLgAAAMMkykC9\nV9IPV7yebq6tY2YXSjog6W8jrCcyWT+rutVUkxj5AAAAGDJRBmrbYO1cW2C8U9KfOefqG36Q2QfM\n7KiZHT158mTHCuyUbDIrSSqZyRGoAQAAhkqUgXpa0vkrXu+T9Mw57n2nnmfcwzn3eefcYefc4amp\nqQ6W2BlZPwzURc9TbZGRDwAAgGESZaB+UNJFZnbAzFIKQ/Pda28ys0sk7ZD0jQhriVSrQz1jaVUX\nT8VcDQAAALopskDtnKtJukXSfZIek/Ql59wjZnabmd2w4tZ3SbrLuf49EaXVoT5hOdUKdKgBAACG\nSWTb5kmSc+5eSfeuWfvEmtefjLKGbmh1qE9ZIFdkhhoAAGCYcFJiB7Q61DOWkUp0qAEAAIYJgboD\nlmeovbS8cl8e9ggAAIAtIlB3QKtDPWdpJSsEagAAgGFCoO6AIBlIkuY8X+nKnNS/z1cCAABgkwjU\nHdAa+Zi3hDxXk5YWYq4IAAAA3UKg7gA/4cv3fJUSzU1TeDARAABgaBCoOyTrZ7WUbAbqIoEaAABg\nWBCoOySbzKqabP45CdQAAABDg0DdITk/p1rrmBxGPgAAAIYGgbpDssms6onmi+JMrLUAAACgewjU\nHRL4gepeTXV5jHwAAAAMEQJ1h2STWcmraEE5OtQAAABDhEDdIVk/q4aWNOtGmKEGAAAYIgTqDskm\ns6prSbMur0aBDjUAAMCwIFB3SDaZVc2VddqNEKgBAACGCIG6Q7J+VlVX1qzL8VAiAADAECFQd0g2\nmZUkHbecvPKs5FzMFQEAAKAbCNQdkvXDQD1jgbz6klQtxlwRAAAAuoFA3SFBMpAkzXiZcIGxDwAA\ngKFAoO6QVof6tKXDBfaiBgAAGAoE6g5pzVCfsVS4wF7UAAAAQ4FA3SGtDvWclwwXGPkAAAAYCgTq\nDsklc5KkctIPFwjUAAAAQ4FA3SGtDrVLtTrUzFADAAAMAwJ1h7RmqP1UQ0Uvzww1AADAkCBQd0ir\nQ+37Vc17o3SoAQAAhgSBukN8z1fSkmGgthFmqAEAAIZEMu4CBoWZKfADJVxFs26EDjUAAMCQoEPd\nQdlkVolERbONvFQ6HXc5AAAA6AICdQdl/awsUdHJep4ONQAAwJAgUHdQNpmVsyWdqGelalGqluIu\nCQAAABEjUHdQ1s/KaSmcoZZ4MBEAAGAIEKg7KJvMqq4lnW4FavaiBgAAGHgE6g4KA3X5bKBmjhoA\nAGDgEag7KOtnVWmUdVr5cIGRDwAAgIHHPtQdFCQDVRolVehQAwAADA0CdQdl/ayW6iWVlAsX2Isa\nAABg4DHy0UHZZFZOTlVzqiTZixoAAGAYEKg7KEgGkiTzKionx5ihBgAAGAIE6g5qBepEoqZCYowO\nNQAAwBAgUHdQJpmRJGUzDS16o+xDDQAAMAQI1B3U6lBn03XN2QgdagAAgCFAoO6gVoc6SNd1WiNS\nkV0+AAAABh2BuoMyiWagTjU028hLlQWpVom5KgAAAESJQN1BrZGPdKqmk43maYnMUQMAAAw0AnUH\ntQJ1yq/reC0bLjJHDQAAMNAI1B3UmqH2kzUdr7YCNR1qAACAQUag7qDlfaiTVR2r0KEGAAAYBgTq\nDmp1qJOJmk7VmaEGAAAYBgTqDvI9X0lLyktUdUbNQE2HGgAAYKARqDssSAaSVbSklBrJLHtRAwAA\nDDgCdYdlkhnJC/eermV20qEGAAAYcATqDsskM3IKA/VSaowZagAAgAFHoO6wIBmo3gzU5eQ4HWoA\nAIABR6DusEwyo7pbkiQVk2PsQw0AADDgCNQdFiQD1ZqBetEbJVADAAAMOAJ1hwWJQJVGGKjnbFRa\nmpPq1ZirAgAAQFQI1B2WSWa0VC8rn07qjEbCxRJb5wEAAAwqAnWHBclAxVpRo5mkZhqtw10Y+wAA\nABhUBOoOyyQzKtfKGg18naznwkV2+gAAABhYBOoOWw7UGV/Ha9lwkb2oAQAABhaBusOCZKBKo6KR\nwNMzVTrUAAAAg45A3WFBIpAk5dINHSuH3zNDDQAAMLgI1B2WSWYkSdlMQ6eWPCkZMPIBAAAwwAjU\nHRYkw650kKprYakml91JhxoAAGCAEag7rNWhTqfrck5qZAjUAAAAg4xA3WGtDnXar0uSqulxHkoE\nAAAYYATqDmsFat8Pjxtf8seZoQYAABhgBOoOyyTCkQ8/UZMklfwxOtQAAAADjEDdYa0Zaq8ZqAve\niFQ6IzUacZYFAACAiBCoO6w18uElKpKkRRuR5KSl+RirAgAAQFQI1B3W6lCbF85QzykfXiidjqsk\nAAAARIhA3WGtDrUsDNSnXfP4cQI1AADAQCJQd1jrocSlelm5VEKzDQI1AADAICNQd1jCSyjlpVSq\nlzQa+DpZz4YXCNQAAAADiUAdgUwyo3KtrNGMrxOV5ggIgRoAAGAgRRqozex6M3vczJ40s4+c456f\nNrNHzewRM/vjKOvpliAZqFRse4NqAAAgAElEQVQraTRI6ng1HAFR+Uy8RQEAACASyag+2MwSku6Q\n9AZJ05IeNLO7nXOPrrjnIkkflfRq59xpM9sVVT3dFCSD5Q71c/N1yc+Fe1EDAABg4ETZoX6lpCed\nc0855yqS7pJ045p7/rOkO5xzpyXJOXciwnq6ZnnkI/A1X65KwQ5GPgAAAAZUlIF6r6Qfrng93Vxb\n6WJJF5vZP5nZfzez6yOsp2uWRz4ySc2XagRqAACAARbZyIck22DNbfDzL5J0RNI+Sf9gZi9zzq2a\njzCzD0j6gCRdcMEFna+0wzKJjAq1gkYDXwvlqlwwLiNQAwAADKQoO9TTks5f8XqfpGc2uOf/cc5V\nnXPfk/S4woC9inPu8865w865w1NTU5EV3Ckrd/loOKmWGmOGGgAAYEBFGagflHSRmR0ws5Skd0q6\ne809X5H0P0qSmU0qHAF5KsKauqI18jGSCf8DoJIaY+QDAABgQEUWqJ1zNUm3SLpP0mOSvuSce8TM\nbjOzG5q33SdpxswelfR3kv5n59xMVDV1y/IuH4EvSSolRsNA7dZOvAAAAKDfRTlDLefcvZLuXbP2\niRXfO0m/0vw3MFaOfEhSMTEi1ZekaklKZWOuDgAAAJ3ESYkRWHmwiyQt2kh4gbEPAACAgUOgjkAm\nkVHN1ZRNhRudzCsXXiBQAwAADBwCdQQyyfC48VSqJkk6o3x4gePHAQAABg6BOgJBMpAkJRNVSdJM\nnQ41AADAoIr0ocRh1QrUNVdRNpXQTD0VXiBQAwAADBw61BFojXyEx4/7OlELAzaBGgAAYPAQqCPQ\n6lC3dvo4teRLnk+gBgAAGEAE6ghkEmGHulwP96KeX6pJwTiBGgAAYAARqCPQ6lC3TkucL1elYIdU\nYpcPAACAQUOgjsCqkY9MUvOlWjNQ06EGAAAYNATqCLQeSmx1qOdKVQI1AADAgCJQR2DtLh8L5apc\nZpyRDwAAgAFEoI7AypGPscBXw0mV1BgdagAAgAFEoI5Aa5eP1rZ5klROjEqVBalejbM0AAAAdBiB\nOgJmpiAZqFwrayzwJUmFxEh4sTwXY2UAAADoNAJ1RIJk0OxQh4F60WsGasY+AAAABkpbgdrMfsTM\n0s3vj5jZh81sPNrS+lsrULc61PPKhxcI1AAAAAOl3Q71n0uqm9lLJP2+pAOS/jiyqgbA2kB92uXC\nCwRqAACAgdJuoG4452qS3ibpf3PO3SrpRdGV1f8yicyqQD1Tz4YXCNQAAAADpd1AXTWzd0l6j6R7\nmmt+NCUNhsAPO9S5VFKeSSdrrUDNXtQAAACDpN1A/V5J10j6lHPue2Z2QNL/FV1Z/a818uF5ptHA\n18lquJUeHWoAAIDBkmznJufco5I+LElmtkPSiHPuv0VZWL9rBWpJGgt8nSk3pAyHuwAAAAyadnf5\nuN/MRs1sp6R/k/QHZva/Rltaf1sbqOdKVSnYQaAGAAAYMO2OfIw55+Yl/aSkP3DOXS3p9dGV1f82\nDNSZcQI1AADAgGk3UCfN7EWSflpnH0rE81gZqEczvuZbHeoyDyUCAAAMknYD9W2S7pP0H865B83s\nxZKeiK6s/pdJZlRtVFVr1DQa+JovM/IBAAAwiNp9KPHLkr684vVTkt4eVVGDIJsMt8lr7UU9V6rK\nBTtkBGoAAICB0u5DifvM7C/N7ISZHTezPzezfVEX18+CZCDpbKCu1p1qqeYuH41GzNUBAACgU9od\n+fgDSXdLOk/SXkl/1VzDOawN1JJUSo5KriFVFuIsDQAAAB3UbqCecs79gXOu1vx3p6SpCOvqexsF\n6oKXDy8y9gEAADAw2g3Up8zsZ8ws0fz3M5Jmoiys37UCdblW1mgQjqov2Eh4kePHAQAABka7gfp9\nCrfMe07Ss5JuUngcOc6hFaiLteJyh3pOdKgBAAAGTVuB2jn3tHPuBufclHNul3PuJxQe8oJz2Gjk\n47QjUAMAAAyadjvUG/mVjlUxgDLJjKTVgfpUPdxKj0ANAAAwOLYTqK1jVQyglR3qkUwYqE/WwjUC\nNQAAwODYTqB2HatiAC0H6mpJCc80kknq9JInJQMCNQAAwAB53pMSzWxBGwdnkxREUtGAWHlSoiSN\nZnzNl5rHj5fZ5QMAAGBQPG+gds6NdKuQQeMnfCUtuRyoW8ePK9jBtnkAAAADZDsjH3gBQTJQuV6W\ntDZQM/IBAAAwKAjUEQqSwQYd6nECNQAAwAAhUEco8AOVqmcD9XyZQA0AADBoCNQRyiQyZx9KDJLM\nUAMAAAwgAnWE1o58lKsN1dLjUq0kNTvXAAAA6G8E6gitDdSSVEyMhhfpUgMAAAwEAnWEgmSgYq0o\nSRptBuqC19yJkDlqAACAgUCgjlDgByrXzm6bJ0kLRqAGAAAYJATqCG008jHncuFFAjUAAMBAIFBH\naGWgbo18nG4Fao4fBwAAGAgE6gi1ArVzTuPNQH2yFoQX6VADAAAMBAJ1hIJkICenpfrS8sjHyUpK\nsgSBGgAAYEAQqCMUJMNudKlWUjLhaSST1JlSrXm4C4EaAABgEBCoI7QyUEvSeNZvnpbI8eMAAACD\ngkAdoXWBOkjpdLHC8eMAAAADhEAdoVagbu1FPZ71daZYZeQDAABggBCoI9QK1K3TEsezqebIB4Ea\nAABgUBCoI7R+5MPXGUY+AAAABgqBOkKZZEbS+ocSG5lxaWlOqtfiLA8AAAAdQKCO0PpdPlJqOGkp\nORreUJ6LqzQAAAB0CIE6QhuNfEhSwRsJb+D4cQAAgL5HoI5QNpmVtHrkQ5LmLR/ewIOJAAAAfY9A\nHaGNZqgl6YzLhTcQqAEAAPoegTpCnnnKJDIr9qFOSZJmHR1qAACAQUGgjliQDNbNUJ+qhbPVBGoA\nAID+R6CO2MpAPdYM1CeqBGoAAIBBQaCOWCaZWQ7UyYSnkXRSs6WGlB7lcBcAAIABQKCOWJAMlo8e\nl6TxnN88fnycDjUAAMAAIFBHLEgGKlVLy6/Hg9SK48cJ1AAAAP2OQB2xlTPUUrh13plSlUANAAAw\nIAjUEVsbqMcCX2eKVSnDyAcAAMAgIFBHLEgGKtfLy693ZFeMfHD0OAAAQN8jUEcsSAYqVlc8lJgN\nH0p0mebIh3MxVgcAAIDtIlBHLJ/Kq1gtyjWD81jgq+Gksj8qNWpSZTHmCgEAALAdBOqI5fycaq6m\npfqSpLPHjxcSI+ENzFEDAAD0NQJ1xPJ+XpK0WA070Tuy4WmJCwrXCdQAAAD9jUAdsZyfkyQVqgVJ\n4Qy1JM0RqAEAAAYCgTpiazvUY0E48jHbCIM2x48DAAD0t0gDtZldb2aPm9mTZvaRDa7fbGYnzeyb\nzX8/H2U9ccinwkBdqKzuUM/Us+ENdKgBAAD6WjKqDzazhKQ7JL1B0rSkB83sbufco2tu/VPn3C1R\n1RG31shHq0M9HoSB+niVQA0AADAIouxQv1LSk865p5xzFUl3Sboxwp/Xk1ojH60Z6mTC00g6qZmK\nJyUzBGoAAIA+F2Wg3ivphyteTzfX1nq7mX3LzP7MzM6PsJ5YtEY+FioLy2tjWV9zHD8OAAAwEKIM\n1LbB2tpjAf9K0n7n3BWS/lrSH274QWYfMLOjZnb05MmTHS4zWms71FI4R32a48cBAAAGQpSBelrS\nyo7zPknPrLzBOTfjnFtqvvw/JF290Qc55z7vnDvsnDs8NTUVSbFRSSVS8j1/eYZaknZkUzpTqoaB\nml0+AAAA+lqUgfpBSReZ2QEzS0l6p6S7V95gZi9a8fIGSY9FWE9s8n5+TYc6pdOFZoeakQ8AAIC+\nFtkuH865mpndIuk+SQlJX3TOPWJmt0k66py7W9KHzewGSTVJs5JujqqeOOX83KoO9c6sr9lWoH72\nmzFWBgAAgO2KLFBLknPuXkn3rln7xIrvPyrpo1HW0AvyqfzyPtSStDOX1ny5pnpmTAk61AAAAH2N\nkxK7YF2HOhfuRV1KjEjVolRbOtdbAQAA0OMI1F2wdoZ6Zy4tSVr0RsIFHkwEAADoWwTqLljbod7R\n7FDPKdxSjwcTAQAA+heBugtGUiOrOtQTzQ716UZ4LLlKs3GUBQAAgA4gUHdBzs9psbK+Q32q0exQ\nF2fiKAsAAAAdQKDugryfV6VRUaVekRQe7CJJz9aaM9SF/jr9EQAAAGcRqLsg54ejHa05aj/haSzw\n9UylOfKxSKAGAADoVwTqLsinwtGO1XtRp3Sy5KTMOB1qAACAPkag7oK1HWopDNSzhYqUmyJQAwAA\n9DECdRfk/bBDvWrrvGwzUOd3EagBAAD6GIG6C1qBevXWea0O9SSBGgAAoI8RqLtgw5GPfEqnixW5\nHB1qAACAfkag7oINH0rMplStOy2ld4YnJdarcZUHAACAbSBQd8FGM9Q7c+Fe1IXkjnChcKrrdQEA\nAGD7CNRdkE6klbTkqhnqVqA+442HC4UTcZQGAACAbSJQd4GZKZfKaaGysLzWCtSzGgsXmKMGAADo\nSwTqLsn7+Q071CddK1Az8gEAANCPCNRdkvNzG85QP1sL56u1yMgHAABAPyJQd8naDnU2lVA66el4\n2ZcSaUY+AAAA+hSBukvWdqjNLDx+vFjltEQAAIA+RqDukrUdaikc++C0RAAAgP5GoO6SXCqnxcri\nqrWzgXqKQA0AANCnCNRdMuKPPE+Hepe0SKAGAADoRwTqLsn5OZXrZVUbZ48Y35FdM/LhXIwVAgAA\nYCsI1F2ST4Xb4xWrxeW1iVxKi0s11bKTUqMqlefiKg8AAABbRKDukpyfk6TVe1Hnw72oFxM7wgXm\nqAEAAPoOgbpL8n7YoV75YOLObBio57zxcIFADQAA0HcI1F2yYYe6eVriKTWPH+e0RAAAgL5DoO6S\nVod65U4fE/m0JOlEfSRcoEMNAADQdwjUXZJLhR3qhcrC8tpUM1A/U8lKMqlwKo7SAAAAsA0E6i4Z\nTY1KWh2oR4OkUglPJ4p1KbtTKjDyAQAA0G8I1F0ylgrnpM8snVleMzNN5FM6tdA8LZEZagAAgL5D\noO4SP+Er5+c0t7R6r+nJfFqnFpekkT3S4vGYqgMAAMBWEai7aCw1tkGgToWBenSvNP9MTJUBAABg\nqwjUXTSWHls18iGt6FCPnictPCfVazFVBwAAgK0gUHfReHpcc5U1HeqRtGYWK2qMnCe5Og8mAgAA\n9BkCdReNpTca+Uir1nAqpHeFC4x9AAAA9BUCdRdtPPIRnpY4m5gKF+aPdbssAAAAbAOBuovG0+Oa\nX5pXwzWW11qHuxy3neECHWoAAIC+QqDuorH0mJzcqsNdJkeagbqSlZIZOtQAAAB9hkDdRePpcUmr\nD3eZbHaoTxUq4U4fdKgBAAD6CoG6i8bS4WmJKx9MHA98JTxjL2oAAIA+RaDuolagXtmh9jzTRK55\n/PjoeYx8AAAA9BkCdRe1Rj7Oefz46HnS/LNSo7HR2wEAANCDCNRddM5APZI+O/LRqErFU3GUBwAA\ngC0gUHdR3s/LZBvuRX1qsTnyITH2AQAA0EcI1F2U8BIaTY+uC9RT+bROLi7JjbQCNQ8mAgAA9AsC\ndZe1DndZaTKfVqXW0GKG48cBAAD6DYG6y8ZS648fn2geP36yPiJ5PiMfAAAAfYRA3WVj6fWB+uzh\nLjVp9EV0qAEAAPoIgbrLxtPjmq+sH/mQdHanjzk61AAAAP2CQN1lG3aoR8KRj7N7UROoAQAA+gWB\nusvG0mMqVAuq1qvLazuzKZlJpxZagfoZybkYqwQAAEC7CNRdtny4S+Xs4S7JhKed2ZROLlak0X1S\nfUkqzsZVIgAAADaBQN1lY+kxSc9z/PjY3nBh7ululwYAAIAtIFB3WStQr52j3jWa1on5srRjf7hw\n+gddrgwAAABbQaDusnN1qPeMZnR8fkkavzBcOP39LlcGAACArSBQd9nyDPWaQL17NKOTi0uqp0ak\nYCeBGgAAoE8QqLusFajXjnzsHsuo3nDhHPWO/QRqAACAPkGg7rJsMqukJTcc+ZCk5+bKBGoAAIA+\nQqDuMjPb8HCX5UDdejBx7odSox5DhQAAANgMAnUMxtPj62eox8Ljx4+3AnWjxomJAAAAfYBAHYOx\n9Niqg10kaTKXVsKzsyMfEmMfAAAAfYBAHYPx9LhOl0+vWvM8066RdLh1HoEaAACgbxCoYzARTGi2\nvP5o8d2jmXDkY3Sv5CUJ1AAAAH2AQB2DyWBSp8unVW1UV63vGc2EDyUmktLY+QRqAACAPkCgjsFk\nMCknp9nS6i71nrGMjs+VwxdsnQcAANAXCNQxmAwmJUmnyqdWre8ezWhhqabCUo1ADQAA0CcI1DFo\nBeqZ0syq9T3NrfOW96Iuzkjl+W6XBwAAgE0gUMdguUNdWtOhHgkPdzm+cuu8Mz/oZmkAAADYJAJ1\nDCaCCUkbBOqxZqBeYC9qAACAfkGgjkE6kdZIamRdoF4+fnyOvagBAAD6BYE6JpPB5LpAnUsnNZJO\nhntRB+NSZlya/V5MFQIAAKAdBOqYTAaT6x5KlMKxj+daW+dNvEQ69d0uVwYAAIDNIFDHZDKzvkMt\nrTjcRZKmXkqgBgAA6HEE6phMZid1snRy3fqu0XQ48iFJUxdLi8el0ukuVwcAAIB2RRqozex6M3vc\nzJ40s488z303mZkzs8NR1tNLJoNJlWolFavFVet7RjM6sbCkesNJk5eEiyfpUgMAAPSqyAK1mSUk\n3SHpzZIuk/QuM7tsg/tGJH1Y0r9EVUsvOtde1HvGMqo3nGYWl8IOtSSderzb5QEAAKBNUXaoXynp\nSefcU865iqS7JN24wX3/i6TfklSOsJaeM5nZOFC/aCyQJD0zV5bGL5QSaekkgRoAAKBXRRmo90r6\n4YrX0821ZWZ2laTznXP3PN8HmdkHzOyomR09eXL93HE/OtfhLvt2hIH62OmS5CWkyYt4MBEAAKCH\nRRmobYM1t3zRzJP0WUn/5YU+yDn3eefcYefc4ampqQ6WGJ9zjXzsbQbq6dPN2erJi+lQAwAA9LAo\nA/W0pPNXvN4n6ZkVr0ckvUzS/Wb2fUk/KunuYXkwcTw9roQl1gXq0YyvscDX9OlSuDB1iXTmaala\niqFKAAAAvJAoA/WDki4yswNmlpL0Tkl3ty465+acc5POuf3Ouf2S/rukG5xzRyOsqWckvIR2ZnZq\nprz+cJe948HZDvXUJZKcdOqJ7hYIAACAtkQWqJ1zNUm3SLpP0mOSvuSce8TMbjOzG6L6uf1ko+PH\npXCO+tiZZke6tXUec9QAAAA9KRnlhzvn7pV075q1T5zj3iNR1tKLJoNJnSyuf8hy346s/vHJU3LO\nySZ+RDKPOWoAAIAexUmJMZoMJjVTWj/ysW9HoGKlrtPFqpRMSzsOsBc1AABAjyJQx2gymNRMeUYN\n11i1vm/tTh9Tl9ChBgAA6FEE6hhNBBOqu7rOLJ1Ztb5vR1aSzu70MXmxNPMfUr3a7RIBAADwAgjU\nMXqhvaiPtQL17sulRpWdPgAAAHoQgTpGU0F4SM3aBxPHAl8jmeTZkY89B8Ovz/17N8sDAABAGwjU\nMdqd2y1JOl48vu7avh3ZsyMfExdJibT03Le6WR4AAADaQKCO0a5gl0ym44WNAnVwNlAnktLuy+hQ\nAwAA9CACdYz8hK+JYELPFZ9bdy0M1EU558KFPQfDQN16DQAAgJ5AoI7Z7uzuc3SosypU6porNXf2\n2HOFVJqV5p/pcoUAAAB4PgTqmO3J7dFzhY071NKKrfN4MBEAAKAnEahjtie35xwPJa453GX35eFX\nAjUAAEBPIVDHbHd2txari1qsLK5a3ze+5nCX9Ii088Xs9AEAANBjCNQx25PbI0nrxj5Gg6RG0kn9\ncLa44uaDdKgBAAB6DIE6ZruzG+9FbWY6f2dWT68N1Ke/J5XnulkiAAAAngeBOmbn6lBL0oUTWf1g\nVaC+Ivx6/JFulAYAAIA2EKhjNpWdCg932eDBxAsncpqeLaneWLEXtSQ9yxw1AABAryBQx8z3fE0G\nk+fsUFfqDT0713wwceRFUm6X9MzDXa4SAAAA50Kg7gHn2ov6wp3hTh9PzzTHPsykfYel6Qe7WR4A\nAACeB4G6B+zO7t545GMyJ0n6/syKOeq9V0uz/yEVZ7tVHgAAAJ4HgboHtDrUzrnV66MZpRKefjBb\nOLu473D49di/drFCAAAAnAuBugfszu5WsVbUYnX14S4Jz7RvZ3B25EOSznu5JJOOHe1ukQAAANgQ\ngboHPN/WefsncqtHPjKj0tRLpWkCNQAAQC8gUPeAVqDeaI76gp1ZPT1TWD0Osu9q6dhD0poREQAA\nAHQfgboHtE5LPNfWeYVKXacWK2cX9x6WSrPS7FPdKhEAAADnQKDuAZPZSXnmnXPkQ5Ke3vDBxIe6\nUR4AAACeB4G6B/ier8nM5MYjHxPhXtQ/WDlHPXWp5GeZowYAAOgBBOoesSe/R88Wnl23vm9HILM1\ne1EnktJ5V7HTBwAAQA8gUPeIvbm9OrZwbN16OpnQeWOBnp4prL6w77D07LekSnHdewAAANA9BOoe\nsXdkr54rPKd6o77u2oUTWf1gdk1wvuBVUqPKHDUAAEDMCNQ9Ym9+r2qutvER5BPZ1TPUknTB/yDJ\npKe/0Z0CAQAAsCECdY/YN7JPknRscf3Yx4UTOc0WKporVs8uBjukXZdJP/jnbpUIAACADRCoe8Te\n/F5J0vTC9LprF+/OS5K+e2Jh9YULr5F++IBUr0VeHwAAADZGoO4Re3J75Jmn6cX1gfqSPaOSpMef\nWxuoXyVVC9Jz/9aNEgEAALABAnWP8D1fe7J7Nhz5OG8so5F0cn2gvuBV4dcfMEcNAAAQFwJ1D9k7\nsvHWeWami/eM6PHjawL16IukHft5MBEAACBGBOoesje/d8MOtSRdvHtE3z2+IOfc6gsXvCoM1GvX\nAQAA0BUE6h6yN79XJ0snVa6V1127ZHdeZ4pVnVhYWn3hwmuk4ox06rtdqhIAAAArEah7SGunj2cK\nz6y7du4HE18dfv3+P0ZaGwAAADZGoO4hy3tRbzBHfcmeEUnSd9fOUe98sTRynvS9v4+8PgAAAKxH\noO4hrQ71RnPUO3MpTY2k9Z21HWoz6cWvCQN1o9GNMgEAALACgbqHTAaTSnmpcz6YeEnzwcR1Dlwn\nlWalE49EXCEAAADWIlD3EM+8cOu8cwXqPWGgbjTW7Ohx4DXh16f+v4grBAAAwFoE6h6zN793w+PH\npbBDXa429PRscfWFsb3SxEuYowYAAIgBgbrH7M3v3fD4cUm6uPlg4roDXqRw7OMH/yTVq1GWBwAA\ngDUI1D1mX37f/9/enYfJcRZ2Hv++dfQ190ijy5KskS0JS8iSQZaxDfjAARsIONx2AgQSiAnEEJZk\nSciGwJKFwAYIGyCcC+aIOQyJWYzB+MA4xod8yZbkS5YsyZJGI43m7OnuOt79o7pbM9KMrpnWXL/P\n8/RT1VVvV7+tmrZ/71HV9JX66C31HrFv+dx6jIEte47cR/tFUOqH3Q+dglqKiIiISIUC9SRTuXXe\nzt6dR+zLpTzOaKvnsed6jnzhkpckS82jFhERETmlFKgnmfamdgC29W4bcf/ZC5t4ZFfPkT9BXjcL\n5q2GbQrUIiIiIqeSAvUks6hhEa5x2dYzSqA+rYnOviJ7e4/8eXKWXgw77oFif03rKCIiIiKHKFBP\nMik3xcKGhaMH6kXNADyyc4RpH2e8DOJAP0MuIiIicgopUE9C7Y3towbqlfMb8RzDxl3dR+5cfD74\nOdh6a41rKCIiIiIVCtSTUHtTOzt6dxDF0RH7Mr7LinkNbNw1Qg+1n4ElL4anFahFREREThUF6kmo\nvamdUlxi98DuEfefvbCZjbu6j7wwEeDMy6BrK3SN3MMtIiIiIuNLgXoSqt7pY5RpH2sWNtFbCNl+\nIH/kzjNeliw17UNERETklFCgnoSWNC4BRg/Uqxc2AYw8j3rWGdC8GJ6+rVbVExEREZEhFKgnoeZM\nM62Z1lED9fK5DaQ9Z+Q7fRiTTPvYdqd+hlxERETkFFCgnqSWNC4ZNVD7rsOqBY0j91BDMu2j1Jfc\nk1pEREREakqBepJqb2pne+/2UfevWdTMY7t7KIXxkTuXXgRuCp68uXYVFBERERFAgXrSam9qp6vQ\nRXdh5F7o9UtaKQQxjz43wv50Q3L7PAVqERERkZpToJ6kKnf6GK2Xen17KwD3PNM18gGWXwEHnob9\nT9eieiIiIiJSpkA9SbU3Hv3WebPq0yybU8+920YJ1CsuT5ZP/qIW1RMRERGRMgXqSWpB/QJ8x+eZ\nnmdGLXPe0lYe2N5FGI0wj7p5McxZBU9o2oeIiIhILSlQT1Ku43Jm85k80fXEqGXOa5/FQCli0+7e\nkQusuBx2/A4GD9aoliIiIiKiQD2JnTXrLLZ0bRn5J8aB88rzqO/ddmDkAyy/AmwET/26VlUUERER\nmfEUqCexla0r6S52s2dgz4j75zRmaJ9dx72jXZh42guhrg2euKmGtRQRERGZ2RSoJ7GVs1YCsPnA\n5lHLnNfeyn3bu4jiEXqxHQdWvBKe+hUEhVpVU0RERGRGU6CexJa3Lsc17tED9dJW+gohW/aMMo96\n5Wuh1A9bb61RLUVERERmNgXqSSztpjmj+YyjBuoXLZ0FwN1b949coP2lkG2Bzf9ZiyqKiIiIzHgK\n1JPcylkr2Xxg86gXJs5vyvK8eQ3c9vi+kQ/g+vC8V8ETv4CwWMOaioiIiMxMCtST3MpZKzlYPEhH\nvmPUMpc+bw73bz9Iz2AwykGuhGIvbL29RrUUERERmbkUqCe5yoWJmw5sGrXMy86aQxRb7nyyc+QC\n7RdBpgk2/0ctqigiIiIyoylQT3IrWlYc88LEtYtaaMn53D7atA8vBSteBY/fpGkfIiIiIuNMgXqS\ny3gZ2pvajxqoXcdw8Yo53P7EvpFvnwew6g+g2ANP3VKjmoqIiIjMTArUU8CxLkyEZB71wXzAwztH\n+ZnxMy5NfuTlkX+vUT+vIyAAACAASURBVC1FREREZiYF6ilg9ezVdBW62NW/a9QyL13ehuuYo9zt\nw4PVb4Infwn5UX5ZUUREREROmAL1FLBu7joANuzdMGqZpqzPutNb+OWmjtF7stdeBXEAj/64FtUU\nERERmZEUqKeAM5rPoCXdwoaO0QM1wJXnnMbT+/p5aGf3yAXmrYa5qzXtQ0RERGQc1TRQG2MuN8Y8\nYYx52hjz4RH2X2OMedQY87Ax5i5jzMpa1meqMsawbt467tt731HnUf/+mgXkUi4/vH/n6AdbexXs\nfhA6n6hBTUVERERmnpoFamOMC3wRuAJYCVw1QmD+vrV2tbV2LfBp4LO1qs9Ut37eevYO7D3qPOr6\ntMerVs/nxkd2018MRy60+o1gXHjouzWqqYiIiMjMUsse6vXA09baZ6y1JeB64LVDC1hre4c8rQNG\n736d4c6ddy5w9HnUAG9Zv4h8KeLnG3ePXKB+Dqy4IgnUweB4V1NERERkxqlloD4NGDr3YFd52zDG\nmPcaY7aS9FBfO9KBjDHvNsZsMMZs6Owc5dcAp7mlTUtpzbRy/977j1ruBYtbOHNOPT842rSP866B\nwS5dnCgiIiIyDmoZqM0I247ogbbWftFaewbw34G/G+lA1tqvWmvXWWvXtbW1jXM1pwZjDOvmHnse\ntTGGN69bxIM7unmqo2/kQkteDHNWwn1fgaMcS0RERESOrZaBehewaMjzhcAo8xCAZErIlTWsz5R3\n7rxz6ch3sKtv9HnUAH/wgtPwXTN6L7UxsP7dsPdR2HFPDWoqIiIiMnPUMlDfDywzxrQbY1LAW4Ab\nhxYwxiwb8vRVwFM1rM+Ut37eegDu23vfUcvNrk/zeyvn8pOHnqMYRiMXOvtNkGmGe/9tvKspIiIi\nMqPULFBba0PgfcAvgS3AD621m4wxHzfGvKZc7H3GmE3GmIeBDwJvr1V9poP2pnbm5uZy5647j1n2\nTesW0TVQ4tebR/nlxFQdvOCtsOVncPDZca6piIiIyMxR0/tQW2tvstYut9aeYa39x/K2v7fW3lhe\nf7+1dpW1dq219hJr7aZa1meqM8ZwyaJLuHv33QyGR79Dx0uWtbGgKcMPNhzl4sQX/Tk4Ltz1uXGu\nqYiIiMjMoV9KnGJedvrLKEQF7t5991HLuY7hjesW8dunOtl1MD9yocYFcM5bk1vo9Rx9XraIiIiI\njEyBeop54dwX0phq5LYdtx2z7BvXLQTgRxuOEpZf/AHAwn/9yzjVUERERGRmUaCeYnzH56KFF/Gb\nXb8hjEf5NcSyhS05Ll7exnfueZaB0X45sXkxrLkKHvg29O2tQY1FREREpjcF6ino0sWX0lPs4cGO\nB49Z9tqXLaNroMR1vzvKhYcv+SDEIdz5v8exliIiIiIzgwL1FHTBggtIu2lu3XHrMcues7iFS1a0\n8ZU7t9JXCEYu1LoU1r0DNnwTOp8Y59qKiIiITG8K1FNQzs9x/oLzuXXHrcQ2Pmb5D1y2nO58wLfv\n3j56oYv/BlL18Kv/MX4VFREREZkBFKinqFe2v5KOfAf37Dn2Lx2uWdTMy543h6/9dhs9g6P0UtfN\nhpd+CJ76JWw99gWPIiIiIpJQoJ6iLl18KY2pRn761E+Pq/wHX76cvkLA5255cvRC5/0ZtCyBm/8W\nwtL4VFRERERkmlOgnqLSbppXL301t+64le5C9zHLr1rQxB+edzrX/W47m3b3jFzIS8Pln4LOLbqN\nnoiIiMhxUqCewl637HUEccDPt/38uMp/6OUraM6l+Oh/biKO7ciFVlwBz3893Plp2Pf4ONZWRERE\nZHpSoJ7CVrSuYOWslfzkqZ9g7SgBeYimnM+HL38eG549yI8fPMqPvVzx6eQCxf98L8TRONZYRERE\nZPpRoJ7iXnfm63jy4JNsPrD5uMq/4YULOXdJCx//2WZ2HBjlJ8nrZieh+rkNcPcXxrG2IiIiItOP\nAvUUd8XSK8h6Wb675bvHVd5xDJ9901qMgWuvf4ggGuW2e6vfACuvhNs+AbseGMcai4iIiEwvCtRT\nXGOqkdcvez03b7uZvQPH99Phi1pzfPJ1q3l4Zzef//Uod/0wBn7/X6BhPtzwTij0jmOtRURERKYP\nBepp4K0r34rF8p3N3znu17z67AW8ad1CvnTHVu7eun/kQtlmeP3XoXsH/L+/hOOYpy0iIiIy0yhQ\nTwML6hfwiiWv4MdP/pje0vH3JP/Da1bRPruOv/zBw3QNjHLf6cUvgks+Ao/9WPOpRUREREagQD1N\nvOP57yAf5vnREz867tfkUh5feMs5HBwI+Osfbxz9TiEv+W/JfOpbPgpP/mqcaiwiIiIyPShQTxPP\na30e588/n+s2X0c+GOXuHSN4/mlN/PXlK/j1lg6+cde2kQsZA1d+Ceathhv+BDqO744iIiIiIjOB\nAvU08r5z3kdXoYtvb/72Cb3unRe284pVc/nHm7bw680dIxdK1cFbvg9+Dr77umRetYiIiIgoUE8n\nZ7edzWWLL+Nbj32LrkLXcb/OcQyfe/NaVp/WxLXXP8Rjz43y0+TNi+CPboBSHr7zOhg4ME41FxER\nEZm6FKinmWtfcC3FqMhXN371hF6XS3l8/e3raMmleMe37ueZzv6RC857Plx9PfTshO/+AeSPP7iL\niIiITEcK1NNMe1M7V555JT944gfs7N15Qq+d05DhW+84lzi2XPW1e9i+f2DkgqdfAG/+Lux7HK57\njXqqRUREZEZToJ6G/nztn5NyUnzyvk+OfueOUSyb28D33/UigigJ1dtGC9XLfg+u+j7sfwq+/fvQ\nv28cai4iIiIy9ShQT0NzcnN479r38tvnfsttO2474devmNfA9/70PIphzBu+fDeP7OweueCZl8HV\nP4CD2+AbL4euUe4SIiIiIjKNKVBPU1efdTXLW5bzyfs+eUK30as4a34jP77mfLIpl6u+dg+3PT7K\n3T+WXgxv/xkUupNQveeRMdVbREREZKpRoJ6mPMfj7170d3TkO/jSw186qWMsbavnJ39+Ae2z63jn\ntzbwtz99lL5CcGTBhevgnb8ENwXfvAIev2mMtRcRERGZOhSop7Fz5pzDG5e/kes2X8eGvRtO6hhz\nGjL8+JoLePdLl3L9fTt4+efu5N5nRrgIsW0FvOvWZHn91XDX5+EE52+LiIiITEUK1NPch9Z9iIUN\nC/nIXR+hr9R3UsfIplz+9pVnccN7LiDju1z99Xv58h1biePDAnPDPHjHTbDqSvj1R+GHb4PCKPe0\nFhEREZkmFKinuZyf43+9+H+xN7+XT933qTEd65zFLdz4vgu5fNU8/unmx3nXdRvozpeGF/Kz8Ib/\nC7/3P+Hxn8NXL4Y9G8f0viIiIiKTmQL1DLB2zlretfpd3Lj1Rm7ceuOYjtWQ8fnXq8/hY69ZxZ1P\ndfKqL9zFw4ffBcQYuPBa+OOfQzAIX78MHvi2poCIiIjItKRAPUNcs+Yazp13Lh//3cfZcmDLmI5l\njOHtFyzhR9dcAMAbvnw3/3Tz4wyWouEFTz8f/uy3yfJn18JP3q1fVhQREZFpR4F6hvAcj8+89DM0\np5v5yzv+ku7CKPeWPgFrFzXz82tfzJXnnMaX79jKZZ/9Db94dM/wH5Opb4M/+glc/Dfw2A3wxfXw\n2E/UWy0iIiLThgL1DDIrO4vPXvxZ9uX38YE7PkAxKo75mM25FP/7jWv44Z+dT33a4z3fe5Arv/hf\n3P30/kOFHBcu/jC8+w5oPA1+/A7496ugZ9eY319ERERkoilQzzBnt53NJy78BA90PMBf/eavCONw\nXI67vr2Vm97/Ej79hrPp7Cty9dfv5a3fuJfHnhtyl4/5Z8Of3gov/wQ8cwd88Ty472sQx+NSBxER\nEZGJYOwUG3pft26d3bDh5O6pLId8b8v3+NR9n+K1Z7yWj1/4cRwzfm2rQhDx3Xue5V9vf5rufMAr\nVs3lLy5dxvNPazpUqGsb/L+/hGduh4Xr4TVfgDlnjVsdRERERMbKGPOAtXbdMcspUM9cX3r4S3z5\nkS/z6qWv5uMXfhzf8cf1+L2FgK/f+Qz/9+7t9BVCLlrexlXrF/Oys+bgu04yj3rjD+DmD0OxH9a/\nC17yIaibNa71EBERETkZCtRyTNZavv7o1/nCQ1/g4oUX85mLPkPGy4z7+/QWAq67ezvfuedZOnqL\nzK5P8/oXnsab1y1iaVs9DOyHX/8DPPw9SNXDiz8A570HUrlxr4uIiIjI8VKgluP2g8d/wD/e+4+s\naVvD5y/5PLOytekhDqOY3zzZyfX37+S2x/cRxZb1S1p587mLeOXq+WS7n4Rffwye/AU0LIBL/gbW\nXAXu+Paci4iIiBwPBWo5Ib/a/is+ctdHmJWdxf+59P+wrGVZTd9vX2+BGx58jh/cv4PtB/I0pD0u\nPWsOr1g1j0syT5G942Pw3AZoXAgveg+88O2QbqhpnURERESGUqCWE/bY/sf4i9v+goFggA+t+xBv\nXP5GjDE1fU9rLfdu6+KGB3Zxy5YOuvMBac/hJWfO5u1tT/Kivd/D3/lfkG6Cde+A866Bxvk1rZOI\niIgIKFDLSeoY6ODv7/577t59NxcuuJCPXfAx5tbNPSXvHUYx923v4lebOvjVpr3s7ingOoa3LOjk\nT92fsWTfrRjjwJmXwZq3wIpXgpc+JXUTERGRmUeBWk6atZYfPvFD/vmBf8ZzPD5y3kd4Zfsra95b\nfXgdHn2uh19u2ssvN3Xw9L5+FpsO3t98F6+I7qS+1InNzca84G1Jz3Xz4lNWNxEREZkZFKhlzJ7t\nfZaP3PURHul8hEsWXcIHX/hBljQtmZC6bO3sr4brR3d28WLnUf40czsvjjfgEFOYv5702jdiVl0J\n9XMmpI4iIiIyvShQy7iI4ohvbfoWX9n4FUpRiTcsfwPXrLmG2dnZE1anPT2D/HrLPu7ZeoBnn3mc\niwq38/vu73ies5MYh45Z63FXvZa2Na/AtC6FU9izLiIiItOHArWMq/2D+/m3R/6NG568Ad/1+eNV\nf8zbV72dOr9uQutlrWVr5wD3bjvAzsc3MOfZm7gk/C3tTkdSb28ezy14Of7aN7H0+eeTSXkTWl8R\nERGZOhSopSae7X2Wf3nwX7jl2VtoSjfxh8/7Q64+62qa0k3HfvEpYK1lx4EBNj36EINP3Mq8fb9l\nffQQvol4zs7mqcxq+ueeS92yl7D8+S9kQXPulM4NFxERkalDgVpq6tHOR/nqo1/ljp13kPNyvGnF\nm3jbyrfRlmub6KodoXPfbvbd+yOcbXcwv/shmuODAHTZeh43Z9JZv5xi29n4Z15E++LFLJ9bT049\n2SIiIjOeArWcEk8efJJvPPoNbt5+M57xuKL9Ct6w/A2saVszOXt+rSXYv5WOR29ncOtd1B14jLbC\ndnxCYmvYaJfyQLycjtxywjmraFy0mhULWlgxr4HTZ9XhOpPwM4mIiEhNKFDLKbWzdyff3vxtfrb1\nZ+TDPGc0ncHrlr2O15zxGpozzRNdvaMLS8S7H6bnsZth623UH9yMHxcBKFqPp+xCttt57DFtFBrb\niec8n8bFq1m+cA4r5jUwu173whYREZmOFKhlQuSDPDdvv5kbnryBjfs34js+L134Ui5fcjkvXfhS\ncn5uoqt4bHEEB7bC3o0Ezz1CYdcjcHA7ufxzuDYEILKGZ+wCttjFPOsvZbDlLNILVnH6/DmcuWA2\nS+bNoj7jT/AHERERkbFQoJYJ9+TBJ/npUz/l5u03s39wP1kvy0ULL+LyJZezfv56GlINE13FExNH\ncHA7dDzGwI6HKezaSGr/JhoKe44ouse28rCzkp25VYTN7fiz22mYewYL21pY1JplQXMW33VO/WcQ\nERGR46ZALZNGFEc8uO9BfrHtF9zy7C10F7sxGM5oPoM1bWuSx5w1LGlcgmOmYMgc7IaOTcT7n6Kr\nu4cDBw/idG5mbtcGGsMDw4p22GZ22jnssm10pxbg1DWTrWumrrmNXNvptCxoZ+68xbQ1ZjRfW0RE\nZIIpUMukFMQBD3Y8yIP7HuSRzkfY2LmRvlIfAI2pRs5uO7saslfPXk19qn6CazwG1kLfXuh+lrhr\nO317n6bYuQ26nyXdv4uGYgcO8REvK1qfvbTS7bQSpBqJ0s3YbAtOrhWnYS6ploVkZy+mae7ptLbO\nxvPcCfhwIiIi058CtUwJsY3Z3rOdRzofqT62dm/FYjEYzmw5kzVta1jRsoLFDYtZ0rSE+XXzJ+cd\nRE5UHEGpH4r9FHs66NrzDH0dzxIe3IHp3YU3eAC/1EM26qU+7qPOFI84xIBNs8/M4qDbxmCqBSeV\nw03liHOzsQ3z8RvnkKlvJtfQQt3sRTTNmqcftxERETlOCtQyZfWWenms87FqwN7YuZG+oK+6vynd\nxFmtZ7G0aSmLGxezuGExixsXs6B+Ab4zfS8EHBgY4GDnLvr37aBwYCdh93OYvt2kBvaQK3SQDbvx\n4iLpuECTGRjxGAXr00cdkfGIHZ+CW0/Rb6SQnk2hbiFR3Txsqg7r53DrZpFqmkuuoZmmlKXRt9Q1\nt+HmWsGZglNzRERETpACtUwb1lr25fexo28Hz3Q/w5auLWzp2sL2nu3kw3y1nGtc5tfNZ3HjYk6r\nP425ubnMrZtbXc7LzZsadxkZB4XBAfo6d9F/cC/5vm4KfQeJe3bj9T+HLfQRhgFxUMAP+siGPbTE\nB5hju3DNsf97EODSTx2x8bGOS2w8Ysej4DXSl57HYGYO1q+HVB0mlcNJ1+Gk6/DS9XiZOvxsPals\nPal0lqzvkPFc0nUNmEwzeKnhb1bshziETBNMh1EJERGZUhSoZdqz1nKgcICdfTvZ0buDHX072Nm7\nk2f7nmVP/x4OFg8e8ZoGv4HmTDOD4SADwQBt2TbWzlnL82c/n9MbTmdRwyJaMi3k/NzUvEByDOKg\nxED3XsLBfqJCP8W+/RS791LK99IfugyEhjh/AC/fiVPsIQpLhGEIUYCJA+rjPubafbTZg2RN6aTq\nMEiafuooOhmabQ/1Nulpj3DIu40Mes0U/CZKqSaCVAthupko04LNtuL5aVKeQ8r3cDP1+Jl6nHQ9\nTrqOTKaO+roMxk0n4dzPKqCLiMgxKVDLjFeMiuwb2Mfe/F468h3sy++jY6CDg4WD5PwcdX4du/p2\n8XDnw3QVuoa91mCo8+uoT9XTkGpgQd0CTm88nbZsG57j4Ts+s3OzmVc3j9Z0a/V4nqP5yQBBEDCY\n76OY76dYXgaFPsLCAGGhn6g4QFQqUoxigshii/24pR68Ui9+0IsX5jlomuhgFsXIkA17yEW91MfJ\no8n20Wz6aaGftAlOuH4lfEomhcHilB+GmKKTJe82UfAawXHBOOSiPuqCLhwb0lu3hP76JVi/Dsf1\nMI6L63k4jofxU7heBs8WSRUO4IUD0LoU07YCz/Nw8/swpX7INEOuFbKtyTLdAMYBTDKnvtADNobc\nLMjNhmwLuPq7EhGZCArUIsepMqVkZ99OdvXvoqfYQ3/QT3+pn/6gn55iD8/1P8eO3h0UosJRj5V2\n09T5deS8JGAf/qgE7zpvyPrQfd6h51kvOz0uvqwBay3FMGawGFLI91HsO0CxVKQYxhSKJYLBfqJi\nP5QGcII8YTFPf6FAcXAQL+gjE3Rj4hJhbAitIYwhjCEV52mMe6izA5g4whDRHdfRaZuIMZxh9tDu\n7CFNgEuMQ4xLjEtEykRA8qM/XTRQsGkWmP3HNY3mWAbdBmLj4cdFXBsQOx6x8YkdH+v6WCeFdVPJ\neqqRKNsKfg4vLuKFebxCF26+E7DQfDo0L8JJ5cBNJQ/HO7Tuesk0m6CQLL0M+BnwskcubQxxkLw+\n25I0FmycvC4OIAqT56kcpOqTR7oe/NyhEYKwCD27oDQALacnIwgiIpOEArXIOIttzGA4SBiHFKMi\nnYOd7B3YS3ehm4FggIFwgHyQT9aD8no4ZL2yfci876MxmGrIHhq+h4byob3inuMlvep+PfWpeur9\nejJeBte4GGNwcHCMQ8bL0JRuojHViO/4Cu3HYK2lFMWUwvIjiikGcXVbMYwohjGlICIoFSjEDqXI\nUAxjwtIg2b5tlEJLj9tKv81gir14xS5SxW78Ujd+2E8Ux4RRTJ/N0BPnCOKYXNhLXdRDfdRDU9wD\nNmIg9gnwcInxCUkT4BPimxCfkBQhjSZPK31kTZFBm2aQFF22kU7bhDGwyOzjNLP/0GuJ8E3y2qFi\nDBEu/mHbx+XfFEPkpIndFH7Qh+HQ/4eCVBOxl0sufDVuEtYdF1NeN44L5dGB5HFovVIW4wxZr2wf\nfrxk3T2szGHbwxIUeyEsJNOE/DpI1SUNBD9Xboj45UaJX173h69XGyw+UP6uVb9zZvj64fsqzx03\neT83palKIqfY8QZqjSOKHCfHONT5ddXnc3JzWDVr1QkfpxLMhwXv8np/0D9qEK8E9t39u4fti21y\nL+vQnlzwSTkpfNdPlo6P7/r4jk/KTR2xbEm3MDs7m/pUPY5xMBgckwR1z/FIu+nqI+NlqtNjfMev\nrme8TNL7jqGr0EVPsYfWTCsLGxaS8TIn9RlqyRhD2nNJn/T9vleMW12GhvtieCjkV9ejiGIQs2vE\nMhFBFNMRWe6JLEEUE8QxYWQJo5ggiomjgDgMKMaGYuRSii3FUokoKJCyRbIE+LYIwSBxWKAYWPpD\nQxQG5KJeGskTY7COR2Q8ipEhwiFHgRxF6s0gdRTImQJpAtIEdNt6dtk28qRZaDpZFHaSoYRrkhEA\nj6g8EmBxicojAgEuBVwsjknKuOUynimvmxivPIIw/DiHHk55dKGyfyRF0gTGJ2WLpDjx6UXjyRoH\n62WJ3QzW9QEHaxwwyeQlHAdjkgfGlPdVnjsY59A+4zhJY6Q6MpFKQr9xwEbJbT1tXF6Wn0O5YZFN\nAr6fS14TR4dGJeIwaVDUtSVTmoybHAebLK1N3stLDR8hicPkOI6bHN/LHHrYGKJSedSj/B6VBg4k\njZ5gMClbaeyk6sBLHypfWRqTjKZkWwBz6LNVPmf536r6GQ9vwMRxuZyrux3JMArUIqdYJZgPDefj\nIYoj8mG+OlWlP+inEBaw1hITE9u4GuZ7ij30lfooxSVKUYkgDihFJcI4HPY8iANKcYkgChgIBtjW\ns43OfCel+OQuOjyWBr8Bz/GGPTJeJultdzMUoyKD4SDAsJDuuR6+SRoDnvGSZWVfuQe/EBYI4gDf\n8Um7aRrTjczJzaE100oURxSjIkEcUIyKxDamJd1Ca7aVjJv08ruOmyzL657xqtsc4zAYDtIf9JN2\n08yrm1c9v0GchDDPeGMeDRga7hvGdKTxV5mG47vOsF/5jGM7JLgfWg+imDCuhHlLGJeX5e1BVH5N\neXupun/0skEcYy1EsSWKLbE9fJnUJ4yPPEYYWaIoxMYRGQ8yLoTGpxg71feMoxA3GsQP87hxEaIS\nJg4xcVB+JOtOHJI2ESkTYmyIG4d45SlBld54g+VQX7QdtuSw7T4RGUpkTJFsUCJHEY8ouQbAJPP/\nner1AHH52HbItqFlouoPSvlEeCYkXR6lSJsQg02OYlwi65BMfEpeZbBkCciYIhlbJE0RnzBpzhiX\nqNy08QlosH24I/xw1VQSGZ+SV4exMW5cwrUhzpCOixgHa1xix8Mab8i6izUesZsictPETopU0Eu6\n2AU2puQ3EHj1gDl0vmyyTBodMbGTIvayWD954OWS/34YwCZ/O8nfR/lvxnjEfg68NE5UxIQFjAHr\nJNO4kuWQURM3GZ00lREZY8qNMZMc2zjlAZTkebLflNsX5XWS58YYcNPJVDDHh6iYTOWqNE4cb8ij\nMgLkEeJQjBxwPVzXxXV9XM/Hcf1D5aIgOVZUgqUXndo/gBOkQC0yTbiOS0OqgYZUbaOWtZYwDrFY\nIhthbbKM4ohCVKAYFZNHmATUIA4I45AwDgnigMFwkMFwEGstLZkWGtONHBhM7tbSXeweVrYyvaY/\n6GcgHCDjZpidnY0xhiAKCG1IKS4xEAwQ2rC6LYwPrQdREmjTXpqUkyKIAwpRgf5SP5baTXnLetlq\nHSCZwpNyU9URgUqv/9DnlVBeig41WNJumqyXJetlq737lQdAKSoR27g6Fcg1LhbL0Ol8OT9HY6qR\njJupNq4gGS2x1mKxyXplWd5mMNX3HPreOS83rB6u4w779w7iIPl79BvIetnqiExkk1DpOR4t9S00\n+A0YY6oNmsFwkFJUIuWmyPkNZNzMtJiSVAwjBkuVQG2GzeaofLogshSCiMEgKVsMI6xNypRCS74U\nMlA+hmPAHRJwXGNwnKTcYBBSDGIcY3AcU21MhLElqjQeyg2OIIrLS0tUbmBE5cZGFNvqMSrvB1Sn\nPHmuIesn08l6CwG9gyFJuCuXJyYX95f/piCKDRGG2IITl3BsgBOVcGyIGweUrEtgHaIwIA7yEBSp\nc0IyToAxLtb1iPAJcAhx8eMiWTtIbKGfHIOk8G2JjC2QtgXStohvS4Q2Gc8olZeOjWmw/TTSlzS+\ncAht8ogw5YZITJYSzaafhiBPiEsJv3wcnxA3aTqYCL88OuKVmxOVh2si0oSkKZEmoId5HLDLiXFo\nKg5Qz2C5mWOqTaB4SHMoRUiWIlny5MxBMpTKjZ3kPAxtllnAIyJHkbQJKFqfAikslKeEReXpXeUp\nXuV1AzjjcI3HyfI4/hAaYXA/enBST3lSoBaRE2KMwXen/g/oBHHAgcEDdBW6qr3WKTdFyk3uhd1d\n6OZA4QClqFRtMEQ2IrQhcRwn63FIZCNiGydB089RCAvsHdhLV6GLlJsi4ybTWCo9/ZXe/6GjA5Xt\nc3JzqPfrSbtpjDHENq4GzUJYYDAc5GDhIHvCPdWe+pSbwhhDPsiTD/JENqqGUFP+X/BgOFgN0ZOJ\n7/hYkgbaSBzjVMO753jV6UWuSabfxDY5DwZTHZWojlCYZITCddxqYwELMYcaDNba4SMiQ0Y3PHNo\ne2Wkw3M8TDXQFg8gtwAADUpJREFUHGq0lI9G+QmYZLSlKd1UbfgAw85L5fMNnVZVbWRlU2Qdv/r5\n0nFINg5pKo8gFaICnuPRmmmlKdVU/bdxHQ/XpKv/Ro5xqo3YMA7JeMnFzhk3g+uc7BSm6c3a8kiG\ntdjDlnF5nx22bfhrKuUPf8388tIxkPIcPNepjpZEcVxt5Piug1duCBXK12oMBjHd5QZW8nd36PiW\nZJ3Kdg7fZ4e97vD6J+sRcRxjbJzsL4/0DG94Hzou5edxefQHLE5cwo2KmDigZFKExgdrsXGEscmU\nICeOMDaZ2pN2LQ0pQ50PJg6J4xAbhdgowsZBeT0kNC4lkyY0Kd45YX8Vx0eBWkRmJN/xmVc3j3l1\n80bc35ppZSlLT3GtaiO2MfkgTyEqDJv7Xhm2rWwzZvi6tbY6olAJ9CM9wjis9rJXwmcYh/SX+ilE\nhWpjozL9JogCugpdHCgcONQL7mZJe8n8+1JUql7Amw/y5MM8URxVA2ZlGlMlOFZC+bARivJ0pShK\nAnflcwLVz4mBMA6r04EOH92ojJYMHTWpqPQ0V8Jx5d8MynPdazQtarxURkaAYaMZrnGr56HyiG1M\nISoQRAE5P0fOy2Gx1elRlYZAKSoxGA5Wp1YNnYJV59XRnGmm3q+nP+int9hLaMPq38zQ6zeGPjzH\nO2K7YxwGggF6S72EcUjWy5JyU/SV+uguduMYh8ZUY3XEriHVgMFUR72GNmKDOCDtplnUsIgF9QsI\n4oD+Uj9dhS468h0cGDxQHVmZlZnFspZlLG5cjMEkDe1yGK00rGMbD2uEpdwUacdL/qaiIoNRkQOl\n5N+yUq4+VU9rppV6v558mFwb4xuH5oYsrnEZCAbJh/nk3JSvT6mcm6EXlifBPq5+tyvfs95Sb7V+\nDX4Ds3OzSTkpDhYPcmDwAGk3TXO6lYZUw0k1tAaCAcI4rHZKnMxvOBSjYrWBOVUpUIuITHOOcZI7\nv1B/wq9NuSma0rqV3YkqhAV6ij0UoyJAtQd7aHiNbTziiEUpStYdx8E3/rBe9EpoKUUluovd9BR7\nqsGuMopSCXaRjUg5qeq0nGKYjHYMRkkDqRSVjug1j2xU3VeZwuUaN7nI2HgMhkm4M8aQdpLe8FJc\nohgVaUo3UefV4TrusEZIKSoxEA6wa/8uBoIB6v16mtJJz/pAaaAabKuPaPjz0UYwsl62ev1CZZSo\nKd2EtZa+Ut9x31HpaBr8QyGzp9hT02liJ6PSIAWqDRyg2qgdjWOcI0atDIbGdCNNqSZcx602RKt/\nI8YM2xZEAR35DvqD/iOO0ZxupinVRFO6iZyfq76uXKhathSVeLr7aXb07cDB4fTG5AfWUm5q2LUq\nnuPx0fM/Ol7/bDWhQC0iIjLOMl5mUt61Ziqy1g6bnx/GIfWpZGrU0P2H924GccBAaYC+Uh/AsIuV\nh/aA58M8O/t2sqd/Dyk3RX2qnpZ0C3Nyc4adw3yQ55meZ9jVvwuHQ9NqXMcdNh0piqNhF3RX6ja0\n1993/Wq5vlIfXYUu+oP+6m1SYxtTCAuENiTn5arbKtenFKJDjZ5SVMJaS9pL4zle9bhZL0trppXG\ndCO+SXqye0u97B/cTz7I05ZrY3Z2NsWoSHehm+5i8ugtJj3aQxuBlSlO1elNNgnt580/j3l18/Ac\nrzpC0VPsoafYQ3exm/2D+xnsGzx0Lg9rWLqOy9KmpbxiySsI45CtPVvZ3b+7Op2u0jCbCnQfahER\nERGRERzvfah1E0URERERkTFQoBYRERERGQMFahERERGRMVCgFhEREREZAwVqEREREZExUKAWERER\nERkDBWoRERERkTGoaaA2xlxujHnCGPO0MebDI+z/oDFmszFmozHmVmPM6bWsj4iIiIjIeKtZoDbG\nuMAXgSuAlcBVxpiVhxV7CFhnrT0b+DHw6VrVR0RERESkFmrZQ70eeNpa+4y1tgRcD7x2aAFr7e3W\n2nz56T3AwhrWR0RERERk3NUyUJ8G7BzyfFd522j+BPhFDesjIiIiIjLuvBoe24ywzY5Y0Jg/AtYB\nF42y/93AuwEWL148XvUTERERERmzWvZQ7wIWDXm+ENh9eCFjzGXAR4DXWGuLIx3IWvtVa+06a+26\ntra2mlRWRERERORk1DJQ3w8sM8a0G2NSwFuAG4cWMMacA3yFJEzvq2FdRERERERqomaB2lobAu8D\nfglsAX5ord1kjPm4MeY15WKfAeqBHxljHjbG3DjK4UREREREJqVazqHGWnsTcNNh2/5+yPpltXx/\nEREREZFa0y8lioiIiIiMgQK1iIiIiMgYKFCLiIiIiIyBArWIiIiIyBgoUIuIiIiIjIECtYiIiIjI\nGChQi4iIiIiMgQK1iIiIiMgYKFCLiIiIiIyBArWIiIiIyBgoUIuIiIiIjIECtYiIiIjIGBhr7UTX\n4YQYYzqBZyfo7WcD+yfoveXU0XmeGXSeZwad55lB53nmONXn+nRrbduxCk25QD2RjDEbrLXrJroe\nUls6zzODzvPMoPM8M+g8zxyT9VxryoeIiIiIyBgoUIuIiIiIjIEC9Yn56kRXQE4JneeZQed5ZtB5\nnhl0nmeOSXmuNYdaRERERGQM1EMtIiIiIjIGCtTHwRhzuTHmCWPM08aYD090fWT8GGO2G2MeNcY8\nbIzZUN7Waoy5xRjzVHnZMtH1lBNnjPmmMWafMeaxIdtGPLcm8YXyd3yjMeYFE1dzORGjnOd/MMY8\nV/5eP2yMeeWQfX9TPs9PGGNeMTG1lhNljFlkjLndGLPFGLPJGPP+8nZ9p6eRo5znSf+dVqA+BmOM\nC3wRuAJYCVxljFk5sbWScXaJtXbtkNvwfBi41Vq7DLi1/Fymnm8Blx+2bbRzewWwrPx4N/DlU1RH\nGbtvceR5Bvhc+Xu91lp7E0D5v91vAVaVX/Ol8n/jZfILgf9mrT0LeBHw3vL51Hd6ehntPMMk/04r\nUB/beuBpa+0z1toScD3w2gmuk9TWa4Fvl9e/DVw5gXWRk2StvRPoOmzzaOf2tcB1NnEP0GyMmX9q\naipjMcp5Hs1rgeuttUVr7TbgaZL/xsskZ63dY619sLzeB2wBTkPf6WnlKOd5NJPmO61AfWynATuH\nPN/F0U+uTC0W+JUx5gFjzLvL2+Zaa/dA8uUG5kxY7WS8jXZu9T2fft5XHur/5pBpWzrP04AxZglw\nDnAv+k5PW4edZ5jk32kF6mMzI2zTrVGmjwuttS8gGR58rzHmpRNdIZkQ+p5PL18GzgDWAnuAfy5v\n13me4owx9cANwAestb1HKzrCNp3rKWKE8zzpv9MK1Me2C1g05PlCYPcE1UXGmbV2d3m5D/gpyVBR\nR2VosLzcN3E1lHE22rnV93wasdZ2WGsja20MfI1DQ8A6z1OYMcYnCVnfs9b+pLxZ3+lpZqTzPBW+\n0wrUx3Y/sMwY026MSZFMfr9xgusk48AYU2eMaaisAy8HHiM5v28vF3s78J8TU0OpgdHO7Y3A28p3\nBngR0FMZRpap57C5sn9A8r2G5Dy/xRiTNsa0k1ywdt+prp+cOGOMAb4BbLHWfnbILn2np5HRzvNU\n+E57E/GmU4m1NjTGvA/4JeAC37TWbprgasn4mAv8NPn+4gHft9bebIy5H/ihMeZPgB3AGyewjnKS\njDH/DlwMzDbG7AI+CnyKkc/tTcArSS5oyQPvOOUVlpMyynm+2BizlmTodzvwZwDW2k3GmB8Cm0nu\nJvBea200EfWWE3Yh8FbgUWPMw+Vtf4u+09PNaOf5qsn+ndYvJYqIiIiIjIGmfIiIiIiIjIECtYiI\niIjIGChQi4iIiIiMgQK1iIiIiMgYKFCLiIiIiIyBArWIyCRnjImMMQ8PeXx4HI+9xBjz2LFLiojI\naHQfahGRyW/QWrt2oishIiIjUw+1iMgUZYzZboz5J2PMfeXHmeXtpxtjbjXGbCwvF5e3zzXG/NQY\n80j5cUH5UK4x5mvGmE3GmF8ZY7Ll8tcaYzaXj3P9BH1MEZFJT4FaRGTyyx425ePNQ/b1WmvXA/8K\nfL687V+B66y1ZwPfA75Q3v4F4DfW2jXAC4DKr74uA75orV0FdAOvL2//MHBO+TjX1OrDiYhMdfql\nRBGRSc4Y02+trR9h+3bgUmvtM8YYH9hrrZ1ljNkPzLfWBuXte6y1s40xncBCa21xyDGWALdYa5eV\nn/93wLfWfsIYczPQD/wH8B/W2v4af1QRkSlJPdQiIlObHWV9tDIjKQ5Zjzh0fc2rgC8CLwQeMMbo\nuhsRkREoUIuITG1vHrL8XXn9buAt5fU/BO4qr98KvAfAGOMaYxpHO6gxxgEWWWtvB/4aaAaO6CUX\nERHd5UNEZCrIGmMeHvL8Zmtt5dZ5aWPMvSQdJFeVt10LfNMY81dAJ/CO8vb3A181xvwJSU/0e4A9\no7ynC3zXGNMEGOBz1trucftEIiLTiOZQi4hMUeU51Oustfsnui4iIjOZpnyIiIiIiIyBeqhFRERE\nRMZAPdQiIiIiImOgQC0iIiIiMgYK1CIiIiIiY6BALSIiIiIyBgrUIiIiIiJjoEAtIiIiIjIG/x/r\nqsZH2ZrdOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29d66c91748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "key_ = list(history.history.keys())[3]\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(history.history[key_], label=\"LSTM\")\n",
    "plt.plot(history2.history[key_], label=\"SimpleRNN\")\n",
    "plt.plot(history3.history[key_], label=\"GRU\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.savefig(\"loss_softmax.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that GRU and LSTM perform better than a Simple RNN. LSTM is also performing slightly better that GRU but require more computation time. We can also check the output and compare it to the real output provided by the graph (see the y description in preparation of data section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :\n",
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]]]\n",
      "\n",
      "\n",
      "LSTM predicts :\n",
      "[[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "\n",
      "\n",
      "GRU predicts :\n",
      "[[ 0.974]\n",
      " [ 0.807]\n",
      " [ 0.719]\n",
      " [ 1.184]\n",
      " [ 0.944]\n",
      " [ 0.999]\n",
      " [ 1.426]\n",
      " [ 0.957]\n",
      " [ 0.999]\n",
      " [ 1.212]\n",
      " [ 1.52 ]\n",
      " [ 0.954]\n",
      " [ 0.42 ]\n",
      " [ 0.83 ]\n",
      " [ 0.903]\n",
      " [ 0.944]\n",
      " [ 0.976]\n",
      " [ 1.005]\n",
      " [ 1.022]\n",
      " [ 1.029]]\n",
      "\n",
      "\n",
      "SRNN predicts :\n",
      "[[[ 0.     0.539  0.001  0.001  0.456  0.001  0.001]\n",
      "  [ 0.     0.662  0.039  0.051  0.002  0.246  0.   ]\n",
      "  [ 0.     0.63   0.007  0.005  0.001  0.356  0.   ]\n",
      "  [ 0.     0.002  0.     0.     0.764  0.232  0.002]\n",
      "  [ 0.     0.012  0.218  0.761  0.     0.007  0.002]\n",
      "  [ 0.     0.568  0.002  0.014  0.001  0.414  0.002]\n",
      "  [ 0.     0.002  0.     0.     0.745  0.251  0.002]\n",
      "  [ 0.     0.016  0.207  0.766  0.     0.009  0.002]\n",
      "  [ 0.     0.571  0.001  0.012  0.001  0.413  0.002]\n",
      "  [ 0.     0.578  0.005  0.006  0.001  0.41   0.   ]\n",
      "  [ 0.     0.002  0.     0.     0.752  0.244  0.002]\n",
      "  [ 0.     0.014  0.211  0.765  0.     0.008  0.002]\n",
      "  [ 0.     0.008  0.019  0.002  0.001  0.002  0.968]\n",
      "  [ 0.003  0.03   0.418  0.527  0.005  0.005  0.012]\n",
      "  [ 0.007  0.387  0.232  0.137  0.03   0.153  0.055]\n",
      "  [ 0.004  0.454  0.055  0.034  0.156  0.295  0.002]\n",
      "  [ 0.003  0.38   0.025  0.014  0.218  0.358  0.003]\n",
      "  [ 0.004  0.334  0.046  0.031  0.226  0.353  0.006]\n",
      "  [ 0.005  0.32   0.072  0.051  0.211  0.331  0.009]\n",
      "  [ 0.006  0.328  0.081  0.058  0.197  0.321  0.01 ]]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input :\")\n",
    "print(X_val)\n",
    "print(\"\\n\\nLSTM predicts :\")\n",
    "y_pred = model.predict(X_val)\n",
    "print(np.sum(y_pred, axis=2).reshape(-1,1))\n",
    "print(\"\\n\\nGRU predicts :\")\n",
    "y_pred = model3.predict(X_val)\n",
    "print(np.sum(y_pred, axis=2).reshape(-1,1))\n",
    "print(\"\\n\\nSRNN predicts :\")\n",
    "y_pred = model2.predict(X_val)\n",
    "print(y_pred)\n",
    "print(np.sum(y_pred, axis=2).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply the output by removing small output and compare it to the possible output (we will only keep prediction from GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred = np.where(y_pred < 0.1, 0, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.     0.54   0.     0.     0.407  0.     0.   ] \t [0 1 0 0 1 0 0]\n",
      "[ 0.     0.     0.66   0.314  0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.     0.     0.957  0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.628  0.     0.     0.     0.372  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.555  0.     0.     0.     0.372  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.996  0.319  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.     0.     0.167  0.55   0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.486  0.     0.     0.     0.51   0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.992  0.499  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.     0.     0.301  0.55   0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.396  0.     0.     0.     0.592  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.689  0.     0.     0.     0.592  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.997  0.592  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.    0.    0.37  0.55  0.    0.    0.  ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.327  0.     0.     0.     0.599  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.967  0.599  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.     0.     0.     0.     0.     0.     0.874] \t [0 0 0 0 0 0 1]\n",
      "[ 0.     0.     0.128  0.337  0.     0.     0.378] \t [0 0 0 0 0 0 0]\n",
      "[ 0.     0.379  0.     0.113  0.     0.284  0.193] \t [0 0 0 0 0 0 0]\n",
      "[ 0.     0.469  0.     0.     0.13   0.295  0.193] \t [0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for pred, real in zip(y_pred[0], y_possible[0]):\n",
    "    print(pred, \"\\t\", real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah !! Output is balanced between both offset but with different \"probabilities\". We can also check how well they are to generate sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it as generator\n",
    "\n",
    "As explained previously, we trained our model as a many-to-many RNN. Now we want a generator so we are going to use a one-to-many model but reusing knowledge from the training. \n",
    "\n",
    "Before that, we will need an evaluation function which take the output, pick the next input based on the probability to have this output, create the next input and run it until the graph is over. After that, we will check is the created word is really a Reber word. This will be done with following functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pick_From_Output(x):\n",
    "    y = np.zeros_like(x)\n",
    "#     x = np.where(x < 0.1, 0, x)\n",
    "    x = x[0]/x[0].sum(axis=1)\n",
    "    i = np.random.choice(list(range(7)), size=1, p=x[0])\n",
    "    y[0,0,i] = 1\n",
    "    return y\n",
    "\n",
    "def evaluate(model, nb_word = 1, max_iter = 100, errors = None):\n",
    "    good_pred = 0\n",
    "    if errors is None:\n",
    "        errors = {1:0, 2:0, 3:0, 4:0}\n",
    "    for _ in range(nb_word):\n",
    "        model.reset_states()\n",
    "        first_input = np.array([[[1,0,0,0,0,0,0]]])\n",
    "        word = \"B\"\n",
    "        loop = 0\n",
    "        nextLetter = \"B\"\n",
    "        next_seq = first_input\n",
    "        count_E = 0\n",
    "        while count_E < 2 and loop < max_iter:\n",
    "            y_pred = model.predict(next_seq)\n",
    "            next_seq = Pick_From_Output(y_pred)\n",
    "            nextLetter = reber.sequenceToWord(next_seq[0])\n",
    "            loop += 1\n",
    "            word += nextLetter\n",
    "            if nextLetter == \"E\":\n",
    "                count_E += 1\n",
    "#         print(word)\n",
    "        code = reber.in_embedded_grammar(word)\n",
    "        if code == 0:\n",
    "            good_pred += 1\n",
    "        else:\n",
    "#             print(word, code)\n",
    "            errors[code] += 1\n",
    "    print(errors)\n",
    "    acc = 100*good_pred/nb_word\n",
    "    print(\"Good prediction : {:.2f}%\".format(acc))\n",
    "    return acc, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create both model as one-to-many and evaluate them 20 times on 100 words generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = load_model(\"lstm_simple.h5\")  # lstm_simple /  srnn_simple / gru_simple\n",
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(LSTM(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.add(Dense(7, activation='softmax'))\n",
    "newModel.set_weights(Model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 44, 4: 2}\n",
      "Good prediction : 54.00%\n",
      "{1: 0, 2: 0, 3: 88, 4: 2}\n",
      "Good prediction : 56.00%\n",
      "{1: 0, 2: 0, 3: 146, 4: 3}\n",
      "Good prediction : 41.00%\n",
      "{1: 0, 2: 0, 3: 202, 4: 4}\n",
      "Good prediction : 43.00%\n",
      "{1: 0, 2: 0, 3: 260, 4: 5}\n",
      "Good prediction : 41.00%\n",
      "{1: 0, 2: 0, 3: 315, 4: 6}\n",
      "Good prediction : 44.00%\n",
      "{1: 0, 2: 0, 3: 358, 4: 6}\n",
      "Good prediction : 57.00%\n",
      "{1: 0, 2: 0, 3: 412, 4: 7}\n",
      "Good prediction : 45.00%\n",
      "{1: 0, 2: 0, 3: 450, 4: 9}\n",
      "Good prediction : 60.00%\n",
      "{1: 0, 2: 1, 3: 502, 4: 10}\n",
      "Good prediction : 46.00%\n",
      "{1: 0, 2: 1, 3: 560, 4: 10}\n",
      "Good prediction : 42.00%\n",
      "{1: 0, 2: 1, 3: 614, 4: 12}\n",
      "Good prediction : 44.00%\n",
      "{1: 0, 2: 1, 3: 658, 4: 15}\n",
      "Good prediction : 53.00%\n",
      "{1: 0, 2: 1, 3: 705, 4: 18}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 1, 3: 745, 4: 21}\n",
      "Good prediction : 57.00%\n",
      "{1: 0, 2: 2, 3: 792, 4: 23}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 2, 3: 848, 4: 23}\n",
      "Good prediction : 44.00%\n",
      "{1: 0, 2: 2, 3: 892, 4: 25}\n",
      "Good prediction : 54.00%\n",
      "{1: 0, 2: 2, 3: 944, 4: 25}\n",
      "Good prediction : 48.00%\n",
      "{1: 0, 2: 2, 3: 985, 4: 26}\n",
      "Good prediction : 58.00%\n",
      "{1: 0, 2: 2, 3: 985, 4: 26}\n"
     ]
    }
   ],
   "source": [
    "error_LSTM = None\n",
    "result_LSTM = []\n",
    "for _ in range(nb_samples):\n",
    "    acc, error_LSTM = evaluate(newModel, 100, 50, error_LSTM)\n",
    "    result_LSTM.append(acc)\n",
    "print(error_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = load_model(\"srnn_simple.h5\")\n",
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(SimpleRNN(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.add(Dense(7, activation='softmax'))\n",
    "newModel.set_weights(Model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 50, 4: 3}\n",
      "Good prediction : 47.00%\n",
      "{1: 0, 2: 0, 3: 102, 4: 4}\n",
      "Good prediction : 47.00%\n",
      "{1: 0, 2: 0, 3: 161, 4: 4}\n",
      "Good prediction : 41.00%\n",
      "{1: 0, 2: 0, 3: 211, 4: 5}\n",
      "Good prediction : 49.00%\n",
      "{1: 0, 2: 0, 3: 267, 4: 5}\n",
      "Good prediction : 44.00%\n",
      "{1: 0, 2: 0, 3: 327, 4: 5}\n",
      "Good prediction : 40.00%\n",
      "{1: 0, 2: 0, 3: 376, 4: 6}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 0, 3: 425, 4: 6}\n",
      "Good prediction : 51.00%\n",
      "{1: 0, 2: 1, 3: 476, 4: 7}\n",
      "Good prediction : 47.00%\n",
      "{1: 0, 2: 2, 3: 519, 4: 7}\n",
      "Good prediction : 56.00%\n",
      "{1: 0, 2: 2, 3: 569, 4: 8}\n",
      "Good prediction : 49.00%\n",
      "{1: 0, 2: 2, 3: 612, 4: 9}\n",
      "Good prediction : 56.00%\n",
      "{1: 0, 2: 2, 3: 660, 4: 11}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 3, 3: 699, 4: 11}\n",
      "Good prediction : 60.00%\n",
      "{1: 0, 2: 3, 3: 744, 4: 12}\n",
      "Good prediction : 54.00%\n",
      "{1: 0, 2: 3, 3: 788, 4: 12}\n",
      "Good prediction : 56.00%\n",
      "{1: 0, 2: 3, 3: 846, 4: 15}\n",
      "Good prediction : 39.00%\n",
      "{1: 0, 2: 3, 3: 896, 4: 17}\n",
      "Good prediction : 48.00%\n",
      "{1: 0, 2: 3, 3: 946, 4: 18}\n",
      "Good prediction : 49.00%\n",
      "{1: 0, 2: 3, 3: 1001, 4: 18}\n",
      "Good prediction : 45.00%\n",
      "{1: 0, 2: 3, 3: 1001, 4: 18}\n"
     ]
    }
   ],
   "source": [
    "error_SRNN = None\n",
    "result_SRNN = []\n",
    "for _ in range(nb_samples):\n",
    "    acc, error_SRNN = evaluate(newModel, 100, 50, error_SRNN)\n",
    "    result_SRNN.append(acc)\n",
    "print(error_SRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = load_model(\"gru_simple.h5\")\n",
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(GRU(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.add(Dense(7, activation='softmax'))\n",
    "newModel.set_weights(Model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 38, 4: 1}\n",
      "Good prediction : 61.00%\n",
      "{1: 0, 2: 0, 3: 77, 4: 1}\n",
      "Good prediction : 61.00%\n",
      "{1: 0, 2: 0, 3: 130, 4: 2}\n",
      "Good prediction : 46.00%\n",
      "{1: 0, 2: 0, 3: 165, 4: 3}\n",
      "Good prediction : 64.00%\n",
      "{1: 0, 2: 0, 3: 199, 4: 3}\n",
      "Good prediction : 66.00%\n",
      "{1: 0, 2: 0, 3: 246, 4: 5}\n",
      "Good prediction : 51.00%\n",
      "{1: 0, 2: 0, 3: 293, 4: 5}\n",
      "Good prediction : 53.00%\n",
      "{1: 0, 2: 0, 3: 338, 4: 6}\n",
      "Good prediction : 54.00%\n",
      "{1: 0, 2: 0, 3: 388, 4: 6}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 0, 3: 430, 4: 6}\n",
      "Good prediction : 58.00%\n",
      "{1: 0, 2: 0, 3: 478, 4: 6}\n",
      "Good prediction : 52.00%\n",
      "{1: 0, 2: 0, 3: 520, 4: 6}\n",
      "Good prediction : 58.00%\n",
      "{1: 0, 2: 0, 3: 566, 4: 6}\n",
      "Good prediction : 54.00%\n",
      "{1: 0, 2: 0, 3: 609, 4: 7}\n",
      "Good prediction : 56.00%\n",
      "{1: 0, 2: 0, 3: 654, 4: 8}\n",
      "Good prediction : 54.00%\n",
      "{1: 0, 2: 1, 3: 699, 4: 9}\n",
      "Good prediction : 53.00%\n",
      "{1: 0, 2: 1, 3: 749, 4: 9}\n",
      "Good prediction : 50.00%\n",
      "{1: 0, 2: 1, 3: 787, 4: 9}\n",
      "Good prediction : 62.00%\n",
      "{1: 0, 2: 1, 3: 821, 4: 10}\n",
      "Good prediction : 65.00%\n",
      "{1: 0, 2: 1, 3: 865, 4: 11}\n",
      "Good prediction : 55.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 1, 3: 865, 4: 11}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_GRU = None\n",
    "result_GRU = []\n",
    "for _ in range(nb_samples):\n",
    "    acc, error_GRU = evaluate(newModel, 100, 50, error_GRU)\n",
    "    result_GRU.append(acc)\n",
    "error_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'LSTM': result_LSTM, 'Simple RNN': result_SRNN, 'GRU' : result_GRU}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bae6630860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bad5942d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.barplot(x=[\"LSTM\", \"Simple RNN\", \"GRU\"], data=df, capsize=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that bost LSTM and GRU outperform the standard RNN. In average LSTM is slightly better than GRU but takes also more time to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAFyCAYAAABFkzRRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDS/u/OA2wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e00bd7bb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax = sns.boxplot(x=[result_LSTM, result_SRNN, result_GRU], y=[\"LSTM\", \"SimpleRNN\", \"GRU\"])\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(xlim=(0, 100), ylabel=\"\",\n",
    "       xlabel=\"Accuracy (%)\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig(\"boxplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0sAAAK8CAYAAAA+pCRjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e1eaba8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(nb_samples))\n",
    "y = [result_LSTM, result_SRNN, result_GRU]\n",
    "labels = [\"LSTM\", \"SimpleRNN\", \"GRU\"]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for y_arr, label in zip(y, labels):\n",
    "    plt.plot(x, y_arr, label=label)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.ylim((0,100))\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.savefig(\"test_result.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(data=error_LSTM, index=[\"LSTM\"])\n",
    "df3 = df3.append(pd.DataFrame(data=error_GRU, index=[\"GRU\"]))\n",
    "df3 = df3.append(pd.DataFrame(data=error_SRNN, index=[\"SRNN\"]))\n",
    "df3.columns = [\"1st Letter\", \"2nd Letter\", \"LTM\", \"Reber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Letter</th>\n",
       "      <th>2nd Letter</th>\n",
       "      <th>LTM</th>\n",
       "      <th>Reber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>985</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>865</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRNN</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1001</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1st Letter  2nd Letter   LTM  Reber\n",
       "LSTM           0           2   985     26\n",
       "GRU            0           1   865     11\n",
       "SRNN           0           3  1001     18"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this workbook, we started to go through RNN. We check a simple model of both LSTM, GRU and SimpleRNN to check how fast and well they learn. On this example GRU and LSTM outperform the standard RNN due to the memory function. There is also a difference between LSTM and GRU but with slightly more epochs, they both perform similar. We can probably have better result by using a more advanced model but for such a simple model, we can see that it works really well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further\n",
    "\n",
    "On a future notebook, we will explore Embedded Reber but using deeper RNNs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
